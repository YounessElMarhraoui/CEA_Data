{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c3c1b232",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T05:49:24.412407Z",
     "start_time": "2021-10-15T05:49:24.393403Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e819c8b0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:28:16.647883Z",
     "start_time": "2021-10-15T06:28:16.632871Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9de020",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-15T06:28:16.889Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = {file[:-4]: pd.read_csv(DATA_PATH+file) for file in os.listdir(DATA_PATH)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168f805c",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-15T06:28:17.674Z"
    }
   },
   "outputs": [],
   "source": [
    "test_df = predictions.pop('test_df')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "44c20869",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:09:36.703868Z",
     "start_time": "2021-10-15T06:09:36.676869Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_real, y_pred):\n",
    "    print(\"Accuracy score: \", accuracy_score(y_real, y_pred))\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_real, y_pred))\n",
    "    print(\"Classification report: \\n\", classification_report(y_real, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_real, label='Real')\n",
    "    plt.plot(y_pred, label='Predictions')\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_real)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_pred)\n",
    "    plt.show()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=y_real, name='Real values'))\n",
    "    fig.add_trace(go.Scatter(y=y_pred, name='Predicted values'))\n",
    "    pio.show(fig)\n",
    "\n",
    "def evaluate_models(test_df, model_preds, model_name):\n",
    "    \"\"\"Evaualtes the predictions made by the models by reformatting them into their initial length\n",
    "    \"\"\"\n",
    "    window_size = int(re.search(r'_ws_(.*?)_transform', model_name).group(1))\n",
    "    y_real_test_pred = model_preds.predictions\n",
    "    y_real_test = test_df.appui_leve.values[:len(y_real_test_pred)]\n",
    "    print(\n",
    "        \"\"\"\n",
    "        ############################################\n",
    "        {} evaluation...\n",
    "        ############################################\n",
    "        \"\"\".format(model_name)\n",
    "    )\n",
    "    print(\"########## All test data ##########\")\n",
    "    #self.evaluate(y_real_test_pred, y_real_test)\n",
    "    acc = accuracy_score(y_real_test, y_real_test_pred)\n",
    "    f1 = f1_score(y_real_test, y_real_test_pred)\n",
    "    rec = recall_score(y_real_test, y_real_test_pred)\n",
    "    pre = precision_score(y_real_test, y_real_test_pred)\n",
    "    print(\"Accuracy score: \", acc)\n",
    "    print(\"F1 score score: \", f1)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_real_test, y_real_test_pred))\n",
    "    print(\"Classification report: \\n\", classification_report(y_real_test, y_real_test_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real_test, y_real_test_pred).ravel()\n",
    "    spe = tn / (tn+fp)\n",
    "    sen = tp / (tp+fn)\n",
    "    print(\"Specificity: \", spe)\n",
    "    print(\"Sensitivity: \", sen)\n",
    "    print(\"TP; \", tp)\n",
    "    print(\"FP; \", fp)\n",
    "    print(\"TN; \", tn)\n",
    "    print(\"FN; \", fn)\n",
    "    return model_name, acc, f1, rec, pre, spe, sen, tn, fp, fn, tp\n",
    "\n",
    "    #print(\"########## Left/Right data ##########\")\n",
    "    #self.test_df['preds'] = np.append(y_real_test_pred, np.zeros(self.test_df.shape[0] - len(y_real_test_pred)))\n",
    "    #test_df_g = self.test_df[self.test_df.foot_type == 0]\n",
    "    #test_df_d = self.test_df[self.test_df.foot_type == 1]\n",
    "    #self.evaluate(test_df_g.appui_leve, test_df_g.preds)\n",
    "    #self.evaluate(test_df_d.appui_leve, test_df_d.preds)\n",
    "\n",
    "    #print(\"########## Per activity data ##########\")\n",
    "    #for activity in test_df_g.activity.unique():\n",
    "    #    print(\"#### Activit√©: {} ####\".format(activity))\n",
    "    #    temp_df_g = test_df_g[test_df_g.activity == activity]\n",
    "    #    temp_df_d = test_df_d[test_df_d.activity == activity]\n",
    "    #    self.evaluate(temp_df_g.appui_leve, temp_df_g.preds)\n",
    "    #    self.evaluate(temp_df_d.appui_leve, temp_df_d.preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "56cc88b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:10:44.215868Z",
     "start_time": "2021-10-15T06:09:44.259884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9506512171023085\n",
      "F1 score score:  0.9453909309583921\n",
      "Recall:  0.9948953974895397\n",
      "Precision:  0.9005794796045904\n",
      "Confusion matrix: \n",
      " [[29140  2625]\n",
      " [  122 23778]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.92      0.95     31765\n",
      "         1.0       0.90      0.99      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55665\n",
      "   macro avg       0.95      0.96      0.95     55665\n",
      "weighted avg       0.95      0.95      0.95     55665\n",
      "\n",
      "Specificity:  0.9173618762789233\n",
      "Sensitivity:  0.9948953974895397\n",
      "TP;  23778\n",
      "FP;  2625\n",
      "TN;  29140\n",
      "FN;  122\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9673942333602803\n",
      "F1 score score:  0.9626996033621735\n",
      "Recall:  0.98\n",
      "Precision:  0.9459994345490529\n",
      "Confusion matrix: \n",
      " [[30428  1337]\n",
      " [  478 23422]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.98      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9579096489847316\n",
      "Sensitivity:  0.98\n",
      "TP;  23422\n",
      "FP;  1337\n",
      "TN;  30428\n",
      "FN;  478\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9482950666522942\n",
      "F1 score score:  0.9415634517766497\n",
      "Recall:  0.9701255230125523\n",
      "Precision:  0.9146351084812623\n",
      "Confusion matrix: \n",
      " [[29598  2164]\n",
      " [  714 23186]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95     31762\n",
      "         1.0       0.91      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9318682702600591\n",
      "Sensitivity:  0.9701255230125523\n",
      "TP;  23186\n",
      "FP;  2164\n",
      "TN;  29598\n",
      "FN;  714\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9493370701735475\n",
      "F1 score score:  0.942177568177158\n",
      "Recall:  0.9612970711297071\n",
      "Precision:  0.9238037796542018\n",
      "Confusion matrix: \n",
      " [[29867  1895]\n",
      " [  925 22975]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31762\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9403375102323531\n",
      "Sensitivity:  0.9612970711297071\n",
      "TP;  22975\n",
      "FP;  1895\n",
      "TN;  29867\n",
      "FN;  925\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9473608565987568\n",
      "F1 score score:  0.940831987075929\n",
      "Recall:  0.9746861924686192\n",
      "Precision:  0.9092505854800936\n",
      "Confusion matrix: \n",
      " [[29437  2325]\n",
      " [  605 23295]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95     31762\n",
      "         1.0       0.91      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.94      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9267993199420691\n",
      "Sensitivity:  0.9746861924686192\n",
      "TP;  23295\n",
      "FP;  2325\n",
      "TN;  29437\n",
      "FN;  605\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9337812589824662\n",
      "F1 score score:  0.927231807951988\n",
      "Recall:  0.9825941422594142\n",
      "Precision:  0.8777752859385513\n",
      "Confusion matrix: \n",
      " [[28494  3270]\n",
      " [  416 23484]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.94     31764\n",
      "         1.0       0.88      0.98      0.93     23900\n",
      "\n",
      "    accuracy                           0.93     55664\n",
      "   macro avg       0.93      0.94      0.93     55664\n",
      "weighted avg       0.94      0.93      0.93     55664\n",
      "\n",
      "Specificity:  0.8970532678503966\n",
      "Sensitivity:  0.9825941422594142\n",
      "TP;  23484\n",
      "FP;  3270\n",
      "TN;  28494\n",
      "FN;  416\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9338351537798217\n",
      "F1 score score:  0.9273613001203084\n",
      "Recall:  0.9836820083682009\n",
      "Precision:  0.8771406185874715\n",
      "Confusion matrix: \n",
      " [[28471  3293]\n",
      " [  390 23510]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.94     31764\n",
      "         1.0       0.88      0.98      0.93     23900\n",
      "\n",
      "    accuracy                           0.93     55664\n",
      "   macro avg       0.93      0.94      0.93     55664\n",
      "weighted avg       0.94      0.93      0.93     55664\n",
      "\n",
      "Specificity:  0.8963291776854301\n",
      "Sensitivity:  0.9836820083682009\n",
      "TP;  23510\n",
      "FP;  3293\n",
      "TN;  28471\n",
      "FN;  390\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9450273066973268\n",
      "F1 score score:  0.9383809907370116\n",
      "Recall:  0.9748953974895398\n",
      "Precision:  0.9045031055900621\n",
      "Confusion matrix: \n",
      " [[29304  2460]\n",
      " [  600 23300]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95     31764\n",
      "         1.0       0.90      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9225538345296562\n",
      "Sensitivity:  0.9748953974895398\n",
      "TP;  23300\n",
      "FP;  2460\n",
      "TN;  29304\n",
      "FN;  600\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9706997215485493\n",
      "F1 score score:  0.965990366369873\n",
      "Recall:  0.969163179916318\n",
      "Precision:  0.9628382591345555\n",
      "Confusion matrix: \n",
      " [[30871   894]\n",
      " [  737 23163]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.97     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9718558161498505\n",
      "Sensitivity:  0.969163179916318\n",
      "TP;  23163\n",
      "FP;  894\n",
      "TN;  30871\n",
      "FN;  737\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9700350309889517\n",
      "F1 score score:  0.9651861746535315\n",
      "Recall:  0.9674476987447699\n",
      "Precision:  0.9629351990671331\n",
      "Confusion matrix: \n",
      " [[30875   890]\n",
      " [  778 23122]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.97     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.9719817409098064\n",
      "Sensitivity:  0.9674476987447699\n",
      "TP;  23122\n",
      "FP;  890\n",
      "TN;  30875\n",
      "FN;  778\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9595077696937034\n",
      "F1 score score:  0.9530122993537629\n",
      "Recall:  0.9564016736401674\n",
      "Precision:  0.9496468633153303\n",
      "Confusion matrix: \n",
      " [[30553  1212]\n",
      " [ 1042 22858]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.95      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9618447977333543\n",
      "Sensitivity:  0.9564016736401674\n",
      "TP;  22858\n",
      "FP;  1212\n",
      "TN;  30553\n",
      "FN;  1042\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9536128777262765\n",
      "F1 score score:  0.9459131090535842\n",
      "Recall:  0.9446861924686193\n",
      "Precision:  0.9471432167128114\n",
      "Confusion matrix: \n",
      " [[30502  1260]\n",
      " [ 1322 22578]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.95      0.94      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9603299540331214\n",
      "Sensitivity:  0.9446861924686193\n",
      "TP;  22578\n",
      "FP;  1260\n",
      "TN;  30502\n",
      "FN;  1322\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9498401063562215\n",
      "F1 score score:  0.9410472972972973\n",
      "Recall:  0.9323849372384937\n",
      "Precision:  0.9498721227621484\n",
      "Confusion matrix: \n",
      " [[30586  1176]\n",
      " [ 1616 22284]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     31762\n",
      "         1.0       0.95      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9629746237642466\n",
      "Sensitivity:  0.9323849372384937\n",
      "TP;  22284\n",
      "FP;  1176\n",
      "TN;  30586\n",
      "FN;  1616\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9523193561136861\n",
      "F1 score score:  0.943690061953662\n",
      "Recall:  0.9305020920502092\n",
      "Precision:  0.9572572314049587\n",
      "Confusion matrix: \n",
      " [[30769   993]\n",
      " [ 1661 22239]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9687362256784837\n",
      "Sensitivity:  0.9305020920502092\n",
      "TP;  22239\n",
      "FP;  993\n",
      "TN;  30769\n",
      "FN;  1661\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9466082207530899\n",
      "F1 score score:  0.938093651058157\n",
      "Recall:  0.9421757322175732\n",
      "Precision:  0.9340467894474863\n",
      "Confusion matrix: \n",
      " [[30174  1590]\n",
      " [ 1382 22518]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9499433320740461\n",
      "Sensitivity:  0.9421757322175732\n",
      "TP;  22518\n",
      "FP;  1590\n",
      "TN;  30174\n",
      "FN;  1382\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9445242885886749\n",
      "F1 score score:  0.9359016937894388\n",
      "Recall:  0.9432635983263599\n",
      "Precision:  0.9286538144669633\n",
      "Confusion matrix: \n",
      " [[30032  1732]\n",
      " [ 1356 22544]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9454728623599042\n",
      "Sensitivity:  0.9432635983263599\n",
      "TP;  22544\n",
      "FP;  1732\n",
      "TN;  30032\n",
      "FN;  1356\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9481172750790458\n",
      "F1 score score:  0.9391333670544596\n",
      "Recall:  0.9322175732217574\n",
      "Precision:  0.9461525394937998\n",
      "Confusion matrix: \n",
      " [[30496  1268]\n",
      " [ 1620 22280]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     31764\n",
      "         1.0       0.95      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9600805943835788\n",
      "Sensitivity:  0.9322175732217574\n",
      "TP;  22280\n",
      "FP;  1268\n",
      "TN;  30496\n",
      "FN;  1620\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9682385700170664\n",
      "F1 score score:  0.9633742127941665\n",
      "Recall:  0.972887029288703\n",
      "Precision:  0.954045626128344\n",
      "Confusion matrix: \n",
      " [[30645  1120]\n",
      " [  648 23252]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9647410672123407\n",
      "Sensitivity:  0.972887029288703\n",
      "TP;  23252\n",
      "FP;  1120\n",
      "TN;  30645\n",
      "FN;  648\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9484028601200101\n",
      "F1 score score:  0.9383981811162113\n",
      "Recall:  0.9152719665271967\n",
      "Precision:  0.9627233518176217\n",
      "Confusion matrix: \n",
      " [[30915   847]\n",
      " [ 2025 21875]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96     31762\n",
      "         1.0       0.96      0.92      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.94      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9733329135444871\n",
      "Sensitivity:  0.9152719665271967\n",
      "TP;  21875\n",
      "FP;  847\n",
      "TN;  30915\n",
      "FN;  2025\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9505587294743272\n",
      "F1 score score:  0.9415363698164514\n",
      "Recall:  0.9271966527196652\n",
      "Precision:  0.9563266010702572\n",
      "Confusion matrix: \n",
      " [[30750  1012]\n",
      " [ 1740 22160]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.9681380265726339\n",
      "Sensitivity:  0.9271966527196652\n",
      "TP;  22160\n",
      "FP;  1012\n",
      "TN;  30750\n",
      "FN;  1740\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9524990118932126\n",
      "F1 score score:  0.9456056616194866\n",
      "Recall:  0.9615899581589958\n",
      "Precision:  0.9301440828881334\n",
      "Confusion matrix: \n",
      " [[30036  1726]\n",
      " [  918 22982]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31762\n",
      "         1.0       0.93      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9456583338580694\n",
      "Sensitivity:  0.9615899581589958\n",
      "TP;  22982\n",
      "FP;  1726\n",
      "TN;  30036\n",
      "FN;  918\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9446859729807416\n",
      "F1 score score:  0.9369587027292643\n",
      "Recall:  0.9573640167364017\n",
      "Precision:  0.9174050759793112\n",
      "Confusion matrix: \n",
      " [[29704  2060]\n",
      " [ 1019 22881]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.95      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9351467069638585\n",
      "Sensitivity:  0.9573640167364017\n",
      "TP;  22881\n",
      "FP;  2060\n",
      "TN;  29704\n",
      "FN;  1019\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9426918654785859\n",
      "F1 score score:  0.9354721255765029\n",
      "Recall:  0.967489539748954\n",
      "Precision:  0.9055059523809523\n",
      "Confusion matrix: \n",
      " [[29351  2413]\n",
      " [  777 23123]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.95     31764\n",
      "         1.0       0.91      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.924033497040675\n",
      "Sensitivity:  0.967489539748954\n",
      "TP;  23123\n",
      "FP;  2413\n",
      "TN;  29351\n",
      "FN;  777\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.946482466225927\n",
      "F1 score score:  0.9383344718375458\n",
      "Recall:  0.948326359832636\n",
      "Precision:  0.928550944323815\n",
      "Confusion matrix: \n",
      " [[30020  1744]\n",
      " [ 1235 22665]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.94      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9450950761868783\n",
      "Sensitivity:  0.948326359832636\n",
      "TP;  22665\n",
      "FP;  1744\n",
      "TN;  30020\n",
      "FN;  1235\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9689571544058205\n",
      "F1 score score:  0.9640599001663894\n",
      "Recall:  0.9697071129707113\n",
      "Precision:  0.9584780810587262\n",
      "Confusion matrix: \n",
      " [[30761  1004]\n",
      " [  724 23176]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9683928852510625\n",
      "Sensitivity:  0.9697071129707113\n",
      "TP;  23176\n",
      "FP;  1004\n",
      "TN;  30761\n",
      "FN;  724\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9697296326237312\n",
      "F1 score score:  0.9648379624799148\n",
      "Recall:  0.9672803347280334\n",
      "Precision:  0.9624078930935431\n",
      "Confusion matrix: \n",
      " [[30862   903]\n",
      " [  782 23118]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9715724854399497\n",
      "Sensitivity:  0.9672803347280334\n",
      "TP;  23118\n",
      "FP;  903\n",
      "TN;  30862\n",
      "FN;  782\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9522474938018756\n",
      "F1 score score:  0.9437126762949473\n",
      "Recall:  0.9323012552301255\n",
      "Precision:  0.955406911928651\n",
      "Confusion matrix: \n",
      " [[30722  1040]\n",
      " [ 1618 22282]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9672564699955922\n",
      "Sensitivity:  0.9323012552301255\n",
      "TP;  22282\n",
      "FP;  1040\n",
      "TN;  30722\n",
      "FN;  1618\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.951169559124717\n",
      "F1 score score:  0.9428343078282084\n",
      "Recall:  0.9378242677824268\n",
      "Precision:  0.9478981645944345\n",
      "Confusion matrix: \n",
      " [[30530  1232]\n",
      " [ 1486 22414]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     31762\n",
      "         1.0       0.95      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9612115106101631\n",
      "Sensitivity:  0.9378242677824268\n",
      "TP;  22414\n",
      "FP;  1232\n",
      "TN;  30530\n",
      "FN;  1486\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9545470877798139\n",
      "F1 score score:  0.9464572928130027\n",
      "Recall:  0.9356066945606695\n",
      "Precision:  0.9575625214114423\n",
      "Confusion matrix: \n",
      " [[30771   991]\n",
      " [ 1539 22361]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.94      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9687991940054153\n",
      "Sensitivity:  0.9356066945606695\n",
      "TP;  22361\n",
      "FP;  991\n",
      "TN;  30771\n",
      "FN;  1539\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9471292037941937\n",
      "F1 score score:  0.9390089735353242\n",
      "Recall:  0.947907949790795\n",
      "Precision:  0.930275530735433\n",
      "Confusion matrix: \n",
      " [[30066  1698]\n",
      " [ 1245 22655]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.9465432565168115\n",
      "Sensitivity:  0.947907949790795\n",
      "TP;  22655\n",
      "FP;  1698\n",
      "TN;  30066\n",
      "FN;  1245\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9449554469675194\n",
      "F1 score score:  0.9367125211715619\n",
      "Recall:  0.948744769874477\n",
      "Precision:  0.9249816431426939\n",
      "Confusion matrix: \n",
      " [[29925  1839]\n",
      " [ 1225 22675]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     31764\n",
      "         1.0       0.92      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.95      0.94      0.95     55664\n",
      "\n",
      "Specificity:  0.9421042689837552\n",
      "Sensitivity:  0.948744769874477\n",
      "TP;  22675\n",
      "FP;  1839\n",
      "TN;  29925\n",
      "FN;  1225\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9485125035929864\n",
      "F1 score score:  0.9405961115947437\n",
      "Recall:  0.9493723849372385\n",
      "Precision:  0.9319806128316767\n",
      "Confusion matrix: \n",
      " [[30108  1656]\n",
      " [ 1210 22690]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9478655081224027\n",
      "Sensitivity:  0.9493723849372385\n",
      "TP;  22690\n",
      "FP;  1656\n",
      "TN;  30108\n",
      "FN;  1210\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9702146770861403\n",
      "F1 score score:  0.9653428093645484\n",
      "Recall:  0.9661506276150628\n",
      "Precision:  0.9645363408521304\n",
      "Confusion matrix: \n",
      " [[30916   849]\n",
      " [  809 23091]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.97     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9732724696993547\n",
      "Sensitivity:  0.9661506276150628\n",
      "TP;  23091\n",
      "FP;  849\n",
      "TN;  30916\n",
      "FN;  809\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.97037635857361\n",
      "F1 score score:  0.9654507741624588\n",
      "Recall:  0.9640167364016736\n",
      "Precision:  0.966889084728692\n",
      "Confusion matrix: \n",
      " [[30976   789]\n",
      " [  860 23040]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.98      0.97     31765\n",
      "         1.0       0.97      0.96      0.97     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9751613410986936\n",
      "Sensitivity:  0.9640167364016736\n",
      "TP;  23040\n",
      "FP;  789\n",
      "TN;  30976\n",
      "FN;  860\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9539721892853293\n",
      "F1 score score:  0.9463455497382198\n",
      "Recall:  0.9453556485355649\n",
      "Precision:  0.9473375262054508\n",
      "Confusion matrix: \n",
      " [[30506  1256]\n",
      " [ 1306 22594]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.95      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9604558906869844\n",
      "Sensitivity:  0.9453556485355649\n",
      "TP;  22594\n",
      "FP;  1256\n",
      "TN;  30506\n",
      "FN;  1306\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9499838309798426\n",
      "F1 score score:  0.9416596814752725\n",
      "Recall:  0.9400836820083682\n",
      "Precision:  0.9432409739714526\n",
      "Confusion matrix: \n",
      " [[30410  1352]\n",
      " [ 1432 22468]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9574334109942699\n",
      "Sensitivity:  0.9400836820083682\n",
      "TP;  22468\n",
      "FP;  1352\n",
      "TN;  30410\n",
      "FN;  1432\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9540440515971399\n",
      "F1 score score:  0.9468434395910393\n",
      "Recall:  0.9532217573221757\n",
      "Precision:  0.9405499133019569\n",
      "Confusion matrix: \n",
      " [[30322  1440]\n",
      " [ 1118 22782]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96     31762\n",
      "         1.0       0.94      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9546628046092815\n",
      "Sensitivity:  0.9532217573221757\n",
      "TP;  22782\n",
      "FP;  1440\n",
      "TN;  30322\n",
      "FN;  1118\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9480993101465939\n",
      "F1 score score:  0.9406447106198509\n",
      "Recall:  0.9578242677824268\n",
      "Precision:  0.924070560691075\n",
      "Confusion matrix: \n",
      " [[29883  1881]\n",
      " [ 1008 22892]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9407820173781639\n",
      "Sensitivity:  0.9578242677824268\n",
      "TP;  22892\n",
      "FP;  1881\n",
      "TN;  29883\n",
      "FN;  1008\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9436080770336304\n",
      "F1 score score:  0.935803832545964\n",
      "Recall:  0.9572803347280334\n",
      "Precision:  0.9152698323798856\n",
      "Confusion matrix: \n",
      " [[29646  2118]\n",
      " [ 1021 22879]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9333207404608991\n",
      "Sensitivity:  0.9572803347280334\n",
      "TP;  22879\n",
      "FP;  2118\n",
      "TN;  29646\n",
      "FN;  1021\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9475783271054901\n",
      "F1 score score:  0.9401263952724885\n",
      "Recall:  0.9585355648535565\n",
      "Precision:  0.9224110162667096\n",
      "Confusion matrix: \n",
      " [[29837  1927]\n",
      " [  991 22909]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Specificity:  0.9393338370482307\n",
      "Sensitivity:  0.9585355648535565\n",
      "TP;  22909\n",
      "FP;  1927\n",
      "TN;  29837\n",
      "FN;  991\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9665319320937753\n",
      "F1 score score:  0.9615376674855998\n",
      "Recall:  0.9743514644351464\n",
      "Precision:  0.9490565268777764\n",
      "Confusion matrix: \n",
      " [[30515  1250]\n",
      " [  613 23287]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.96      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.960648512513773\n",
      "Sensitivity:  0.9743514644351464\n",
      "TP;  23287\n",
      "FP;  1250\n",
      "TN;  30515\n",
      "FN;  613\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9670888349950597\n",
      "F1 score score:  0.9617775923221364\n",
      "Recall:  0.9643933054393306\n",
      "Precision:  0.9591760299625468\n",
      "Confusion matrix: \n",
      " [[30784   981]\n",
      " [  851 23049]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31765\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9691169526208091\n",
      "Sensitivity:  0.9643933054393306\n",
      "TP;  23049\n",
      "FP;  981\n",
      "TN;  30784\n",
      "FN;  851\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9479716862491466\n",
      "F1 score score:  0.9392821200939282\n",
      "Recall:  0.9372384937238494\n",
      "Precision:  0.9413346780971592\n",
      "Confusion matrix: \n",
      " [[30366  1396]\n",
      " [ 1500 22400]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9560481078017757\n",
      "Sensitivity:  0.9372384937238494\n",
      "TP;  22400\n",
      "FP;  1396\n",
      "TN;  30366\n",
      "FN;  1500\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9486903093672523\n",
      "F1 score score:  0.9400755350398656\n",
      "Recall:  0.9373221757322175\n",
      "Precision:  0.9428451178451178\n",
      "Confusion matrix: \n",
      " [[30404  1358]\n",
      " [ 1498 22402]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9572445060134752\n",
      "Sensitivity:  0.9373221757322175\n",
      "TP;  22402\n",
      "FP;  1358\n",
      "TN;  30404\n",
      "FN;  1498\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9504509360066113\n",
      "F1 score score:  0.9423422670067317\n",
      "Recall:  0.9430125523012552\n",
      "Precision:  0.9416729339015626\n",
      "Confusion matrix: \n",
      " [[30366  1396]\n",
      " [ 1362 22538]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9560481078017757\n",
      "Sensitivity:  0.9430125523012552\n",
      "TP;  22538\n",
      "FP;  1396\n",
      "TN;  30366\n",
      "FN;  1362\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9427277953434895\n",
      "F1 score score:  0.9345299215509097\n",
      "Recall:  0.9520083682008368\n",
      "Precision:  0.9176816971848027\n",
      "Confusion matrix: \n",
      " [[29723  2041]\n",
      " [ 1147 22753]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     31764\n",
      "         1.0       0.92      0.95      0.93     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.935744868404483\n",
      "Sensitivity:  0.9520083682008368\n",
      "TP;  22753\n",
      "FP;  2041\n",
      "TN;  29723\n",
      "FN;  1147\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9430691290600748\n",
      "F1 score score:  0.9342299151152896\n",
      "Recall:  0.9417154811715481\n",
      "Precision:  0.9268624140345098\n",
      "Confusion matrix: \n",
      " [[29988  1776]\n",
      " [ 1393 22507]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     31764\n",
      "         1.0       0.93      0.94      0.93     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.944087646392142\n",
      "Sensitivity:  0.9417154811715481\n",
      "TP;  22507\n",
      "FP;  1776\n",
      "TN;  29988\n",
      "FN;  1393\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.943033199195171\n",
      "F1 score score:  0.9350750394136075\n",
      "Recall:  0.955439330543933\n",
      "Precision:  0.9155607233070046\n",
      "Confusion matrix: \n",
      " [[29658  2106]\n",
      " [ 1065 22835]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9336985266339252\n",
      "Sensitivity:  0.955439330543933\n",
      "TP;  22835\n",
      "FP;  2106\n",
      "TN;  29658\n",
      "FN;  1065\n"
     ]
    }
   ],
   "source": [
    "all_scores = [evaluate_models(test_df, model_preds, model_name) for model_name, model_preds in predictions.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5f50432",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:08:05.161872Z",
     "start_time": "2021-10-15T06:08:05.090867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9506512171023085,\n",
       "  0.9453909309583921,\n",
       "  0.9948953974895397,\n",
       "  0.9005794796045904,\n",
       "  0.9173618762789233,\n",
       "  0.9948953974895397,\n",
       "  29140,\n",
       "  2625,\n",
       "  122,\n",
       "  23778),\n",
       " (0.9673942333602803,\n",
       "  0.9626996033621735,\n",
       "  0.98,\n",
       "  0.9459994345490529,\n",
       "  0.9579096489847316,\n",
       "  0.98,\n",
       "  30428,\n",
       "  1337,\n",
       "  478,\n",
       "  23422),\n",
       " (0.9482950666522942,\n",
       "  0.9415634517766497,\n",
       "  0.9701255230125523,\n",
       "  0.9146351084812623,\n",
       "  0.9318682702600591,\n",
       "  0.9701255230125523,\n",
       "  29598,\n",
       "  2164,\n",
       "  714,\n",
       "  23186),\n",
       " (0.9493370701735475,\n",
       "  0.942177568177158,\n",
       "  0.9612970711297071,\n",
       "  0.9238037796542018,\n",
       "  0.9403375102323531,\n",
       "  0.9612970711297071,\n",
       "  29867,\n",
       "  1895,\n",
       "  925,\n",
       "  22975),\n",
       " (0.9473608565987568,\n",
       "  0.940831987075929,\n",
       "  0.9746861924686192,\n",
       "  0.9092505854800936,\n",
       "  0.9267993199420691,\n",
       "  0.9746861924686192,\n",
       "  29437,\n",
       "  2325,\n",
       "  605,\n",
       "  23295),\n",
       " (0.9337812589824662,\n",
       "  0.927231807951988,\n",
       "  0.9825941422594142,\n",
       "  0.8777752859385513,\n",
       "  0.8970532678503966,\n",
       "  0.9825941422594142,\n",
       "  28494,\n",
       "  3270,\n",
       "  416,\n",
       "  23484),\n",
       " (0.9338351537798217,\n",
       "  0.9273613001203084,\n",
       "  0.9836820083682009,\n",
       "  0.8771406185874715,\n",
       "  0.8963291776854301,\n",
       "  0.9836820083682009,\n",
       "  28471,\n",
       "  3293,\n",
       "  390,\n",
       "  23510),\n",
       " (0.9450273066973268,\n",
       "  0.9383809907370116,\n",
       "  0.9748953974895398,\n",
       "  0.9045031055900621,\n",
       "  0.9225538345296562,\n",
       "  0.9748953974895398,\n",
       "  29304,\n",
       "  2460,\n",
       "  600,\n",
       "  23300),\n",
       " (0.9706997215485493,\n",
       "  0.965990366369873,\n",
       "  0.969163179916318,\n",
       "  0.9628382591345555,\n",
       "  0.9718558161498505,\n",
       "  0.969163179916318,\n",
       "  30871,\n",
       "  894,\n",
       "  737,\n",
       "  23163),\n",
       " (0.9700350309889517,\n",
       "  0.9651861746535315,\n",
       "  0.9674476987447699,\n",
       "  0.9629351990671331,\n",
       "  0.9719817409098064,\n",
       "  0.9674476987447699,\n",
       "  30875,\n",
       "  890,\n",
       "  778,\n",
       "  23122),\n",
       " (0.9595077696937034,\n",
       "  0.9530122993537629,\n",
       "  0.9564016736401674,\n",
       "  0.9496468633153303,\n",
       "  0.9618447977333543,\n",
       "  0.9564016736401674,\n",
       "  30553,\n",
       "  1212,\n",
       "  1042,\n",
       "  22858),\n",
       " (0.9536128777262765,\n",
       "  0.9459131090535842,\n",
       "  0.9446861924686193,\n",
       "  0.9471432167128114,\n",
       "  0.9603299540331214,\n",
       "  0.9446861924686193,\n",
       "  30502,\n",
       "  1260,\n",
       "  1322,\n",
       "  22578),\n",
       " (0.9498401063562215,\n",
       "  0.9410472972972973,\n",
       "  0.9323849372384937,\n",
       "  0.9498721227621484,\n",
       "  0.9629746237642466,\n",
       "  0.9323849372384937,\n",
       "  30586,\n",
       "  1176,\n",
       "  1616,\n",
       "  22284),\n",
       " (0.9523193561136861,\n",
       "  0.943690061953662,\n",
       "  0.9305020920502092,\n",
       "  0.9572572314049587,\n",
       "  0.9687362256784837,\n",
       "  0.9305020920502092,\n",
       "  30769,\n",
       "  993,\n",
       "  1661,\n",
       "  22239),\n",
       " (0.9466082207530899,\n",
       "  0.938093651058157,\n",
       "  0.9421757322175732,\n",
       "  0.9340467894474863,\n",
       "  0.9499433320740461,\n",
       "  0.9421757322175732,\n",
       "  30174,\n",
       "  1590,\n",
       "  1382,\n",
       "  22518),\n",
       " (0.9445242885886749,\n",
       "  0.9359016937894388,\n",
       "  0.9432635983263599,\n",
       "  0.9286538144669633,\n",
       "  0.9454728623599042,\n",
       "  0.9432635983263599,\n",
       "  30032,\n",
       "  1732,\n",
       "  1356,\n",
       "  22544),\n",
       " (0.9481172750790458,\n",
       "  0.9391333670544596,\n",
       "  0.9322175732217574,\n",
       "  0.9461525394937998,\n",
       "  0.9600805943835788,\n",
       "  0.9322175732217574,\n",
       "  30496,\n",
       "  1268,\n",
       "  1620,\n",
       "  22280),\n",
       " (0.9682385700170664,\n",
       "  0.9633742127941665,\n",
       "  0.972887029288703,\n",
       "  0.954045626128344,\n",
       "  0.9647410672123407,\n",
       "  0.972887029288703,\n",
       "  30645,\n",
       "  1120,\n",
       "  648,\n",
       "  23252),\n",
       " (0.9484028601200101,\n",
       "  0.9383981811162113,\n",
       "  0.9152719665271967,\n",
       "  0.9627233518176217,\n",
       "  0.9733329135444871,\n",
       "  0.9152719665271967,\n",
       "  30915,\n",
       "  847,\n",
       "  2025,\n",
       "  21875),\n",
       " (0.9505587294743272,\n",
       "  0.9415363698164514,\n",
       "  0.9271966527196652,\n",
       "  0.9563266010702572,\n",
       "  0.9681380265726339,\n",
       "  0.9271966527196652,\n",
       "  30750,\n",
       "  1012,\n",
       "  1740,\n",
       "  22160),\n",
       " (0.9524990118932126,\n",
       "  0.9456056616194866,\n",
       "  0.9615899581589958,\n",
       "  0.9301440828881334,\n",
       "  0.9456583338580694,\n",
       "  0.9615899581589958,\n",
       "  30036,\n",
       "  1726,\n",
       "  918,\n",
       "  22982),\n",
       " (0.9446859729807416,\n",
       "  0.9369587027292643,\n",
       "  0.9573640167364017,\n",
       "  0.9174050759793112,\n",
       "  0.9351467069638585,\n",
       "  0.9573640167364017,\n",
       "  29704,\n",
       "  2060,\n",
       "  1019,\n",
       "  22881),\n",
       " (0.9426918654785859,\n",
       "  0.9354721255765029,\n",
       "  0.967489539748954,\n",
       "  0.9055059523809523,\n",
       "  0.924033497040675,\n",
       "  0.967489539748954,\n",
       "  29351,\n",
       "  2413,\n",
       "  777,\n",
       "  23123),\n",
       " (0.946482466225927,\n",
       "  0.9383344718375458,\n",
       "  0.948326359832636,\n",
       "  0.928550944323815,\n",
       "  0.9450950761868783,\n",
       "  0.948326359832636,\n",
       "  30020,\n",
       "  1744,\n",
       "  1235,\n",
       "  22665),\n",
       " (0.9689571544058205,\n",
       "  0.9640599001663894,\n",
       "  0.9697071129707113,\n",
       "  0.9584780810587262,\n",
       "  0.9683928852510625,\n",
       "  0.9697071129707113,\n",
       "  30761,\n",
       "  1004,\n",
       "  724,\n",
       "  23176),\n",
       " (0.9697296326237312,\n",
       "  0.9648379624799148,\n",
       "  0.9672803347280334,\n",
       "  0.9624078930935431,\n",
       "  0.9715724854399497,\n",
       "  0.9672803347280334,\n",
       "  30862,\n",
       "  903,\n",
       "  782,\n",
       "  23118),\n",
       " (0.9522474938018756,\n",
       "  0.9437126762949473,\n",
       "  0.9323012552301255,\n",
       "  0.955406911928651,\n",
       "  0.9672564699955922,\n",
       "  0.9323012552301255,\n",
       "  30722,\n",
       "  1040,\n",
       "  1618,\n",
       "  22282),\n",
       " (0.951169559124717,\n",
       "  0.9428343078282084,\n",
       "  0.9378242677824268,\n",
       "  0.9478981645944345,\n",
       "  0.9612115106101631,\n",
       "  0.9378242677824268,\n",
       "  30530,\n",
       "  1232,\n",
       "  1486,\n",
       "  22414),\n",
       " (0.9545470877798139,\n",
       "  0.9464572928130027,\n",
       "  0.9356066945606695,\n",
       "  0.9575625214114423,\n",
       "  0.9687991940054153,\n",
       "  0.9356066945606695,\n",
       "  30771,\n",
       "  991,\n",
       "  1539,\n",
       "  22361),\n",
       " (0.9471292037941937,\n",
       "  0.9390089735353242,\n",
       "  0.947907949790795,\n",
       "  0.930275530735433,\n",
       "  0.9465432565168115,\n",
       "  0.947907949790795,\n",
       "  30066,\n",
       "  1698,\n",
       "  1245,\n",
       "  22655),\n",
       " (0.9449554469675194,\n",
       "  0.9367125211715619,\n",
       "  0.948744769874477,\n",
       "  0.9249816431426939,\n",
       "  0.9421042689837552,\n",
       "  0.948744769874477,\n",
       "  29925,\n",
       "  1839,\n",
       "  1225,\n",
       "  22675),\n",
       " (0.9485125035929864,\n",
       "  0.9405961115947437,\n",
       "  0.9493723849372385,\n",
       "  0.9319806128316767,\n",
       "  0.9478655081224027,\n",
       "  0.9493723849372385,\n",
       "  30108,\n",
       "  1656,\n",
       "  1210,\n",
       "  22690),\n",
       " (0.9702146770861403,\n",
       "  0.9653428093645484,\n",
       "  0.9661506276150628,\n",
       "  0.9645363408521304,\n",
       "  0.9732724696993547,\n",
       "  0.9661506276150628,\n",
       "  30916,\n",
       "  849,\n",
       "  809,\n",
       "  23091),\n",
       " (0.97037635857361,\n",
       "  0.9654507741624588,\n",
       "  0.9640167364016736,\n",
       "  0.966889084728692,\n",
       "  0.9751613410986936,\n",
       "  0.9640167364016736,\n",
       "  30976,\n",
       "  789,\n",
       "  860,\n",
       "  23040),\n",
       " (0.9539721892853293,\n",
       "  0.9463455497382198,\n",
       "  0.9453556485355649,\n",
       "  0.9473375262054508,\n",
       "  0.9604558906869844,\n",
       "  0.9453556485355649,\n",
       "  30506,\n",
       "  1256,\n",
       "  1306,\n",
       "  22594),\n",
       " (0.9499838309798426,\n",
       "  0.9416596814752725,\n",
       "  0.9400836820083682,\n",
       "  0.9432409739714526,\n",
       "  0.9574334109942699,\n",
       "  0.9400836820083682,\n",
       "  30410,\n",
       "  1352,\n",
       "  1432,\n",
       "  22468),\n",
       " (0.9540440515971399,\n",
       "  0.9468434395910393,\n",
       "  0.9532217573221757,\n",
       "  0.9405499133019569,\n",
       "  0.9546628046092815,\n",
       "  0.9532217573221757,\n",
       "  30322,\n",
       "  1440,\n",
       "  1118,\n",
       "  22782),\n",
       " (0.9480993101465939,\n",
       "  0.9406447106198509,\n",
       "  0.9578242677824268,\n",
       "  0.924070560691075,\n",
       "  0.9407820173781639,\n",
       "  0.9578242677824268,\n",
       "  29883,\n",
       "  1881,\n",
       "  1008,\n",
       "  22892),\n",
       " (0.9436080770336304,\n",
       "  0.935803832545964,\n",
       "  0.9572803347280334,\n",
       "  0.9152698323798856,\n",
       "  0.9333207404608991,\n",
       "  0.9572803347280334,\n",
       "  29646,\n",
       "  2118,\n",
       "  1021,\n",
       "  22879),\n",
       " (0.9475783271054901,\n",
       "  0.9401263952724885,\n",
       "  0.9585355648535565,\n",
       "  0.9224110162667096,\n",
       "  0.9393338370482307,\n",
       "  0.9585355648535565,\n",
       "  29837,\n",
       "  1927,\n",
       "  991,\n",
       "  22909),\n",
       " (0.9665319320937753,\n",
       "  0.9615376674855998,\n",
       "  0.9743514644351464,\n",
       "  0.9490565268777764,\n",
       "  0.960648512513773,\n",
       "  0.9743514644351464,\n",
       "  30515,\n",
       "  1250,\n",
       "  613,\n",
       "  23287),\n",
       " (0.9670888349950597,\n",
       "  0.9617775923221364,\n",
       "  0.9643933054393306,\n",
       "  0.9591760299625468,\n",
       "  0.9691169526208091,\n",
       "  0.9643933054393306,\n",
       "  30784,\n",
       "  981,\n",
       "  851,\n",
       "  23049),\n",
       " (0.9479716862491466,\n",
       "  0.9392821200939282,\n",
       "  0.9372384937238494,\n",
       "  0.9413346780971592,\n",
       "  0.9560481078017757,\n",
       "  0.9372384937238494,\n",
       "  30366,\n",
       "  1396,\n",
       "  1500,\n",
       "  22400),\n",
       " (0.9486903093672523,\n",
       "  0.9400755350398656,\n",
       "  0.9373221757322175,\n",
       "  0.9428451178451178,\n",
       "  0.9572445060134752,\n",
       "  0.9373221757322175,\n",
       "  30404,\n",
       "  1358,\n",
       "  1498,\n",
       "  22402),\n",
       " (0.9504509360066113,\n",
       "  0.9423422670067317,\n",
       "  0.9430125523012552,\n",
       "  0.9416729339015626,\n",
       "  0.9560481078017757,\n",
       "  0.9430125523012552,\n",
       "  30366,\n",
       "  1396,\n",
       "  1362,\n",
       "  22538),\n",
       " (0.9427277953434895,\n",
       "  0.9345299215509097,\n",
       "  0.9520083682008368,\n",
       "  0.9176816971848027,\n",
       "  0.935744868404483,\n",
       "  0.9520083682008368,\n",
       "  29723,\n",
       "  2041,\n",
       "  1147,\n",
       "  22753),\n",
       " (0.9430691290600748,\n",
       "  0.9342299151152896,\n",
       "  0.9417154811715481,\n",
       "  0.9268624140345098,\n",
       "  0.944087646392142,\n",
       "  0.9417154811715481,\n",
       "  29988,\n",
       "  1776,\n",
       "  1393,\n",
       "  22507),\n",
       " (0.943033199195171,\n",
       "  0.9350750394136075,\n",
       "  0.955439330543933,\n",
       "  0.9155607233070046,\n",
       "  0.9336985266339252,\n",
       "  0.955439330543933,\n",
       "  29658,\n",
       "  2106,\n",
       "  1065,\n",
       "  22835)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd812e5d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:15:54.507873Z",
     "start_time": "2021-10-15T06:15:54.407867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>rec</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>sen</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_model_comp_ws_3_transform_dct</td>\n",
       "      <td>0.950651</td>\n",
       "      <td>0.945391</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.900579</td>\n",
       "      <td>0.917362</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>29140</td>\n",
       "      <td>2625</td>\n",
       "      <td>122</td>\n",
       "      <td>23778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_model_comp_ws_3_transform_None</td>\n",
       "      <td>0.967394</td>\n",
       "      <td>0.962700</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.945999</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>30428</td>\n",
       "      <td>1337</td>\n",
       "      <td>478</td>\n",
       "      <td>23422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_model_comp_ws_6_transform_dct</td>\n",
       "      <td>0.948295</td>\n",
       "      <td>0.941563</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>0.914635</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>29598</td>\n",
       "      <td>2164</td>\n",
       "      <td>714</td>\n",
       "      <td>23186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_model_comp_ws_6_transform_fft</td>\n",
       "      <td>0.949337</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>0.923804</td>\n",
       "      <td>0.940338</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>29867</td>\n",
       "      <td>1895</td>\n",
       "      <td>925</td>\n",
       "      <td>22975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_model_comp_ws_6_transform_None</td>\n",
       "      <td>0.947361</td>\n",
       "      <td>0.940832</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.909251</td>\n",
       "      <td>0.926799</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>29437</td>\n",
       "      <td>2325</td>\n",
       "      <td>605</td>\n",
       "      <td>23295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn_model_comp_ws_7_transform_dct</td>\n",
       "      <td>0.933781</td>\n",
       "      <td>0.927232</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.897053</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>28494</td>\n",
       "      <td>3270</td>\n",
       "      <td>416</td>\n",
       "      <td>23484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cnn_model_comp_ws_7_transform_fft</td>\n",
       "      <td>0.933835</td>\n",
       "      <td>0.927361</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>0.877141</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>28471</td>\n",
       "      <td>3293</td>\n",
       "      <td>390</td>\n",
       "      <td>23510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cnn_model_comp_ws_7_transform_None</td>\n",
       "      <td>0.945027</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.904503</td>\n",
       "      <td>0.922554</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>29304</td>\n",
       "      <td>2460</td>\n",
       "      <td>600</td>\n",
       "      <td>23300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnn_model_ws_3_transform_dct</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.965990</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.971856</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>30871</td>\n",
       "      <td>894</td>\n",
       "      <td>737</td>\n",
       "      <td>23163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn_model_ws_3_transform_None</td>\n",
       "      <td>0.970035</td>\n",
       "      <td>0.965186</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>0.962935</td>\n",
       "      <td>0.971982</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>30875</td>\n",
       "      <td>890</td>\n",
       "      <td>778</td>\n",
       "      <td>23122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnn_model_ws_5_transform_None</td>\n",
       "      <td>0.959508</td>\n",
       "      <td>0.953012</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.949647</td>\n",
       "      <td>0.961845</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>30553</td>\n",
       "      <td>1212</td>\n",
       "      <td>1042</td>\n",
       "      <td>22858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnn_model_ws_6_transform_dct</td>\n",
       "      <td>0.953613</td>\n",
       "      <td>0.945913</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.947143</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>30502</td>\n",
       "      <td>1260</td>\n",
       "      <td>1322</td>\n",
       "      <td>22578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnn_model_ws_6_transform_fft</td>\n",
       "      <td>0.949840</td>\n",
       "      <td>0.941047</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>0.949872</td>\n",
       "      <td>0.962975</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>30586</td>\n",
       "      <td>1176</td>\n",
       "      <td>1616</td>\n",
       "      <td>22284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cnn_model_ws_6_transform_None</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>0.943690</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>0.957257</td>\n",
       "      <td>0.968736</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>30769</td>\n",
       "      <td>993</td>\n",
       "      <td>1661</td>\n",
       "      <td>22239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cnn_model_ws_7_transform_dct</td>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.949943</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>30174</td>\n",
       "      <td>1590</td>\n",
       "      <td>1382</td>\n",
       "      <td>22518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnn_model_ws_7_transform_fft</td>\n",
       "      <td>0.944524</td>\n",
       "      <td>0.935902</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>0.928654</td>\n",
       "      <td>0.945473</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>30032</td>\n",
       "      <td>1732</td>\n",
       "      <td>1356</td>\n",
       "      <td>22544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cnn_model_ws_7_transform_None</td>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.939133</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>0.946153</td>\n",
       "      <td>0.960081</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>30496</td>\n",
       "      <td>1268</td>\n",
       "      <td>1620</td>\n",
       "      <td>22280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cnn_two_channels_model_ws_3_transform_None</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.963374</td>\n",
       "      <td>0.972887</td>\n",
       "      <td>0.954046</td>\n",
       "      <td>0.964741</td>\n",
       "      <td>0.972887</td>\n",
       "      <td>30645</td>\n",
       "      <td>1120</td>\n",
       "      <td>648</td>\n",
       "      <td>23252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_dct</td>\n",
       "      <td>0.948403</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>30915</td>\n",
       "      <td>847</td>\n",
       "      <td>2025</td>\n",
       "      <td>21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_fft</td>\n",
       "      <td>0.950559</td>\n",
       "      <td>0.941536</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>0.956327</td>\n",
       "      <td>0.968138</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>30750</td>\n",
       "      <td>1012</td>\n",
       "      <td>1740</td>\n",
       "      <td>22160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_None</td>\n",
       "      <td>0.952499</td>\n",
       "      <td>0.945606</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>0.930144</td>\n",
       "      <td>0.945658</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>30036</td>\n",
       "      <td>1726</td>\n",
       "      <td>918</td>\n",
       "      <td>22982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnn_two_channels_model_ws_7_transform_dct</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.936959</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.917405</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>29704</td>\n",
       "      <td>2060</td>\n",
       "      <td>1019</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnn_two_channels_model_ws_7_transform_fft</td>\n",
       "      <td>0.942692</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>0.905506</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>29351</td>\n",
       "      <td>2413</td>\n",
       "      <td>777</td>\n",
       "      <td>23123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnn_two_channels_model_ws_7_transform_None</td>\n",
       "      <td>0.946482</td>\n",
       "      <td>0.938334</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>0.928551</td>\n",
       "      <td>0.945095</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>30020</td>\n",
       "      <td>1744</td>\n",
       "      <td>1235</td>\n",
       "      <td>22665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>multi_cnn_model_ws_3_transform_dct</td>\n",
       "      <td>0.968957</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>0.958478</td>\n",
       "      <td>0.968393</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>30761</td>\n",
       "      <td>1004</td>\n",
       "      <td>724</td>\n",
       "      <td>23176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>multi_cnn_model_ws_3_transform_None</td>\n",
       "      <td>0.969730</td>\n",
       "      <td>0.964838</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.962408</td>\n",
       "      <td>0.971572</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>30862</td>\n",
       "      <td>903</td>\n",
       "      <td>782</td>\n",
       "      <td>23118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>multi_cnn_model_ws_6_transform_dct</td>\n",
       "      <td>0.952247</td>\n",
       "      <td>0.943713</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.955407</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>30722</td>\n",
       "      <td>1040</td>\n",
       "      <td>1618</td>\n",
       "      <td>22282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>multi_cnn_model_ws_6_transform_fft</td>\n",
       "      <td>0.951170</td>\n",
       "      <td>0.942834</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.947898</td>\n",
       "      <td>0.961212</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>30530</td>\n",
       "      <td>1232</td>\n",
       "      <td>1486</td>\n",
       "      <td>22414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>multi_cnn_model_ws_6_transform_None</td>\n",
       "      <td>0.954547</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.968799</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>30771</td>\n",
       "      <td>991</td>\n",
       "      <td>1539</td>\n",
       "      <td>22361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>multi_cnn_model_ws_7_transform_dct</td>\n",
       "      <td>0.947129</td>\n",
       "      <td>0.939009</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>0.930276</td>\n",
       "      <td>0.946543</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>30066</td>\n",
       "      <td>1698</td>\n",
       "      <td>1245</td>\n",
       "      <td>22655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>multi_cnn_model_ws_7_transform_fft</td>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.936713</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>0.924982</td>\n",
       "      <td>0.942104</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>29925</td>\n",
       "      <td>1839</td>\n",
       "      <td>1225</td>\n",
       "      <td>22675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>multi_cnn_model_ws_7_transform_None</td>\n",
       "      <td>0.948513</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>0.931981</td>\n",
       "      <td>0.947866</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>30108</td>\n",
       "      <td>1656</td>\n",
       "      <td>1210</td>\n",
       "      <td>22690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>multi_lstm_model_ws_3_transform_dct</td>\n",
       "      <td>0.970215</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>0.973272</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>30916</td>\n",
       "      <td>849</td>\n",
       "      <td>809</td>\n",
       "      <td>23091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>multi_lstm_model_ws_3_transform_None</td>\n",
       "      <td>0.970376</td>\n",
       "      <td>0.965451</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>0.966889</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>30976</td>\n",
       "      <td>789</td>\n",
       "      <td>860</td>\n",
       "      <td>23040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>multi_lstm_model_ws_6_transform_dct</td>\n",
       "      <td>0.953972</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>0.947338</td>\n",
       "      <td>0.960456</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>30506</td>\n",
       "      <td>1256</td>\n",
       "      <td>1306</td>\n",
       "      <td>22594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>multi_lstm_model_ws_6_transform_fft</td>\n",
       "      <td>0.949984</td>\n",
       "      <td>0.941660</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.943241</td>\n",
       "      <td>0.957433</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>30410</td>\n",
       "      <td>1352</td>\n",
       "      <td>1432</td>\n",
       "      <td>22468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>multi_lstm_model_ws_6_transform_None</td>\n",
       "      <td>0.954044</td>\n",
       "      <td>0.946843</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>0.940550</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>30322</td>\n",
       "      <td>1440</td>\n",
       "      <td>1118</td>\n",
       "      <td>22782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>multi_lstm_model_ws_7_transform_dct</td>\n",
       "      <td>0.948099</td>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>0.924071</td>\n",
       "      <td>0.940782</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>29883</td>\n",
       "      <td>1881</td>\n",
       "      <td>1008</td>\n",
       "      <td>22892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>multi_lstm_model_ws_7_transform_fft</td>\n",
       "      <td>0.943608</td>\n",
       "      <td>0.935804</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>0.933321</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>29646</td>\n",
       "      <td>2118</td>\n",
       "      <td>1021</td>\n",
       "      <td>22879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>multi_lstm_model_ws_7_transform_None</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>0.922411</td>\n",
       "      <td>0.939334</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>29837</td>\n",
       "      <td>1927</td>\n",
       "      <td>991</td>\n",
       "      <td>22909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>uni_lstm_model_ws_3_transform_dct</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>0.949057</td>\n",
       "      <td>0.960649</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>30515</td>\n",
       "      <td>1250</td>\n",
       "      <td>613</td>\n",
       "      <td>23287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>uni_lstm_model_ws_3_transform_None</td>\n",
       "      <td>0.967089</td>\n",
       "      <td>0.961778</td>\n",
       "      <td>0.964393</td>\n",
       "      <td>0.959176</td>\n",
       "      <td>0.969117</td>\n",
       "      <td>0.964393</td>\n",
       "      <td>30784</td>\n",
       "      <td>981</td>\n",
       "      <td>851</td>\n",
       "      <td>23049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>uni_lstm_model_ws_6_transform_dct</td>\n",
       "      <td>0.947972</td>\n",
       "      <td>0.939282</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.941335</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1500</td>\n",
       "      <td>22400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>uni_lstm_model_ws_6_transform_fft</td>\n",
       "      <td>0.948690</td>\n",
       "      <td>0.940076</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.942845</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>30404</td>\n",
       "      <td>1358</td>\n",
       "      <td>1498</td>\n",
       "      <td>22402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>uni_lstm_model_ws_6_transform_None</td>\n",
       "      <td>0.950451</td>\n",
       "      <td>0.942342</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1362</td>\n",
       "      <td>22538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>uni_lstm_model_ws_7_transform_dct</td>\n",
       "      <td>0.942728</td>\n",
       "      <td>0.934530</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>0.917682</td>\n",
       "      <td>0.935745</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>29723</td>\n",
       "      <td>2041</td>\n",
       "      <td>1147</td>\n",
       "      <td>22753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>uni_lstm_model_ws_7_transform_fft</td>\n",
       "      <td>0.943069</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>0.926862</td>\n",
       "      <td>0.944088</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>29988</td>\n",
       "      <td>1776</td>\n",
       "      <td>1393</td>\n",
       "      <td>22507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>uni_lstm_model_ws_7_transform_None</td>\n",
       "      <td>0.943033</td>\n",
       "      <td>0.935075</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>0.915561</td>\n",
       "      <td>0.933699</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>29658</td>\n",
       "      <td>2106</td>\n",
       "      <td>1065</td>\n",
       "      <td>22835</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model_name       acc        f1       rec  \\\n",
       "0            cnn_model_comp_ws_3_transform_dct  0.950651  0.945391  0.994895   \n",
       "1           cnn_model_comp_ws_3_transform_None  0.967394  0.962700  0.980000   \n",
       "2            cnn_model_comp_ws_6_transform_dct  0.948295  0.941563  0.970126   \n",
       "3            cnn_model_comp_ws_6_transform_fft  0.949337  0.942178  0.961297   \n",
       "4           cnn_model_comp_ws_6_transform_None  0.947361  0.940832  0.974686   \n",
       "5            cnn_model_comp_ws_7_transform_dct  0.933781  0.927232  0.982594   \n",
       "6            cnn_model_comp_ws_7_transform_fft  0.933835  0.927361  0.983682   \n",
       "7           cnn_model_comp_ws_7_transform_None  0.945027  0.938381  0.974895   \n",
       "8                 cnn_model_ws_3_transform_dct  0.970700  0.965990  0.969163   \n",
       "9                cnn_model_ws_3_transform_None  0.970035  0.965186  0.967448   \n",
       "10               cnn_model_ws_5_transform_None  0.959508  0.953012  0.956402   \n",
       "11                cnn_model_ws_6_transform_dct  0.953613  0.945913  0.944686   \n",
       "12                cnn_model_ws_6_transform_fft  0.949840  0.941047  0.932385   \n",
       "13               cnn_model_ws_6_transform_None  0.952319  0.943690  0.930502   \n",
       "14                cnn_model_ws_7_transform_dct  0.946608  0.938094  0.942176   \n",
       "15                cnn_model_ws_7_transform_fft  0.944524  0.935902  0.943264   \n",
       "16               cnn_model_ws_7_transform_None  0.948117  0.939133  0.932218   \n",
       "17  cnn_two_channels_model_ws_3_transform_None  0.968239  0.963374  0.972887   \n",
       "18   cnn_two_channels_model_ws_6_transform_dct  0.948403  0.938398  0.915272   \n",
       "19   cnn_two_channels_model_ws_6_transform_fft  0.950559  0.941536  0.927197   \n",
       "20  cnn_two_channels_model_ws_6_transform_None  0.952499  0.945606  0.961590   \n",
       "21   cnn_two_channels_model_ws_7_transform_dct  0.944686  0.936959  0.957364   \n",
       "22   cnn_two_channels_model_ws_7_transform_fft  0.942692  0.935472  0.967490   \n",
       "23  cnn_two_channels_model_ws_7_transform_None  0.946482  0.938334  0.948326   \n",
       "24          multi_cnn_model_ws_3_transform_dct  0.968957  0.964060  0.969707   \n",
       "25         multi_cnn_model_ws_3_transform_None  0.969730  0.964838  0.967280   \n",
       "26          multi_cnn_model_ws_6_transform_dct  0.952247  0.943713  0.932301   \n",
       "27          multi_cnn_model_ws_6_transform_fft  0.951170  0.942834  0.937824   \n",
       "28         multi_cnn_model_ws_6_transform_None  0.954547  0.946457  0.935607   \n",
       "29          multi_cnn_model_ws_7_transform_dct  0.947129  0.939009  0.947908   \n",
       "30          multi_cnn_model_ws_7_transform_fft  0.944955  0.936713  0.948745   \n",
       "31         multi_cnn_model_ws_7_transform_None  0.948513  0.940596  0.949372   \n",
       "32         multi_lstm_model_ws_3_transform_dct  0.970215  0.965343  0.966151   \n",
       "33        multi_lstm_model_ws_3_transform_None  0.970376  0.965451  0.964017   \n",
       "34         multi_lstm_model_ws_6_transform_dct  0.953972  0.946346  0.945356   \n",
       "35         multi_lstm_model_ws_6_transform_fft  0.949984  0.941660  0.940084   \n",
       "36        multi_lstm_model_ws_6_transform_None  0.954044  0.946843  0.953222   \n",
       "37         multi_lstm_model_ws_7_transform_dct  0.948099  0.940645  0.957824   \n",
       "38         multi_lstm_model_ws_7_transform_fft  0.943608  0.935804  0.957280   \n",
       "39        multi_lstm_model_ws_7_transform_None  0.947578  0.940126  0.958536   \n",
       "40           uni_lstm_model_ws_3_transform_dct  0.966532  0.961538  0.974351   \n",
       "41          uni_lstm_model_ws_3_transform_None  0.967089  0.961778  0.964393   \n",
       "42           uni_lstm_model_ws_6_transform_dct  0.947972  0.939282  0.937238   \n",
       "43           uni_lstm_model_ws_6_transform_fft  0.948690  0.940076  0.937322   \n",
       "44          uni_lstm_model_ws_6_transform_None  0.950451  0.942342  0.943013   \n",
       "45           uni_lstm_model_ws_7_transform_dct  0.942728  0.934530  0.952008   \n",
       "46           uni_lstm_model_ws_7_transform_fft  0.943069  0.934230  0.941715   \n",
       "47          uni_lstm_model_ws_7_transform_None  0.943033  0.935075  0.955439   \n",
       "\n",
       "         pre       spe       sen     tn    fp    fn     tp  \n",
       "0   0.900579  0.917362  0.994895  29140  2625   122  23778  \n",
       "1   0.945999  0.957910  0.980000  30428  1337   478  23422  \n",
       "2   0.914635  0.931868  0.970126  29598  2164   714  23186  \n",
       "3   0.923804  0.940338  0.961297  29867  1895   925  22975  \n",
       "4   0.909251  0.926799  0.974686  29437  2325   605  23295  \n",
       "5   0.877775  0.897053  0.982594  28494  3270   416  23484  \n",
       "6   0.877141  0.896329  0.983682  28471  3293   390  23510  \n",
       "7   0.904503  0.922554  0.974895  29304  2460   600  23300  \n",
       "8   0.962838  0.971856  0.969163  30871   894   737  23163  \n",
       "9   0.962935  0.971982  0.967448  30875   890   778  23122  \n",
       "10  0.949647  0.961845  0.956402  30553  1212  1042  22858  \n",
       "11  0.947143  0.960330  0.944686  30502  1260  1322  22578  \n",
       "12  0.949872  0.962975  0.932385  30586  1176  1616  22284  \n",
       "13  0.957257  0.968736  0.930502  30769   993  1661  22239  \n",
       "14  0.934047  0.949943  0.942176  30174  1590  1382  22518  \n",
       "15  0.928654  0.945473  0.943264  30032  1732  1356  22544  \n",
       "16  0.946153  0.960081  0.932218  30496  1268  1620  22280  \n",
       "17  0.954046  0.964741  0.972887  30645  1120   648  23252  \n",
       "18  0.962723  0.973333  0.915272  30915   847  2025  21875  \n",
       "19  0.956327  0.968138  0.927197  30750  1012  1740  22160  \n",
       "20  0.930144  0.945658  0.961590  30036  1726   918  22982  \n",
       "21  0.917405  0.935147  0.957364  29704  2060  1019  22881  \n",
       "22  0.905506  0.924033  0.967490  29351  2413   777  23123  \n",
       "23  0.928551  0.945095  0.948326  30020  1744  1235  22665  \n",
       "24  0.958478  0.968393  0.969707  30761  1004   724  23176  \n",
       "25  0.962408  0.971572  0.967280  30862   903   782  23118  \n",
       "26  0.955407  0.967256  0.932301  30722  1040  1618  22282  \n",
       "27  0.947898  0.961212  0.937824  30530  1232  1486  22414  \n",
       "28  0.957563  0.968799  0.935607  30771   991  1539  22361  \n",
       "29  0.930276  0.946543  0.947908  30066  1698  1245  22655  \n",
       "30  0.924982  0.942104  0.948745  29925  1839  1225  22675  \n",
       "31  0.931981  0.947866  0.949372  30108  1656  1210  22690  \n",
       "32  0.964536  0.973272  0.966151  30916   849   809  23091  \n",
       "33  0.966889  0.975161  0.964017  30976   789   860  23040  \n",
       "34  0.947338  0.960456  0.945356  30506  1256  1306  22594  \n",
       "35  0.943241  0.957433  0.940084  30410  1352  1432  22468  \n",
       "36  0.940550  0.954663  0.953222  30322  1440  1118  22782  \n",
       "37  0.924071  0.940782  0.957824  29883  1881  1008  22892  \n",
       "38  0.915270  0.933321  0.957280  29646  2118  1021  22879  \n",
       "39  0.922411  0.939334  0.958536  29837  1927   991  22909  \n",
       "40  0.949057  0.960649  0.974351  30515  1250   613  23287  \n",
       "41  0.959176  0.969117  0.964393  30784   981   851  23049  \n",
       "42  0.941335  0.956048  0.937238  30366  1396  1500  22400  \n",
       "43  0.942845  0.957245  0.937322  30404  1358  1498  22402  \n",
       "44  0.941673  0.956048  0.943013  30366  1396  1362  22538  \n",
       "45  0.917682  0.935745  0.952008  29723  2041  1147  22753  \n",
       "46  0.926862  0.944088  0.941715  29988  1776  1393  22507  \n",
       "47  0.915561  0.933699  0.955439  29658  2106  1065  22835  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores, columns = [\"model_name\", \"acc\", \"f1\", \"rec\", \"pre\", \"spe\", \"sen\", \"tn\", \"fp\", \"fn\", \"tp\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "944aab56",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:20:32.190870Z",
     "start_time": "2021-10-15T06:20:32.167874Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_ws = lambda x: re.search(r'_ws_(.*?)_transform', x).group(1)\n",
    "extract_transform = lambda x: re.search(r'transform_(.*)', x).group(1)\n",
    "extract_model = lambda x: re.search(r'(.*?)_ws', x).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a57dc68d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:20:32.777874Z",
     "start_time": "2021-10-15T06:20:32.757880Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df[\"window_size\"] = scores_df.model_name.apply(extract_ws)\n",
    "scores_df[\"transform\"] = scores_df.model_name.apply(extract_transform)\n",
    "scores_df[\"model\"] = scores_df.model_name.apply(extract_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1908aa5c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:20:34.096866Z",
     "start_time": "2021-10-15T06:20:33.974876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>rec</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>sen</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>window_size</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_model_comp_ws_3_transform_dct</td>\n",
       "      <td>0.950651</td>\n",
       "      <td>0.945391</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.900579</td>\n",
       "      <td>0.917362</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>29140</td>\n",
       "      <td>2625</td>\n",
       "      <td>122</td>\n",
       "      <td>23778</td>\n",
       "      <td>3</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_model_comp_ws_3_transform_None</td>\n",
       "      <td>0.967394</td>\n",
       "      <td>0.962700</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.945999</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>30428</td>\n",
       "      <td>1337</td>\n",
       "      <td>478</td>\n",
       "      <td>23422</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_model_comp_ws_6_transform_dct</td>\n",
       "      <td>0.948295</td>\n",
       "      <td>0.941563</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>0.914635</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>29598</td>\n",
       "      <td>2164</td>\n",
       "      <td>714</td>\n",
       "      <td>23186</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cnn_model_comp_ws_6_transform_fft</td>\n",
       "      <td>0.949337</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>0.923804</td>\n",
       "      <td>0.940338</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>29867</td>\n",
       "      <td>1895</td>\n",
       "      <td>925</td>\n",
       "      <td>22975</td>\n",
       "      <td>6</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_model_comp_ws_6_transform_None</td>\n",
       "      <td>0.947361</td>\n",
       "      <td>0.940832</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.909251</td>\n",
       "      <td>0.926799</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>29437</td>\n",
       "      <td>2325</td>\n",
       "      <td>605</td>\n",
       "      <td>23295</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cnn_model_comp_ws_7_transform_dct</td>\n",
       "      <td>0.933781</td>\n",
       "      <td>0.927232</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.897053</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>28494</td>\n",
       "      <td>3270</td>\n",
       "      <td>416</td>\n",
       "      <td>23484</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cnn_model_comp_ws_7_transform_fft</td>\n",
       "      <td>0.933835</td>\n",
       "      <td>0.927361</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>0.877141</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>28471</td>\n",
       "      <td>3293</td>\n",
       "      <td>390</td>\n",
       "      <td>23510</td>\n",
       "      <td>7</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>cnn_model_comp_ws_7_transform_None</td>\n",
       "      <td>0.945027</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.904503</td>\n",
       "      <td>0.922554</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>29304</td>\n",
       "      <td>2460</td>\n",
       "      <td>600</td>\n",
       "      <td>23300</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>cnn_model_ws_3_transform_dct</td>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.965990</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.971856</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>30871</td>\n",
       "      <td>894</td>\n",
       "      <td>737</td>\n",
       "      <td>23163</td>\n",
       "      <td>3</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>cnn_model_ws_3_transform_None</td>\n",
       "      <td>0.970035</td>\n",
       "      <td>0.965186</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>0.962935</td>\n",
       "      <td>0.971982</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>30875</td>\n",
       "      <td>890</td>\n",
       "      <td>778</td>\n",
       "      <td>23122</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>cnn_model_ws_5_transform_None</td>\n",
       "      <td>0.959508</td>\n",
       "      <td>0.953012</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.949647</td>\n",
       "      <td>0.961845</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>30553</td>\n",
       "      <td>1212</td>\n",
       "      <td>1042</td>\n",
       "      <td>22858</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>cnn_model_ws_6_transform_dct</td>\n",
       "      <td>0.953613</td>\n",
       "      <td>0.945913</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.947143</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>30502</td>\n",
       "      <td>1260</td>\n",
       "      <td>1322</td>\n",
       "      <td>22578</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cnn_model_ws_6_transform_fft</td>\n",
       "      <td>0.949840</td>\n",
       "      <td>0.941047</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>0.949872</td>\n",
       "      <td>0.962975</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>30586</td>\n",
       "      <td>1176</td>\n",
       "      <td>1616</td>\n",
       "      <td>22284</td>\n",
       "      <td>6</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>cnn_model_ws_6_transform_None</td>\n",
       "      <td>0.952319</td>\n",
       "      <td>0.943690</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>0.957257</td>\n",
       "      <td>0.968736</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>30769</td>\n",
       "      <td>993</td>\n",
       "      <td>1661</td>\n",
       "      <td>22239</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>cnn_model_ws_7_transform_dct</td>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.949943</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>30174</td>\n",
       "      <td>1590</td>\n",
       "      <td>1382</td>\n",
       "      <td>22518</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>cnn_model_ws_7_transform_fft</td>\n",
       "      <td>0.944524</td>\n",
       "      <td>0.935902</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>0.928654</td>\n",
       "      <td>0.945473</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>30032</td>\n",
       "      <td>1732</td>\n",
       "      <td>1356</td>\n",
       "      <td>22544</td>\n",
       "      <td>7</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>cnn_model_ws_7_transform_None</td>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.939133</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>0.946153</td>\n",
       "      <td>0.960081</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>30496</td>\n",
       "      <td>1268</td>\n",
       "      <td>1620</td>\n",
       "      <td>22280</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cnn_two_channels_model_ws_3_transform_None</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.963374</td>\n",
       "      <td>0.972887</td>\n",
       "      <td>0.954046</td>\n",
       "      <td>0.964741</td>\n",
       "      <td>0.972887</td>\n",
       "      <td>30645</td>\n",
       "      <td>1120</td>\n",
       "      <td>648</td>\n",
       "      <td>23252</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_dct</td>\n",
       "      <td>0.948403</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>30915</td>\n",
       "      <td>847</td>\n",
       "      <td>2025</td>\n",
       "      <td>21875</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_fft</td>\n",
       "      <td>0.950559</td>\n",
       "      <td>0.941536</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>0.956327</td>\n",
       "      <td>0.968138</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>30750</td>\n",
       "      <td>1012</td>\n",
       "      <td>1740</td>\n",
       "      <td>22160</td>\n",
       "      <td>6</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_None</td>\n",
       "      <td>0.952499</td>\n",
       "      <td>0.945606</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>0.930144</td>\n",
       "      <td>0.945658</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>30036</td>\n",
       "      <td>1726</td>\n",
       "      <td>918</td>\n",
       "      <td>22982</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>cnn_two_channels_model_ws_7_transform_dct</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.936959</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.917405</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>29704</td>\n",
       "      <td>2060</td>\n",
       "      <td>1019</td>\n",
       "      <td>22881</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>cnn_two_channels_model_ws_7_transform_fft</td>\n",
       "      <td>0.942692</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>0.905506</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>29351</td>\n",
       "      <td>2413</td>\n",
       "      <td>777</td>\n",
       "      <td>23123</td>\n",
       "      <td>7</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cnn_two_channels_model_ws_7_transform_None</td>\n",
       "      <td>0.946482</td>\n",
       "      <td>0.938334</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>0.928551</td>\n",
       "      <td>0.945095</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>30020</td>\n",
       "      <td>1744</td>\n",
       "      <td>1235</td>\n",
       "      <td>22665</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>multi_cnn_model_ws_3_transform_dct</td>\n",
       "      <td>0.968957</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>0.958478</td>\n",
       "      <td>0.968393</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>30761</td>\n",
       "      <td>1004</td>\n",
       "      <td>724</td>\n",
       "      <td>23176</td>\n",
       "      <td>3</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>multi_cnn_model_ws_3_transform_None</td>\n",
       "      <td>0.969730</td>\n",
       "      <td>0.964838</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.962408</td>\n",
       "      <td>0.971572</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>30862</td>\n",
       "      <td>903</td>\n",
       "      <td>782</td>\n",
       "      <td>23118</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>multi_cnn_model_ws_6_transform_dct</td>\n",
       "      <td>0.952247</td>\n",
       "      <td>0.943713</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.955407</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>30722</td>\n",
       "      <td>1040</td>\n",
       "      <td>1618</td>\n",
       "      <td>22282</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>multi_cnn_model_ws_6_transform_fft</td>\n",
       "      <td>0.951170</td>\n",
       "      <td>0.942834</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.947898</td>\n",
       "      <td>0.961212</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>30530</td>\n",
       "      <td>1232</td>\n",
       "      <td>1486</td>\n",
       "      <td>22414</td>\n",
       "      <td>6</td>\n",
       "      <td>fft</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>multi_cnn_model_ws_6_transform_None</td>\n",
       "      <td>0.954547</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.968799</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>30771</td>\n",
       "      <td>991</td>\n",
       "      <td>1539</td>\n",
       "      <td>22361</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>multi_cnn_model_ws_7_transform_dct</td>\n",
       "      <td>0.947129</td>\n",
       "      <td>0.939009</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>0.930276</td>\n",
       "      <td>0.946543</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>30066</td>\n",
       "      <td>1698</td>\n",
       "      <td>1245</td>\n",
       "      <td>22655</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>multi_cnn_model_ws_7_transform_fft</td>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.936713</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>0.924982</td>\n",
       "      <td>0.942104</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>29925</td>\n",
       "      <td>1839</td>\n",
       "      <td>1225</td>\n",
       "      <td>22675</td>\n",
       "      <td>7</td>\n",
       "      <td>fft</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>multi_cnn_model_ws_7_transform_None</td>\n",
       "      <td>0.948513</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>0.931981</td>\n",
       "      <td>0.947866</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>30108</td>\n",
       "      <td>1656</td>\n",
       "      <td>1210</td>\n",
       "      <td>22690</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>multi_lstm_model_ws_3_transform_dct</td>\n",
       "      <td>0.970215</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>0.973272</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>30916</td>\n",
       "      <td>849</td>\n",
       "      <td>809</td>\n",
       "      <td>23091</td>\n",
       "      <td>3</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>multi_lstm_model_ws_3_transform_None</td>\n",
       "      <td>0.970376</td>\n",
       "      <td>0.965451</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>0.966889</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>30976</td>\n",
       "      <td>789</td>\n",
       "      <td>860</td>\n",
       "      <td>23040</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>multi_lstm_model_ws_6_transform_dct</td>\n",
       "      <td>0.953972</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>0.947338</td>\n",
       "      <td>0.960456</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>30506</td>\n",
       "      <td>1256</td>\n",
       "      <td>1306</td>\n",
       "      <td>22594</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>multi_lstm_model_ws_6_transform_fft</td>\n",
       "      <td>0.949984</td>\n",
       "      <td>0.941660</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.943241</td>\n",
       "      <td>0.957433</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>30410</td>\n",
       "      <td>1352</td>\n",
       "      <td>1432</td>\n",
       "      <td>22468</td>\n",
       "      <td>6</td>\n",
       "      <td>fft</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>multi_lstm_model_ws_6_transform_None</td>\n",
       "      <td>0.954044</td>\n",
       "      <td>0.946843</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>0.940550</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>30322</td>\n",
       "      <td>1440</td>\n",
       "      <td>1118</td>\n",
       "      <td>22782</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>multi_lstm_model_ws_7_transform_dct</td>\n",
       "      <td>0.948099</td>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>0.924071</td>\n",
       "      <td>0.940782</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>29883</td>\n",
       "      <td>1881</td>\n",
       "      <td>1008</td>\n",
       "      <td>22892</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>multi_lstm_model_ws_7_transform_fft</td>\n",
       "      <td>0.943608</td>\n",
       "      <td>0.935804</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>0.933321</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>29646</td>\n",
       "      <td>2118</td>\n",
       "      <td>1021</td>\n",
       "      <td>22879</td>\n",
       "      <td>7</td>\n",
       "      <td>fft</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>multi_lstm_model_ws_7_transform_None</td>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>0.922411</td>\n",
       "      <td>0.939334</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>29837</td>\n",
       "      <td>1927</td>\n",
       "      <td>991</td>\n",
       "      <td>22909</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>uni_lstm_model_ws_3_transform_dct</td>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>0.949057</td>\n",
       "      <td>0.960649</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>30515</td>\n",
       "      <td>1250</td>\n",
       "      <td>613</td>\n",
       "      <td>23287</td>\n",
       "      <td>3</td>\n",
       "      <td>dct</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>uni_lstm_model_ws_3_transform_None</td>\n",
       "      <td>0.967089</td>\n",
       "      <td>0.961778</td>\n",
       "      <td>0.964393</td>\n",
       "      <td>0.959176</td>\n",
       "      <td>0.969117</td>\n",
       "      <td>0.964393</td>\n",
       "      <td>30784</td>\n",
       "      <td>981</td>\n",
       "      <td>851</td>\n",
       "      <td>23049</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>uni_lstm_model_ws_6_transform_dct</td>\n",
       "      <td>0.947972</td>\n",
       "      <td>0.939282</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.941335</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1500</td>\n",
       "      <td>22400</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>uni_lstm_model_ws_6_transform_fft</td>\n",
       "      <td>0.948690</td>\n",
       "      <td>0.940076</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.942845</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>30404</td>\n",
       "      <td>1358</td>\n",
       "      <td>1498</td>\n",
       "      <td>22402</td>\n",
       "      <td>6</td>\n",
       "      <td>fft</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>uni_lstm_model_ws_6_transform_None</td>\n",
       "      <td>0.950451</td>\n",
       "      <td>0.942342</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1362</td>\n",
       "      <td>22538</td>\n",
       "      <td>6</td>\n",
       "      <td>None</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>uni_lstm_model_ws_7_transform_dct</td>\n",
       "      <td>0.942728</td>\n",
       "      <td>0.934530</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>0.917682</td>\n",
       "      <td>0.935745</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>29723</td>\n",
       "      <td>2041</td>\n",
       "      <td>1147</td>\n",
       "      <td>22753</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>uni_lstm_model_ws_7_transform_fft</td>\n",
       "      <td>0.943069</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>0.926862</td>\n",
       "      <td>0.944088</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>29988</td>\n",
       "      <td>1776</td>\n",
       "      <td>1393</td>\n",
       "      <td>22507</td>\n",
       "      <td>7</td>\n",
       "      <td>fft</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>uni_lstm_model_ws_7_transform_None</td>\n",
       "      <td>0.943033</td>\n",
       "      <td>0.935075</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>0.915561</td>\n",
       "      <td>0.933699</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>29658</td>\n",
       "      <td>2106</td>\n",
       "      <td>1065</td>\n",
       "      <td>22835</td>\n",
       "      <td>7</td>\n",
       "      <td>None</td>\n",
       "      <td>uni_lstm_model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model_name       acc        f1       rec  \\\n",
       "0            cnn_model_comp_ws_3_transform_dct  0.950651  0.945391  0.994895   \n",
       "1           cnn_model_comp_ws_3_transform_None  0.967394  0.962700  0.980000   \n",
       "2            cnn_model_comp_ws_6_transform_dct  0.948295  0.941563  0.970126   \n",
       "3            cnn_model_comp_ws_6_transform_fft  0.949337  0.942178  0.961297   \n",
       "4           cnn_model_comp_ws_6_transform_None  0.947361  0.940832  0.974686   \n",
       "5            cnn_model_comp_ws_7_transform_dct  0.933781  0.927232  0.982594   \n",
       "6            cnn_model_comp_ws_7_transform_fft  0.933835  0.927361  0.983682   \n",
       "7           cnn_model_comp_ws_7_transform_None  0.945027  0.938381  0.974895   \n",
       "8                 cnn_model_ws_3_transform_dct  0.970700  0.965990  0.969163   \n",
       "9                cnn_model_ws_3_transform_None  0.970035  0.965186  0.967448   \n",
       "10               cnn_model_ws_5_transform_None  0.959508  0.953012  0.956402   \n",
       "11                cnn_model_ws_6_transform_dct  0.953613  0.945913  0.944686   \n",
       "12                cnn_model_ws_6_transform_fft  0.949840  0.941047  0.932385   \n",
       "13               cnn_model_ws_6_transform_None  0.952319  0.943690  0.930502   \n",
       "14                cnn_model_ws_7_transform_dct  0.946608  0.938094  0.942176   \n",
       "15                cnn_model_ws_7_transform_fft  0.944524  0.935902  0.943264   \n",
       "16               cnn_model_ws_7_transform_None  0.948117  0.939133  0.932218   \n",
       "17  cnn_two_channels_model_ws_3_transform_None  0.968239  0.963374  0.972887   \n",
       "18   cnn_two_channels_model_ws_6_transform_dct  0.948403  0.938398  0.915272   \n",
       "19   cnn_two_channels_model_ws_6_transform_fft  0.950559  0.941536  0.927197   \n",
       "20  cnn_two_channels_model_ws_6_transform_None  0.952499  0.945606  0.961590   \n",
       "21   cnn_two_channels_model_ws_7_transform_dct  0.944686  0.936959  0.957364   \n",
       "22   cnn_two_channels_model_ws_7_transform_fft  0.942692  0.935472  0.967490   \n",
       "23  cnn_two_channels_model_ws_7_transform_None  0.946482  0.938334  0.948326   \n",
       "24          multi_cnn_model_ws_3_transform_dct  0.968957  0.964060  0.969707   \n",
       "25         multi_cnn_model_ws_3_transform_None  0.969730  0.964838  0.967280   \n",
       "26          multi_cnn_model_ws_6_transform_dct  0.952247  0.943713  0.932301   \n",
       "27          multi_cnn_model_ws_6_transform_fft  0.951170  0.942834  0.937824   \n",
       "28         multi_cnn_model_ws_6_transform_None  0.954547  0.946457  0.935607   \n",
       "29          multi_cnn_model_ws_7_transform_dct  0.947129  0.939009  0.947908   \n",
       "30          multi_cnn_model_ws_7_transform_fft  0.944955  0.936713  0.948745   \n",
       "31         multi_cnn_model_ws_7_transform_None  0.948513  0.940596  0.949372   \n",
       "32         multi_lstm_model_ws_3_transform_dct  0.970215  0.965343  0.966151   \n",
       "33        multi_lstm_model_ws_3_transform_None  0.970376  0.965451  0.964017   \n",
       "34         multi_lstm_model_ws_6_transform_dct  0.953972  0.946346  0.945356   \n",
       "35         multi_lstm_model_ws_6_transform_fft  0.949984  0.941660  0.940084   \n",
       "36        multi_lstm_model_ws_6_transform_None  0.954044  0.946843  0.953222   \n",
       "37         multi_lstm_model_ws_7_transform_dct  0.948099  0.940645  0.957824   \n",
       "38         multi_lstm_model_ws_7_transform_fft  0.943608  0.935804  0.957280   \n",
       "39        multi_lstm_model_ws_7_transform_None  0.947578  0.940126  0.958536   \n",
       "40           uni_lstm_model_ws_3_transform_dct  0.966532  0.961538  0.974351   \n",
       "41          uni_lstm_model_ws_3_transform_None  0.967089  0.961778  0.964393   \n",
       "42           uni_lstm_model_ws_6_transform_dct  0.947972  0.939282  0.937238   \n",
       "43           uni_lstm_model_ws_6_transform_fft  0.948690  0.940076  0.937322   \n",
       "44          uni_lstm_model_ws_6_transform_None  0.950451  0.942342  0.943013   \n",
       "45           uni_lstm_model_ws_7_transform_dct  0.942728  0.934530  0.952008   \n",
       "46           uni_lstm_model_ws_7_transform_fft  0.943069  0.934230  0.941715   \n",
       "47          uni_lstm_model_ws_7_transform_None  0.943033  0.935075  0.955439   \n",
       "\n",
       "         pre       spe       sen     tn    fp    fn     tp window_size  \\\n",
       "0   0.900579  0.917362  0.994895  29140  2625   122  23778           3   \n",
       "1   0.945999  0.957910  0.980000  30428  1337   478  23422           3   \n",
       "2   0.914635  0.931868  0.970126  29598  2164   714  23186           6   \n",
       "3   0.923804  0.940338  0.961297  29867  1895   925  22975           6   \n",
       "4   0.909251  0.926799  0.974686  29437  2325   605  23295           6   \n",
       "5   0.877775  0.897053  0.982594  28494  3270   416  23484           7   \n",
       "6   0.877141  0.896329  0.983682  28471  3293   390  23510           7   \n",
       "7   0.904503  0.922554  0.974895  29304  2460   600  23300           7   \n",
       "8   0.962838  0.971856  0.969163  30871   894   737  23163           3   \n",
       "9   0.962935  0.971982  0.967448  30875   890   778  23122           3   \n",
       "10  0.949647  0.961845  0.956402  30553  1212  1042  22858           5   \n",
       "11  0.947143  0.960330  0.944686  30502  1260  1322  22578           6   \n",
       "12  0.949872  0.962975  0.932385  30586  1176  1616  22284           6   \n",
       "13  0.957257  0.968736  0.930502  30769   993  1661  22239           6   \n",
       "14  0.934047  0.949943  0.942176  30174  1590  1382  22518           7   \n",
       "15  0.928654  0.945473  0.943264  30032  1732  1356  22544           7   \n",
       "16  0.946153  0.960081  0.932218  30496  1268  1620  22280           7   \n",
       "17  0.954046  0.964741  0.972887  30645  1120   648  23252           3   \n",
       "18  0.962723  0.973333  0.915272  30915   847  2025  21875           6   \n",
       "19  0.956327  0.968138  0.927197  30750  1012  1740  22160           6   \n",
       "20  0.930144  0.945658  0.961590  30036  1726   918  22982           6   \n",
       "21  0.917405  0.935147  0.957364  29704  2060  1019  22881           7   \n",
       "22  0.905506  0.924033  0.967490  29351  2413   777  23123           7   \n",
       "23  0.928551  0.945095  0.948326  30020  1744  1235  22665           7   \n",
       "24  0.958478  0.968393  0.969707  30761  1004   724  23176           3   \n",
       "25  0.962408  0.971572  0.967280  30862   903   782  23118           3   \n",
       "26  0.955407  0.967256  0.932301  30722  1040  1618  22282           6   \n",
       "27  0.947898  0.961212  0.937824  30530  1232  1486  22414           6   \n",
       "28  0.957563  0.968799  0.935607  30771   991  1539  22361           6   \n",
       "29  0.930276  0.946543  0.947908  30066  1698  1245  22655           7   \n",
       "30  0.924982  0.942104  0.948745  29925  1839  1225  22675           7   \n",
       "31  0.931981  0.947866  0.949372  30108  1656  1210  22690           7   \n",
       "32  0.964536  0.973272  0.966151  30916   849   809  23091           3   \n",
       "33  0.966889  0.975161  0.964017  30976   789   860  23040           3   \n",
       "34  0.947338  0.960456  0.945356  30506  1256  1306  22594           6   \n",
       "35  0.943241  0.957433  0.940084  30410  1352  1432  22468           6   \n",
       "36  0.940550  0.954663  0.953222  30322  1440  1118  22782           6   \n",
       "37  0.924071  0.940782  0.957824  29883  1881  1008  22892           7   \n",
       "38  0.915270  0.933321  0.957280  29646  2118  1021  22879           7   \n",
       "39  0.922411  0.939334  0.958536  29837  1927   991  22909           7   \n",
       "40  0.949057  0.960649  0.974351  30515  1250   613  23287           3   \n",
       "41  0.959176  0.969117  0.964393  30784   981   851  23049           3   \n",
       "42  0.941335  0.956048  0.937238  30366  1396  1500  22400           6   \n",
       "43  0.942845  0.957245  0.937322  30404  1358  1498  22402           6   \n",
       "44  0.941673  0.956048  0.943013  30366  1396  1362  22538           6   \n",
       "45  0.917682  0.935745  0.952008  29723  2041  1147  22753           7   \n",
       "46  0.926862  0.944088  0.941715  29988  1776  1393  22507           7   \n",
       "47  0.915561  0.933699  0.955439  29658  2106  1065  22835           7   \n",
       "\n",
       "   transform                   model  \n",
       "0        dct          cnn_model_comp  \n",
       "1       None          cnn_model_comp  \n",
       "2        dct          cnn_model_comp  \n",
       "3        fft          cnn_model_comp  \n",
       "4       None          cnn_model_comp  \n",
       "5        dct          cnn_model_comp  \n",
       "6        fft          cnn_model_comp  \n",
       "7       None          cnn_model_comp  \n",
       "8        dct               cnn_model  \n",
       "9       None               cnn_model  \n",
       "10      None               cnn_model  \n",
       "11       dct               cnn_model  \n",
       "12       fft               cnn_model  \n",
       "13      None               cnn_model  \n",
       "14       dct               cnn_model  \n",
       "15       fft               cnn_model  \n",
       "16      None               cnn_model  \n",
       "17      None  cnn_two_channels_model  \n",
       "18       dct  cnn_two_channels_model  \n",
       "19       fft  cnn_two_channels_model  \n",
       "20      None  cnn_two_channels_model  \n",
       "21       dct  cnn_two_channels_model  \n",
       "22       fft  cnn_two_channels_model  \n",
       "23      None  cnn_two_channels_model  \n",
       "24       dct         multi_cnn_model  \n",
       "25      None         multi_cnn_model  \n",
       "26       dct         multi_cnn_model  \n",
       "27       fft         multi_cnn_model  \n",
       "28      None         multi_cnn_model  \n",
       "29       dct         multi_cnn_model  \n",
       "30       fft         multi_cnn_model  \n",
       "31      None         multi_cnn_model  \n",
       "32       dct        multi_lstm_model  \n",
       "33      None        multi_lstm_model  \n",
       "34       dct        multi_lstm_model  \n",
       "35       fft        multi_lstm_model  \n",
       "36      None        multi_lstm_model  \n",
       "37       dct        multi_lstm_model  \n",
       "38       fft        multi_lstm_model  \n",
       "39      None        multi_lstm_model  \n",
       "40       dct          uni_lstm_model  \n",
       "41      None          uni_lstm_model  \n",
       "42       dct          uni_lstm_model  \n",
       "43       fft          uni_lstm_model  \n",
       "44      None          uni_lstm_model  \n",
       "45       dct          uni_lstm_model  \n",
       "46       fft          uni_lstm_model  \n",
       "47      None          uni_lstm_model  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "a9a194a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:26:54.840876Z",
     "start_time": "2021-10-15T06:26:54.816866Z"
    }
   },
   "outputs": [],
   "source": [
    "del scores_df['model_name']\n",
    "\n",
    "scores_df = scores_df[scores_df.columns[-3:].tolist() + scores_df.columns[:-3].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "75bc9783",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:27:20.069874Z",
     "start_time": "2021-10-15T06:27:19.956882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>rec</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>sen</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"11\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.970035</td>\n",
       "      <td>0.965186</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>0.962935</td>\n",
       "      <td>0.971982</td>\n",
       "      <td>0.967448</td>\n",
       "      <td>30875</td>\n",
       "      <td>890</td>\n",
       "      <td>778</td>\n",
       "      <td>23122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.967394</td>\n",
       "      <td>0.962700</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.945999</td>\n",
       "      <td>0.957910</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>30428</td>\n",
       "      <td>1337</td>\n",
       "      <td>478</td>\n",
       "      <td>23422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.963374</td>\n",
       "      <td>0.972887</td>\n",
       "      <td>0.954046</td>\n",
       "      <td>0.964741</td>\n",
       "      <td>0.972887</td>\n",
       "      <td>30645</td>\n",
       "      <td>1120</td>\n",
       "      <td>648</td>\n",
       "      <td>23252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.969730</td>\n",
       "      <td>0.964838</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>0.962408</td>\n",
       "      <td>0.971572</td>\n",
       "      <td>0.967280</td>\n",
       "      <td>30862</td>\n",
       "      <td>903</td>\n",
       "      <td>782</td>\n",
       "      <td>23118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.970376</td>\n",
       "      <td>0.965451</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>0.966889</td>\n",
       "      <td>0.975161</td>\n",
       "      <td>0.964017</td>\n",
       "      <td>30976</td>\n",
       "      <td>789</td>\n",
       "      <td>860</td>\n",
       "      <td>23040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.967089</td>\n",
       "      <td>0.961778</td>\n",
       "      <td>0.964393</td>\n",
       "      <td>0.959176</td>\n",
       "      <td>0.969117</td>\n",
       "      <td>0.964393</td>\n",
       "      <td>30784</td>\n",
       "      <td>981</td>\n",
       "      <td>851</td>\n",
       "      <td>23049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.970700</td>\n",
       "      <td>0.965990</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>0.962838</td>\n",
       "      <td>0.971856</td>\n",
       "      <td>0.969163</td>\n",
       "      <td>30871</td>\n",
       "      <td>894</td>\n",
       "      <td>737</td>\n",
       "      <td>23163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.950651</td>\n",
       "      <td>0.945391</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>0.900579</td>\n",
       "      <td>0.917362</td>\n",
       "      <td>0.994895</td>\n",
       "      <td>29140</td>\n",
       "      <td>2625</td>\n",
       "      <td>122</td>\n",
       "      <td>23778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.968957</td>\n",
       "      <td>0.964060</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>0.958478</td>\n",
       "      <td>0.968393</td>\n",
       "      <td>0.969707</td>\n",
       "      <td>30761</td>\n",
       "      <td>1004</td>\n",
       "      <td>724</td>\n",
       "      <td>23176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.970215</td>\n",
       "      <td>0.965343</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>0.964536</td>\n",
       "      <td>0.973272</td>\n",
       "      <td>0.966151</td>\n",
       "      <td>30916</td>\n",
       "      <td>849</td>\n",
       "      <td>809</td>\n",
       "      <td>23091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.966532</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>0.949057</td>\n",
       "      <td>0.960649</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>30515</td>\n",
       "      <td>1250</td>\n",
       "      <td>613</td>\n",
       "      <td>23287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.959508</td>\n",
       "      <td>0.953012</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.949647</td>\n",
       "      <td>0.961845</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>30553</td>\n",
       "      <td>1212</td>\n",
       "      <td>1042</td>\n",
       "      <td>22858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.952319</td>\n",
       "      <td>0.943690</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>0.957257</td>\n",
       "      <td>0.968736</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>30769</td>\n",
       "      <td>993</td>\n",
       "      <td>1661</td>\n",
       "      <td>22239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.947361</td>\n",
       "      <td>0.940832</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.909251</td>\n",
       "      <td>0.926799</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>29437</td>\n",
       "      <td>2325</td>\n",
       "      <td>605</td>\n",
       "      <td>23295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.952499</td>\n",
       "      <td>0.945606</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>0.930144</td>\n",
       "      <td>0.945658</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>30036</td>\n",
       "      <td>1726</td>\n",
       "      <td>918</td>\n",
       "      <td>22982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.954547</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.968799</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>30771</td>\n",
       "      <td>991</td>\n",
       "      <td>1539</td>\n",
       "      <td>22361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.954044</td>\n",
       "      <td>0.946843</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>0.940550</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>30322</td>\n",
       "      <td>1440</td>\n",
       "      <td>1118</td>\n",
       "      <td>22782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.950451</td>\n",
       "      <td>0.942342</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1362</td>\n",
       "      <td>22538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.953613</td>\n",
       "      <td>0.945913</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.947143</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>30502</td>\n",
       "      <td>1260</td>\n",
       "      <td>1322</td>\n",
       "      <td>22578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.948295</td>\n",
       "      <td>0.941563</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>0.914635</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>29598</td>\n",
       "      <td>2164</td>\n",
       "      <td>714</td>\n",
       "      <td>23186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.948403</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>30915</td>\n",
       "      <td>847</td>\n",
       "      <td>2025</td>\n",
       "      <td>21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.952247</td>\n",
       "      <td>0.943713</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.955407</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>30722</td>\n",
       "      <td>1040</td>\n",
       "      <td>1618</td>\n",
       "      <td>22282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.953972</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>0.947338</td>\n",
       "      <td>0.960456</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>30506</td>\n",
       "      <td>1256</td>\n",
       "      <td>1306</td>\n",
       "      <td>22594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.947972</td>\n",
       "      <td>0.939282</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.941335</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1500</td>\n",
       "      <td>22400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.949840</td>\n",
       "      <td>0.941047</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>0.949872</td>\n",
       "      <td>0.962975</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>30586</td>\n",
       "      <td>1176</td>\n",
       "      <td>1616</td>\n",
       "      <td>22284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.949337</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>0.923804</td>\n",
       "      <td>0.940338</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>29867</td>\n",
       "      <td>1895</td>\n",
       "      <td>925</td>\n",
       "      <td>22975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.950559</td>\n",
       "      <td>0.941536</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>0.956327</td>\n",
       "      <td>0.968138</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>30750</td>\n",
       "      <td>1012</td>\n",
       "      <td>1740</td>\n",
       "      <td>22160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.951170</td>\n",
       "      <td>0.942834</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.947898</td>\n",
       "      <td>0.961212</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>30530</td>\n",
       "      <td>1232</td>\n",
       "      <td>1486</td>\n",
       "      <td>22414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.949984</td>\n",
       "      <td>0.941660</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.943241</td>\n",
       "      <td>0.957433</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>30410</td>\n",
       "      <td>1352</td>\n",
       "      <td>1432</td>\n",
       "      <td>22468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.948690</td>\n",
       "      <td>0.940076</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.942845</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>30404</td>\n",
       "      <td>1358</td>\n",
       "      <td>1498</td>\n",
       "      <td>22402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.939133</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>0.946153</td>\n",
       "      <td>0.960081</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>30496</td>\n",
       "      <td>1268</td>\n",
       "      <td>1620</td>\n",
       "      <td>22280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.945027</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.904503</td>\n",
       "      <td>0.922554</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>29304</td>\n",
       "      <td>2460</td>\n",
       "      <td>600</td>\n",
       "      <td>23300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.946482</td>\n",
       "      <td>0.938334</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>0.928551</td>\n",
       "      <td>0.945095</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>30020</td>\n",
       "      <td>1744</td>\n",
       "      <td>1235</td>\n",
       "      <td>22665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.948513</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>0.931981</td>\n",
       "      <td>0.947866</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>30108</td>\n",
       "      <td>1656</td>\n",
       "      <td>1210</td>\n",
       "      <td>22690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>0.922411</td>\n",
       "      <td>0.939334</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>29837</td>\n",
       "      <td>1927</td>\n",
       "      <td>991</td>\n",
       "      <td>22909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.943033</td>\n",
       "      <td>0.935075</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>0.915561</td>\n",
       "      <td>0.933699</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>29658</td>\n",
       "      <td>2106</td>\n",
       "      <td>1065</td>\n",
       "      <td>22835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.949943</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>30174</td>\n",
       "      <td>1590</td>\n",
       "      <td>1382</td>\n",
       "      <td>22518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.933781</td>\n",
       "      <td>0.927232</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.897053</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>28494</td>\n",
       "      <td>3270</td>\n",
       "      <td>416</td>\n",
       "      <td>23484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.936959</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.917405</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>29704</td>\n",
       "      <td>2060</td>\n",
       "      <td>1019</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.947129</td>\n",
       "      <td>0.939009</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>0.930276</td>\n",
       "      <td>0.946543</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>30066</td>\n",
       "      <td>1698</td>\n",
       "      <td>1245</td>\n",
       "      <td>22655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.948099</td>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>0.924071</td>\n",
       "      <td>0.940782</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>29883</td>\n",
       "      <td>1881</td>\n",
       "      <td>1008</td>\n",
       "      <td>22892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.942728</td>\n",
       "      <td>0.934530</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>0.917682</td>\n",
       "      <td>0.935745</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>29723</td>\n",
       "      <td>2041</td>\n",
       "      <td>1147</td>\n",
       "      <td>22753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.944524</td>\n",
       "      <td>0.935902</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>0.928654</td>\n",
       "      <td>0.945473</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>30032</td>\n",
       "      <td>1732</td>\n",
       "      <td>1356</td>\n",
       "      <td>22544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.933835</td>\n",
       "      <td>0.927361</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>0.877141</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>28471</td>\n",
       "      <td>3293</td>\n",
       "      <td>390</td>\n",
       "      <td>23510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.942692</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>0.905506</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>29351</td>\n",
       "      <td>2413</td>\n",
       "      <td>777</td>\n",
       "      <td>23123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.936713</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>0.924982</td>\n",
       "      <td>0.942104</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>29925</td>\n",
       "      <td>1839</td>\n",
       "      <td>1225</td>\n",
       "      <td>22675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.943608</td>\n",
       "      <td>0.935804</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>0.933321</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>29646</td>\n",
       "      <td>2118</td>\n",
       "      <td>1021</td>\n",
       "      <td>22879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.943069</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>0.926862</td>\n",
       "      <td>0.944088</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>29988</td>\n",
       "      <td>1776</td>\n",
       "      <td>1393</td>\n",
       "      <td>22507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   acc        f1       rec  \\\n",
       "window_size transform model                                                  \n",
       "3           None      cnn_model               0.970035  0.965186  0.967448   \n",
       "                      cnn_model_comp          0.967394  0.962700  0.980000   \n",
       "                      cnn_two_channels_model  0.968239  0.963374  0.972887   \n",
       "                      multi_cnn_model         0.969730  0.964838  0.967280   \n",
       "                      multi_lstm_model        0.970376  0.965451  0.964017   \n",
       "                      uni_lstm_model          0.967089  0.961778  0.964393   \n",
       "            dct       cnn_model               0.970700  0.965990  0.969163   \n",
       "                      cnn_model_comp          0.950651  0.945391  0.994895   \n",
       "                      multi_cnn_model         0.968957  0.964060  0.969707   \n",
       "                      multi_lstm_model        0.970215  0.965343  0.966151   \n",
       "                      uni_lstm_model          0.966532  0.961538  0.974351   \n",
       "5           None      cnn_model               0.959508  0.953012  0.956402   \n",
       "6           None      cnn_model               0.952319  0.943690  0.930502   \n",
       "                      cnn_model_comp          0.947361  0.940832  0.974686   \n",
       "                      cnn_two_channels_model  0.952499  0.945606  0.961590   \n",
       "                      multi_cnn_model         0.954547  0.946457  0.935607   \n",
       "                      multi_lstm_model        0.954044  0.946843  0.953222   \n",
       "                      uni_lstm_model          0.950451  0.942342  0.943013   \n",
       "            dct       cnn_model               0.953613  0.945913  0.944686   \n",
       "                      cnn_model_comp          0.948295  0.941563  0.970126   \n",
       "                      cnn_two_channels_model  0.948403  0.938398  0.915272   \n",
       "                      multi_cnn_model         0.952247  0.943713  0.932301   \n",
       "                      multi_lstm_model        0.953972  0.946346  0.945356   \n",
       "                      uni_lstm_model          0.947972  0.939282  0.937238   \n",
       "            fft       cnn_model               0.949840  0.941047  0.932385   \n",
       "                      cnn_model_comp          0.949337  0.942178  0.961297   \n",
       "                      cnn_two_channels_model  0.950559  0.941536  0.927197   \n",
       "                      multi_cnn_model         0.951170  0.942834  0.937824   \n",
       "                      multi_lstm_model        0.949984  0.941660  0.940084   \n",
       "                      uni_lstm_model          0.948690  0.940076  0.937322   \n",
       "7           None      cnn_model               0.948117  0.939133  0.932218   \n",
       "                      cnn_model_comp          0.945027  0.938381  0.974895   \n",
       "                      cnn_two_channels_model  0.946482  0.938334  0.948326   \n",
       "                      multi_cnn_model         0.948513  0.940596  0.949372   \n",
       "                      multi_lstm_model        0.947578  0.940126  0.958536   \n",
       "                      uni_lstm_model          0.943033  0.935075  0.955439   \n",
       "            dct       cnn_model               0.946608  0.938094  0.942176   \n",
       "                      cnn_model_comp          0.933781  0.927232  0.982594   \n",
       "                      cnn_two_channels_model  0.944686  0.936959  0.957364   \n",
       "                      multi_cnn_model         0.947129  0.939009  0.947908   \n",
       "                      multi_lstm_model        0.948099  0.940645  0.957824   \n",
       "                      uni_lstm_model          0.942728  0.934530  0.952008   \n",
       "            fft       cnn_model               0.944524  0.935902  0.943264   \n",
       "                      cnn_model_comp          0.933835  0.927361  0.983682   \n",
       "                      cnn_two_channels_model  0.942692  0.935472  0.967490   \n",
       "                      multi_cnn_model         0.944955  0.936713  0.948745   \n",
       "                      multi_lstm_model        0.943608  0.935804  0.957280   \n",
       "                      uni_lstm_model          0.943069  0.934230  0.941715   \n",
       "\n",
       "                                                   pre       spe       sen  \\\n",
       "window_size transform model                                                  \n",
       "3           None      cnn_model               0.962935  0.971982  0.967448   \n",
       "                      cnn_model_comp          0.945999  0.957910  0.980000   \n",
       "                      cnn_two_channels_model  0.954046  0.964741  0.972887   \n",
       "                      multi_cnn_model         0.962408  0.971572  0.967280   \n",
       "                      multi_lstm_model        0.966889  0.975161  0.964017   \n",
       "                      uni_lstm_model          0.959176  0.969117  0.964393   \n",
       "            dct       cnn_model               0.962838  0.971856  0.969163   \n",
       "                      cnn_model_comp          0.900579  0.917362  0.994895   \n",
       "                      multi_cnn_model         0.958478  0.968393  0.969707   \n",
       "                      multi_lstm_model        0.964536  0.973272  0.966151   \n",
       "                      uni_lstm_model          0.949057  0.960649  0.974351   \n",
       "5           None      cnn_model               0.949647  0.961845  0.956402   \n",
       "6           None      cnn_model               0.957257  0.968736  0.930502   \n",
       "                      cnn_model_comp          0.909251  0.926799  0.974686   \n",
       "                      cnn_two_channels_model  0.930144  0.945658  0.961590   \n",
       "                      multi_cnn_model         0.957563  0.968799  0.935607   \n",
       "                      multi_lstm_model        0.940550  0.954663  0.953222   \n",
       "                      uni_lstm_model          0.941673  0.956048  0.943013   \n",
       "            dct       cnn_model               0.947143  0.960330  0.944686   \n",
       "                      cnn_model_comp          0.914635  0.931868  0.970126   \n",
       "                      cnn_two_channels_model  0.962723  0.973333  0.915272   \n",
       "                      multi_cnn_model         0.955407  0.967256  0.932301   \n",
       "                      multi_lstm_model        0.947338  0.960456  0.945356   \n",
       "                      uni_lstm_model          0.941335  0.956048  0.937238   \n",
       "            fft       cnn_model               0.949872  0.962975  0.932385   \n",
       "                      cnn_model_comp          0.923804  0.940338  0.961297   \n",
       "                      cnn_two_channels_model  0.956327  0.968138  0.927197   \n",
       "                      multi_cnn_model         0.947898  0.961212  0.937824   \n",
       "                      multi_lstm_model        0.943241  0.957433  0.940084   \n",
       "                      uni_lstm_model          0.942845  0.957245  0.937322   \n",
       "7           None      cnn_model               0.946153  0.960081  0.932218   \n",
       "                      cnn_model_comp          0.904503  0.922554  0.974895   \n",
       "                      cnn_two_channels_model  0.928551  0.945095  0.948326   \n",
       "                      multi_cnn_model         0.931981  0.947866  0.949372   \n",
       "                      multi_lstm_model        0.922411  0.939334  0.958536   \n",
       "                      uni_lstm_model          0.915561  0.933699  0.955439   \n",
       "            dct       cnn_model               0.934047  0.949943  0.942176   \n",
       "                      cnn_model_comp          0.877775  0.897053  0.982594   \n",
       "                      cnn_two_channels_model  0.917405  0.935147  0.957364   \n",
       "                      multi_cnn_model         0.930276  0.946543  0.947908   \n",
       "                      multi_lstm_model        0.924071  0.940782  0.957824   \n",
       "                      uni_lstm_model          0.917682  0.935745  0.952008   \n",
       "            fft       cnn_model               0.928654  0.945473  0.943264   \n",
       "                      cnn_model_comp          0.877141  0.896329  0.983682   \n",
       "                      cnn_two_channels_model  0.905506  0.924033  0.967490   \n",
       "                      multi_cnn_model         0.924982  0.942104  0.948745   \n",
       "                      multi_lstm_model        0.915270  0.933321  0.957280   \n",
       "                      uni_lstm_model          0.926862  0.944088  0.941715   \n",
       "\n",
       "                                                 tn    fp    fn     tp  \n",
       "window_size transform model                                             \n",
       "3           None      cnn_model               30875   890   778  23122  \n",
       "                      cnn_model_comp          30428  1337   478  23422  \n",
       "                      cnn_two_channels_model  30645  1120   648  23252  \n",
       "                      multi_cnn_model         30862   903   782  23118  \n",
       "                      multi_lstm_model        30976   789   860  23040  \n",
       "                      uni_lstm_model          30784   981   851  23049  \n",
       "            dct       cnn_model               30871   894   737  23163  \n",
       "                      cnn_model_comp          29140  2625   122  23778  \n",
       "                      multi_cnn_model         30761  1004   724  23176  \n",
       "                      multi_lstm_model        30916   849   809  23091  \n",
       "                      uni_lstm_model          30515  1250   613  23287  \n",
       "5           None      cnn_model               30553  1212  1042  22858  \n",
       "6           None      cnn_model               30769   993  1661  22239  \n",
       "                      cnn_model_comp          29437  2325   605  23295  \n",
       "                      cnn_two_channels_model  30036  1726   918  22982  \n",
       "                      multi_cnn_model         30771   991  1539  22361  \n",
       "                      multi_lstm_model        30322  1440  1118  22782  \n",
       "                      uni_lstm_model          30366  1396  1362  22538  \n",
       "            dct       cnn_model               30502  1260  1322  22578  \n",
       "                      cnn_model_comp          29598  2164   714  23186  \n",
       "                      cnn_two_channels_model  30915   847  2025  21875  \n",
       "                      multi_cnn_model         30722  1040  1618  22282  \n",
       "                      multi_lstm_model        30506  1256  1306  22594  \n",
       "                      uni_lstm_model          30366  1396  1500  22400  \n",
       "            fft       cnn_model               30586  1176  1616  22284  \n",
       "                      cnn_model_comp          29867  1895   925  22975  \n",
       "                      cnn_two_channels_model  30750  1012  1740  22160  \n",
       "                      multi_cnn_model         30530  1232  1486  22414  \n",
       "                      multi_lstm_model        30410  1352  1432  22468  \n",
       "                      uni_lstm_model          30404  1358  1498  22402  \n",
       "7           None      cnn_model               30496  1268  1620  22280  \n",
       "                      cnn_model_comp          29304  2460   600  23300  \n",
       "                      cnn_two_channels_model  30020  1744  1235  22665  \n",
       "                      multi_cnn_model         30108  1656  1210  22690  \n",
       "                      multi_lstm_model        29837  1927   991  22909  \n",
       "                      uni_lstm_model          29658  2106  1065  22835  \n",
       "            dct       cnn_model               30174  1590  1382  22518  \n",
       "                      cnn_model_comp          28494  3270   416  23484  \n",
       "                      cnn_two_channels_model  29704  2060  1019  22881  \n",
       "                      multi_cnn_model         30066  1698  1245  22655  \n",
       "                      multi_lstm_model        29883  1881  1008  22892  \n",
       "                      uni_lstm_model          29723  2041  1147  22753  \n",
       "            fft       cnn_model               30032  1732  1356  22544  \n",
       "                      cnn_model_comp          28471  3293   390  23510  \n",
       "                      cnn_two_channels_model  29351  2413   777  23123  \n",
       "                      multi_cnn_model         29925  1839  1225  22675  \n",
       "                      multi_lstm_model        29646  2118  1021  22879  \n",
       "                      uni_lstm_model          29988  1776  1393  22507  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by=['window_size', 'transform', 'model']).set_index(['window_size', 'transform', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf26304d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
