{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce66a8e8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T05:49:24.412407Z",
     "start_time": "2021-10-15T05:49:24.393403Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec66694e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:28:16.647883Z",
     "start_time": "2021-10-15T06:28:16.632871Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/outputs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d99d675b",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-15T06:28:16.889Z"
    }
   },
   "outputs": [],
   "source": [
    "predictions = {file[:-4]: pd.read_csv(DATA_PATH+file) for file in os.listdir(DATA_PATH)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19914983",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-10-15T06:28:17.674Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id_pat</th>\n",
       "      <th>date</th>\n",
       "      <th>activity</th>\n",
       "      <th>timeline</th>\n",
       "      <th>Acc_x</th>\n",
       "      <th>Acc_y</th>\n",
       "      <th>Acc_z</th>\n",
       "      <th>Gyro_x</th>\n",
       "      <th>Gyro_y</th>\n",
       "      <th>Gyro_z</th>\n",
       "      <th>appui_leve</th>\n",
       "      <th>foot_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1081748</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>1minJoint</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.66</td>\n",
       "      <td>-7.96</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.074176</td>\n",
       "      <td>-0.206167</td>\n",
       "      <td>-0.014181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1081749</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>1minJoint</td>\n",
       "      <td>0.025316</td>\n",
       "      <td>5.76</td>\n",
       "      <td>-7.59</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.070904</td>\n",
       "      <td>-0.077449</td>\n",
       "      <td>-0.034907</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1081750</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>1minJoint</td>\n",
       "      <td>0.050633</td>\n",
       "      <td>5.82</td>\n",
       "      <td>-7.62</td>\n",
       "      <td>1.08</td>\n",
       "      <td>0.032725</td>\n",
       "      <td>0.068722</td>\n",
       "      <td>-0.005454</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1081751</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>1minJoint</td>\n",
       "      <td>0.075949</td>\n",
       "      <td>6.10</td>\n",
       "      <td>-7.73</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-0.061087</td>\n",
       "      <td>0.297797</td>\n",
       "      <td>0.014181</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1081752</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>1minJoint</td>\n",
       "      <td>0.101266</td>\n",
       "      <td>5.78</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>1.28</td>\n",
       "      <td>-0.215984</td>\n",
       "      <td>1.015563</td>\n",
       "      <td>0.075267</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55663</th>\n",
       "      <td>2219159</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>Step</td>\n",
       "      <td>27.022901</td>\n",
       "      <td>1.14</td>\n",
       "      <td>-9.64</td>\n",
       "      <td>1.67</td>\n",
       "      <td>0.112356</td>\n",
       "      <td>-0.186532</td>\n",
       "      <td>0.010908</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55664</th>\n",
       "      <td>2219160</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>Step</td>\n",
       "      <td>27.048346</td>\n",
       "      <td>1.09</td>\n",
       "      <td>-9.58</td>\n",
       "      <td>1.72</td>\n",
       "      <td>0.267254</td>\n",
       "      <td>-0.296706</td>\n",
       "      <td>0.047997</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55665</th>\n",
       "      <td>2219161</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>Step</td>\n",
       "      <td>27.073791</td>\n",
       "      <td>1.31</td>\n",
       "      <td>-9.28</td>\n",
       "      <td>1.66</td>\n",
       "      <td>0.234529</td>\n",
       "      <td>-0.265072</td>\n",
       "      <td>0.066541</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55666</th>\n",
       "      <td>2219162</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>Step</td>\n",
       "      <td>27.099237</td>\n",
       "      <td>0.99</td>\n",
       "      <td>-9.48</td>\n",
       "      <td>1.78</td>\n",
       "      <td>0.266163</td>\n",
       "      <td>-0.250891</td>\n",
       "      <td>0.105811</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55667</th>\n",
       "      <td>2219163</td>\n",
       "      <td>P42</td>\n",
       "      <td>2020-07-13</td>\n",
       "      <td>Step</td>\n",
       "      <td>27.124682</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-294.39</td>\n",
       "      <td>43.53</td>\n",
       "      <td>11.779882</td>\n",
       "      <td>16.800976</td>\n",
       "      <td>-27.041695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55668 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0 id_pat        date   activity   timeline  Acc_x   Acc_y  \\\n",
       "0         1081748    P42  2020-07-13  1minJoint   0.000000   5.66   -7.96   \n",
       "1         1081749    P42  2020-07-13  1minJoint   0.025316   5.76   -7.59   \n",
       "2         1081750    P42  2020-07-13  1minJoint   0.050633   5.82   -7.62   \n",
       "3         1081751    P42  2020-07-13  1minJoint   0.075949   6.10   -7.73   \n",
       "4         1081752    P42  2020-07-13  1minJoint   0.101266   5.78   -7.69   \n",
       "...           ...    ...         ...        ...        ...    ...     ...   \n",
       "55663     2219159    P42  2020-07-13       Step  27.022901   1.14   -9.64   \n",
       "55664     2219160    P42  2020-07-13       Step  27.048346   1.09   -9.58   \n",
       "55665     2219161    P42  2020-07-13       Step  27.073791   1.31   -9.28   \n",
       "55666     2219162    P42  2020-07-13       Step  27.099237   0.99   -9.48   \n",
       "55667     2219163    P42  2020-07-13       Step  27.124682   0.00 -294.39   \n",
       "\n",
       "       Acc_z     Gyro_x     Gyro_y     Gyro_z  appui_leve  foot_type  \n",
       "0       0.79   0.074176  -0.206167  -0.014181         0.0          0  \n",
       "1       0.95   0.070904  -0.077449  -0.034907         0.0          0  \n",
       "2       1.08   0.032725   0.068722  -0.005454         0.0          0  \n",
       "3       1.18  -0.061087   0.297797   0.014181         0.0          0  \n",
       "4       1.28  -0.215984   1.015563   0.075267         0.0          0  \n",
       "...      ...        ...        ...        ...         ...        ...  \n",
       "55663   1.67   0.112356  -0.186532   0.010908         0.0          1  \n",
       "55664   1.72   0.267254  -0.296706   0.047997         0.0          1  \n",
       "55665   1.66   0.234529  -0.265072   0.066541         0.0          1  \n",
       "55666   1.78   0.266163  -0.250891   0.105811         0.0          1  \n",
       "55667  43.53  11.779882  16.800976 -27.041695         0.0          1  \n",
       "\n",
       "[55668 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = predictions.pop('test_df')\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5849abff",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:09:36.703868Z",
     "start_time": "2021-10-15T06:09:36.676869Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(y_real, y_pred):\n",
    "    print(\"Accuracy score: \", accuracy_score(y_real, y_pred))\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_real, y_pred))\n",
    "    print(\"Classification report: \\n\", classification_report(y_real, y_pred))\n",
    "\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_real, label='Real')\n",
    "    plt.plot(y_pred, label='Predictions')\n",
    "    plt.legend()\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_real)\n",
    "    plt.figure(figsize=(20, 5))\n",
    "    plt.plot(y_pred)\n",
    "    plt.show()\n",
    "\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(y=y_real, name='Real values'))\n",
    "    fig.add_trace(go.Scatter(y=y_pred, name='Predicted values'))\n",
    "    pio.show(fig)\n",
    "\n",
    "def evaluate_models(test_df, model_preds, model_name):\n",
    "    \"\"\"Evaualtes the predictions made by the models by reformatting them into their initial length\n",
    "    \"\"\"\n",
    "    window_size = int(re.search(r'_ws_(.*?)_transform', model_name).group(1))\n",
    "    y_real_test_pred = model_preds.predictions\n",
    "    y_real_test = test_df.appui_leve.values[:len(y_real_test_pred)]\n",
    "    print(\n",
    "        \"\"\"\n",
    "        ############################################\n",
    "        {} evaluation...\n",
    "        ############################################\n",
    "        \"\"\".format(model_name)\n",
    "    )\n",
    "    print(\"########## All test data ##########\")\n",
    "    #self.evaluate(y_real_test_pred, y_real_test)\n",
    "    acc = accuracy_score(y_real_test, y_real_test_pred)\n",
    "    f1 = f1_score(y_real_test, y_real_test_pred)\n",
    "    rec = recall_score(y_real_test, y_real_test_pred)\n",
    "    pre = precision_score(y_real_test, y_real_test_pred)\n",
    "    print(\"Accuracy score: \", acc)\n",
    "    print(\"F1 score score: \", f1)\n",
    "    print(\"Recall: \", rec)\n",
    "    print(\"Precision: \", pre)\n",
    "    print(\"Confusion matrix: \\n\", confusion_matrix(y_real_test, y_real_test_pred))\n",
    "    print(\"Classification report: \\n\", classification_report(y_real_test, y_real_test_pred))\n",
    "    tn, fp, fn, tp = confusion_matrix(y_real_test, y_real_test_pred).ravel()\n",
    "    spe = tn / (tn+fp)\n",
    "    sen = tp / (tp+fn)\n",
    "    print(\"Specificity: \", spe)\n",
    "    print(\"Sensitivity: \", sen)\n",
    "    print(\"TP; \", tp)\n",
    "    print(\"FP; \", fp)\n",
    "    print(\"TN; \", tn)\n",
    "    print(\"FN; \", fn)\n",
    "    return model_name, acc, f1, rec, pre, spe, sen, tn, fp, fn, tp\n",
    "\n",
    "    #print(\"########## Left/Right data ##########\")\n",
    "    #self.test_df['preds'] = np.append(y_real_test_pred, np.zeros(self.test_df.shape[0] - len(y_real_test_pred)))\n",
    "    #test_df_g = self.test_df[self.test_df.foot_type == 0]\n",
    "    #test_df_d = self.test_df[self.test_df.foot_type == 1]\n",
    "    #self.evaluate(test_df_g.appui_leve, test_df_g.preds)\n",
    "    #self.evaluate(test_df_d.appui_leve, test_df_d.preds)\n",
    "\n",
    "    #print(\"########## Per activity data ##########\")\n",
    "    #for activity in test_df_g.activity.unique():\n",
    "    #    print(\"#### Activité: {} ####\".format(activity))\n",
    "    #    temp_df_g = test_df_g[test_df_g.activity == activity]\n",
    "    #    temp_df_d = test_df_d[test_df_d.activity == activity]\n",
    "    #    self.evaluate(temp_df_g.appui_leve, temp_df_g.preds)\n",
    "    #    self.evaluate(temp_df_d.appui_leve, temp_df_d.preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "550361d0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:10:44.215868Z",
     "start_time": "2021-10-15T06:09:44.259884Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_5_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9565256444803737\n",
      "F1 score score:  0.9499275812124973\n",
      "Recall:  0.9604602510460251\n",
      "Precision:  0.9396234138354482\n",
      "Confusion matrix: \n",
      " [[30290  1475]\n",
      " [  945 22955]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31765\n",
      "         1.0       0.94      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9535652447662522\n",
      "Sensitivity:  0.9604602510460251\n",
      "TP;  22955\n",
      "FP;  1475\n",
      "TN;  30290\n",
      "FN;  945\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.969639809575137\n",
      "F1 score score:  0.964819517881677\n",
      "Recall:  0.969623430962343\n",
      "Precision:  0.9600629712486536\n",
      "Confusion matrix: \n",
      " [[30801   964]\n",
      " [  726 23174]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9696521328506218\n",
      "Sensitivity:  0.969623430962343\n",
      "TP;  23174\n",
      "FP;  964\n",
      "TN;  30801\n",
      "FN;  726\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9484028601200101\n",
      "F1 score score:  0.9383981811162113\n",
      "Recall:  0.9152719665271967\n",
      "Precision:  0.9627233518176217\n",
      "Confusion matrix: \n",
      " [[30915   847]\n",
      " [ 2025 21875]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.97      0.96     31762\n",
      "         1.0       0.96      0.92      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.94      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9733329135444871\n",
      "Sensitivity:  0.9152719665271967\n",
      "TP;  21875\n",
      "FP;  847\n",
      "TN;  30915\n",
      "FN;  2025\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9604958232282403\n",
      "F1 score score:  0.9542304089915704\n",
      "Recall:  0.9591213389121339\n",
      "Precision:  0.9493891074756678\n",
      "Confusion matrix: \n",
      " [[30543  1222]\n",
      " [  977 22923]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97     31765\n",
      "         1.0       0.95      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9615299858334645\n",
      "Sensitivity:  0.9591213389121339\n",
      "TP;  22923\n",
      "FP;  1222\n",
      "TN;  30543\n",
      "FN;  977\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9687954729183509\n",
      "F1 score score:  0.9642010675789865\n",
      "Recall:  0.978744769874477\n",
      "Precision:  0.9500832622557979\n",
      "Confusion matrix: \n",
      " [[30536  1229]\n",
      " [  508 23392]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.98      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9613096175035416\n",
      "Sensitivity:  0.978744769874477\n",
      "TP;  23392\n",
      "FP;  1229\n",
      "TN;  30536\n",
      "FN;  508\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_3_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9673583041408426\n",
      "F1 score score:  0.9625661838933641\n",
      "Recall:  0.9774476987447699\n",
      "Precision:  0.9481310118105443\n",
      "Confusion matrix: \n",
      " [[30487  1278]\n",
      " [  539 23361]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.98      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9597670391940816\n",
      "Sensitivity:  0.9774476987447699\n",
      "TP;  23361\n",
      "FP;  1278\n",
      "TN;  30487\n",
      "FN;  539\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_4_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9649683817188848\n",
      "F1 score score:  0.9586268352711533\n",
      "Recall:  0.9452301255230126\n",
      "Precision:  0.9724087465564738\n",
      "Confusion matrix: \n",
      " [[31123   641]\n",
      " [ 1309 22591]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.98      0.97     31764\n",
      "         1.0       0.97      0.95      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.97      0.96      0.96     55664\n",
      "weighted avg       0.97      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9798199219241909\n",
      "Sensitivity:  0.9452301255230126\n",
      "TP;  22591\n",
      "FP;  641\n",
      "TN;  31123\n",
      "FN;  1309\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9695320219168239\n",
      "F1 score score:  0.9646460435253897\n",
      "Recall:  0.9681171548117155\n",
      "Precision:  0.9611997341309405\n",
      "Confusion matrix: \n",
      " [[30831   934]\n",
      " [  762 23138]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9705965685502912\n",
      "Sensitivity:  0.9681171548117155\n",
      "TP;  23138\n",
      "FP;  934\n",
      "TN;  30831\n",
      "FN;  762\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_4_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9629203794193734\n",
      "F1 score score:  0.956459370517256\n",
      "Recall:  0.9485355648535565\n",
      "Precision:  0.9645166780122533\n",
      "Confusion matrix: \n",
      " [[30930   834]\n",
      " [ 1230 22670]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97     31764\n",
      "         1.0       0.96      0.95      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9737438609746883\n",
      "Sensitivity:  0.9485355648535565\n",
      "TP;  22670\n",
      "FP;  834\n",
      "TN;  30930\n",
      "FN;  1230\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9471292037941937\n",
      "F1 score score:  0.9390089735353242\n",
      "Recall:  0.947907949790795\n",
      "Precision:  0.930275530735433\n",
      "Confusion matrix: \n",
      " [[30066  1698]\n",
      " [ 1245 22655]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9465432565168115\n",
      "Sensitivity:  0.947907949790795\n",
      "TP;  22655\n",
      "FP;  1698\n",
      "TN;  30066\n",
      "FN;  1245\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9445242885886749\n",
      "F1 score score:  0.9359016937894388\n",
      "Recall:  0.9432635983263599\n",
      "Precision:  0.9286538144669633\n",
      "Confusion matrix: \n",
      " [[30032  1732]\n",
      " [ 1356 22544]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9454728623599042\n",
      "Sensitivity:  0.9432635983263599\n",
      "TP;  22544\n",
      "FP;  1732\n",
      "TN;  30032\n",
      "FN;  1356\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9536128777262765\n",
      "F1 score score:  0.9459131090535842\n",
      "Recall:  0.9446861924686193\n",
      "Precision:  0.9471432167128114\n",
      "Confusion matrix: \n",
      " [[30502  1260]\n",
      " [ 1322 22578]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.95      0.94      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9603299540331214\n",
      "Sensitivity:  0.9446861924686193\n",
      "TP;  22578\n",
      "FP;  1260\n",
      "TN;  30502\n",
      "FN;  1322\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9473608565987568\n",
      "F1 score score:  0.940831987075929\n",
      "Recall:  0.9746861924686192\n",
      "Precision:  0.9092505854800936\n",
      "Confusion matrix: \n",
      " [[29437  2325]\n",
      " [  605 23295]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95     31762\n",
      "         1.0       0.91      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.94      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9267993199420691\n",
      "Sensitivity:  0.9746861924686192\n",
      "TP;  23295\n",
      "FP;  2325\n",
      "TN;  29437\n",
      "FN;  605\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9449554469675194\n",
      "F1 score score:  0.9367125211715619\n",
      "Recall:  0.948744769874477\n",
      "Precision:  0.9249816431426939\n",
      "Confusion matrix: \n",
      " [[29925  1839]\n",
      " [ 1225 22675]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     31764\n",
      "         1.0       0.92      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.95      0.94      0.95     55664\n",
      "\n",
      "Specificity:  0.9421042689837552\n",
      "Sensitivity:  0.948744769874477\n",
      "TP;  22675\n",
      "FP;  1839\n",
      "TN;  29925\n",
      "FN;  1225\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_5_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9585556453786042\n",
      "F1 score score:  0.9518723271096277\n",
      "Recall:  0.954560669456067\n",
      "Precision:  0.9491990846681923\n",
      "Confusion matrix: \n",
      " [[30544  1221]\n",
      " [ 1086 22814]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.95      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9615614670234535\n",
      "Sensitivity:  0.954560669456067\n",
      "TP;  22814\n",
      "FP;  1221\n",
      "TN;  30544\n",
      "FN;  1086\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9691727297224468\n",
      "F1 score score:  0.9644646924829157\n",
      "Recall:  0.9743514644351464\n",
      "Precision:  0.9547765477654776\n",
      "Confusion matrix: \n",
      " [[30662  1103]\n",
      " [  613 23287]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9652762474421533\n",
      "Sensitivity:  0.9743514644351464\n",
      "TP;  23287\n",
      "FP;  1103\n",
      "TN;  30662\n",
      "FN;  613\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_5_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9565795383095302\n",
      "F1 score score:  0.9501289590426081\n",
      "Recall:  0.963347280334728\n",
      "Precision:  0.9372684714024018\n",
      "Confusion matrix: \n",
      " [[30224  1541]\n",
      " [  876 23024]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31765\n",
      "         1.0       0.94      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9514874862269794\n",
      "Sensitivity:  0.963347280334728\n",
      "TP;  23024\n",
      "FP;  1541\n",
      "TN;  30224\n",
      "FN;  876\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_3_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.967915207042127\n",
      "F1 score score:  0.9630518432703049\n",
      "Recall:  0.9738912133891213\n",
      "Precision:  0.9524511007447418\n",
      "Confusion matrix: \n",
      " [[30603  1162]\n",
      " [  624 23276]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9634188572328034\n",
      "Sensitivity:  0.9738912133891213\n",
      "TP;  23276\n",
      "FP;  1162\n",
      "TN;  30603\n",
      "FN;  624\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9480993101465939\n",
      "F1 score score:  0.9406447106198509\n",
      "Recall:  0.9578242677824268\n",
      "Precision:  0.924070560691075\n",
      "Confusion matrix: \n",
      " [[29883  1881]\n",
      " [ 1008 22892]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9407820173781639\n",
      "Sensitivity:  0.9578242677824268\n",
      "TP;  22892\n",
      "FP;  1881\n",
      "TN;  29883\n",
      "FN;  1008\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_5_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9546573250696129\n",
      "F1 score score:  0.9479372937293729\n",
      "Recall:  0.9614225941422594\n",
      "Precision:  0.9348250610252238\n",
      "Confusion matrix: \n",
      " [[30163  1602]\n",
      " [  922 22978]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31765\n",
      "         1.0       0.93      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55665\n",
      "   macro avg       0.95      0.96      0.95     55665\n",
      "weighted avg       0.96      0.95      0.95     55665\n",
      "\n",
      "Specificity:  0.9495671336376516\n",
      "Sensitivity:  0.9614225941422594\n",
      "TP;  22978\n",
      "FP;  1602\n",
      "TN;  30163\n",
      "FN;  922\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9662265337285547\n",
      "F1 score score:  0.9608398600233294\n",
      "Recall:  0.9650209205020921\n",
      "Precision:  0.9566948730711797\n",
      "Confusion matrix: \n",
      " [[30721  1044]\n",
      " [  836 23064]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9671336376515032\n",
      "Sensitivity:  0.9650209205020921\n",
      "TP;  23064\n",
      "FP;  1044\n",
      "TN;  30721\n",
      "FN;  836\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9493370701735475\n",
      "F1 score score:  0.942177568177158\n",
      "Recall:  0.9612970711297071\n",
      "Precision:  0.9238037796542018\n",
      "Confusion matrix: \n",
      " [[29867  1895]\n",
      " [  925 22975]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31762\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9403375102323531\n",
      "Sensitivity:  0.9612970711297071\n",
      "TP;  22975\n",
      "FP;  1895\n",
      "TN;  29867\n",
      "FN;  925\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9337812589824662\n",
      "F1 score score:  0.927231807951988\n",
      "Recall:  0.9825941422594142\n",
      "Precision:  0.8777752859385513\n",
      "Confusion matrix: \n",
      " [[28494  3270]\n",
      " [  416 23484]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.94     31764\n",
      "         1.0       0.88      0.98      0.93     23900\n",
      "\n",
      "    accuracy                           0.93     55664\n",
      "   macro avg       0.93      0.94      0.93     55664\n",
      "weighted avg       0.94      0.93      0.93     55664\n",
      "\n",
      "Specificity:  0.8970532678503966\n",
      "Sensitivity:  0.9825941422594142\n",
      "TP;  23484\n",
      "FP;  3270\n",
      "TN;  28494\n",
      "FN;  416\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9481172750790458\n",
      "F1 score score:  0.9391333670544596\n",
      "Recall:  0.9322175732217574\n",
      "Precision:  0.9461525394937998\n",
      "Confusion matrix: \n",
      " [[30496  1268]\n",
      " [ 1620 22280]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     31764\n",
      "         1.0       0.95      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9600805943835788\n",
      "Sensitivity:  0.9322175732217574\n",
      "TP;  22280\n",
      "FP;  1268\n",
      "TN;  30496\n",
      "FN;  1620\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9589688314021377\n",
      "F1 score score:  0.952495840266223\n",
      "Recall:  0.9580753138075314\n",
      "Precision:  0.946980976013234\n",
      "Confusion matrix: \n",
      " [[30483  1282]\n",
      " [ 1002 22898]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.95      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9596411144341256\n",
      "Sensitivity:  0.9580753138075314\n",
      "TP;  22898\n",
      "FP;  1282\n",
      "TN;  30483\n",
      "FN;  1002\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9595077696937034\n",
      "F1 score score:  0.9530122993537629\n",
      "Recall:  0.9564016736401674\n",
      "Precision:  0.9496468633153303\n",
      "Confusion matrix: \n",
      " [[30553  1212]\n",
      " [ 1042 22858]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.95      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9618447977333543\n",
      "Sensitivity:  0.9564016736401674\n",
      "TP;  22858\n",
      "FP;  1212\n",
      "TN;  30553\n",
      "FN;  1042\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9540440515971399\n",
      "F1 score score:  0.9468434395910393\n",
      "Recall:  0.9532217573221757\n",
      "Precision:  0.9405499133019569\n",
      "Confusion matrix: \n",
      " [[30322  1440]\n",
      " [ 1118 22782]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.96     31762\n",
      "         1.0       0.94      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9546628046092815\n",
      "Sensitivity:  0.9532217573221757\n",
      "TP;  22782\n",
      "FP;  1440\n",
      "TN;  30322\n",
      "FN;  1118\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9524990118932126\n",
      "F1 score score:  0.9456056616194866\n",
      "Recall:  0.9615899581589958\n",
      "Precision:  0.9301440828881334\n",
      "Confusion matrix: \n",
      " [[30036  1726]\n",
      " [  918 22982]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31762\n",
      "         1.0       0.93      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9456583338580694\n",
      "Sensitivity:  0.9615899581589958\n",
      "TP;  22982\n",
      "FP;  1726\n",
      "TN;  30036\n",
      "FN;  918\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_5_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9551782987514597\n",
      "F1 score score:  0.9479720571368992\n",
      "Recall:  0.9510460251046026\n",
      "Precision:  0.9449178964872168\n",
      "Confusion matrix: \n",
      " [[30440  1325]\n",
      " [ 1170 22730]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31765\n",
      "         1.0       0.94      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.95      0.95     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9582874232645994\n",
      "Sensitivity:  0.9510460251046026\n",
      "TP;  22730\n",
      "FP;  1325\n",
      "TN;  30440\n",
      "FN;  1170\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_5_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9565436090900925\n",
      "F1 score score:  0.9499327331056608\n",
      "Recall:  0.9601673640167364\n",
      "Precision:  0.9399139873028876\n",
      "Confusion matrix: \n",
      " [[30298  1467]\n",
      " [  952 22948]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31765\n",
      "         1.0       0.94      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.953817094286164\n",
      "Sensitivity:  0.9601673640167364\n",
      "TP;  22948\n",
      "FP;  1467\n",
      "TN;  30298\n",
      "FN;  952\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9338351537798217\n",
      "F1 score score:  0.9273613001203084\n",
      "Recall:  0.9836820083682009\n",
      "Precision:  0.8771406185874715\n",
      "Confusion matrix: \n",
      " [[28471  3293]\n",
      " [  390 23510]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.90      0.94     31764\n",
      "         1.0       0.88      0.98      0.93     23900\n",
      "\n",
      "    accuracy                           0.93     55664\n",
      "   macro avg       0.93      0.94      0.93     55664\n",
      "weighted avg       0.94      0.93      0.93     55664\n",
      "\n",
      "Specificity:  0.8963291776854301\n",
      "Sensitivity:  0.9836820083682009\n",
      "TP;  23510\n",
      "FP;  3293\n",
      "TN;  28471\n",
      "FN;  390\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9504509360066113\n",
      "F1 score score:  0.9423422670067317\n",
      "Recall:  0.9430125523012552\n",
      "Precision:  0.9416729339015626\n",
      "Confusion matrix: \n",
      " [[30366  1396]\n",
      " [ 1362 22538]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9560481078017757\n",
      "Sensitivity:  0.9430125523012552\n",
      "TP;  22538\n",
      "FP;  1396\n",
      "TN;  30366\n",
      "FN;  1362\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_4_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9639982753664846\n",
      "F1 score score:  0.9582116940528818\n",
      "Recall:  0.9613389121338912\n",
      "Precision:  0.9551047555703359\n",
      "Confusion matrix: \n",
      " [[30684  1080]\n",
      " [  924 22976]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.965999244427654\n",
      "Sensitivity:  0.9613389121338912\n",
      "TP;  22976\n",
      "FP;  1080\n",
      "TN;  30684\n",
      "FN;  924\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9475783271054901\n",
      "F1 score score:  0.9401263952724885\n",
      "Recall:  0.9585355648535565\n",
      "Precision:  0.9224110162667096\n",
      "Confusion matrix: \n",
      " [[29837  1927]\n",
      " [  991 22909]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9393338370482307\n",
      "Sensitivity:  0.9585355648535565\n",
      "TP;  22909\n",
      "FP;  1927\n",
      "TN;  29837\n",
      "FN;  991\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9667475074104015\n",
      "F1 score score:  0.9617047688010758\n",
      "Recall:  0.9724686192468619\n",
      "Precision:  0.9511765909555965\n",
      "Confusion matrix: \n",
      " [[30572  1193]\n",
      " [  658 23242]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9624429403431449\n",
      "Sensitivity:  0.9724686192468619\n",
      "TP;  23242\n",
      "FP;  1193\n",
      "TN;  30572\n",
      "FN;  658\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_4_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9639623455015809\n",
      "F1 score score:  0.958246607276663\n",
      "Recall:  0.9631380753138076\n",
      "Precision:  0.9534045725646123\n",
      "Confusion matrix: \n",
      " [[30639  1125]\n",
      " [  881 23019]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97     31764\n",
      "         1.0       0.95      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9645825462788062\n",
      "Sensitivity:  0.9631380753138076\n",
      "TP;  23019\n",
      "FP;  1125\n",
      "TN;  30639\n",
      "FN;  881\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9539721892853293\n",
      "F1 score score:  0.9463455497382198\n",
      "Recall:  0.9453556485355649\n",
      "Precision:  0.9473375262054508\n",
      "Confusion matrix: \n",
      " [[30506  1256]\n",
      " [ 1306 22594]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.95      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9604558906869844\n",
      "Sensitivity:  0.9453556485355649\n",
      "TP;  22594\n",
      "FP;  1256\n",
      "TN;  30506\n",
      "FN;  1306\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9689391897961017\n",
      "F1 score score:  0.9640772059587376\n",
      "Recall:  0.9707531380753138\n",
      "Precision:  0.9574924683256985\n",
      "Confusion matrix: \n",
      " [[30735  1030]\n",
      " [  699 23201]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.967574374311349\n",
      "Sensitivity:  0.9707531380753138\n",
      "TP;  23201\n",
      "FP;  1030\n",
      "TN;  30735\n",
      "FN;  699\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9586813976466362\n",
      "F1 score score:  0.9521928912907919\n",
      "Recall:  0.9583682008368201\n",
      "Precision:  0.9460966542750929\n",
      "Confusion matrix: \n",
      " [[30460  1305]\n",
      " [  995 22905]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.95      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9589170470643791\n",
      "Sensitivity:  0.9583682008368201\n",
      "TP;  22905\n",
      "FP;  1305\n",
      "TN;  30460\n",
      "FN;  995\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_5_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9593460882062337\n",
      "F1 score score:  0.9531227343345416\n",
      "Recall:  0.9625941422594142\n",
      "Precision:  0.9438358974358975\n",
      "Confusion matrix: \n",
      " [[30396  1369]\n",
      " [  894 23006]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.94      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9569022509050842\n",
      "Sensitivity:  0.9625941422594142\n",
      "TP;  23006\n",
      "FP;  1369\n",
      "TN;  30396\n",
      "FN;  894\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_4_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9611598160390917\n",
      "F1 score score:  0.9547698744769875\n",
      "Recall:  0.9547698744769875\n",
      "Precision:  0.9547698744769875\n",
      "Confusion matrix: \n",
      " [[30683  1081]\n",
      " [ 1081 22819]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.95      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9659677622465684\n",
      "Sensitivity:  0.9547698744769875\n",
      "TP;  22819\n",
      "FP;  1081\n",
      "TN;  30683\n",
      "FN;  1081\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9705560046707985\n",
      "F1 score score:  0.9657335201020258\n",
      "Recall:  0.9663598326359832\n",
      "Precision:  0.9651080188876353\n",
      "Confusion matrix: \n",
      " [[30930   835]\n",
      " [  804 23096]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31765\n",
      "         1.0       0.97      0.97      0.97     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9737132063592003\n",
      "Sensitivity:  0.9663598326359832\n",
      "TP;  23096\n",
      "FP;  835\n",
      "TN;  30930\n",
      "FN;  804\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_4_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9642138545559069\n",
      "F1 score score:  0.9581407077414473\n",
      "Recall:  0.9538912133891213\n",
      "Precision:  0.9624282337048294\n",
      "Confusion matrix: \n",
      " [[30874   890]\n",
      " [ 1102 22798]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.95      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9719808588339001\n",
      "Sensitivity:  0.9538912133891213\n",
      "TP;  22798\n",
      "FP;  890\n",
      "TN;  30874\n",
      "FN;  1102\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_4_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9653276803679218\n",
      "F1 score score:  0.9593923581888572\n",
      "Recall:  0.9539330543933054\n",
      "Precision:  0.9649145082105975\n",
      "Confusion matrix: \n",
      " [[30935   829]\n",
      " [ 1101 22799]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.95      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55664\n",
      "   macro avg       0.97      0.96      0.96     55664\n",
      "weighted avg       0.97      0.97      0.97     55664\n",
      "\n",
      "Specificity:  0.9739012718801159\n",
      "Sensitivity:  0.9539330543933054\n",
      "TP;  22799\n",
      "FP;  829\n",
      "TN;  30935\n",
      "FN;  1101\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_5_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9558429893110573\n",
      "F1 score score:  0.9489829804898298\n",
      "Recall:  0.9565271966527197\n",
      "Precision:  0.9415568369028007\n",
      "Confusion matrix: \n",
      " [[30346  1419]\n",
      " [ 1039 22861]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.94      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9553281914056352\n",
      "Sensitivity:  0.9565271966527197\n",
      "TP;  22861\n",
      "FP;  1419\n",
      "TN;  30346\n",
      "FN;  1039\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_4_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9643216441506179\n",
      "F1 score score:  0.9585005015045136\n",
      "Recall:  0.9596234309623431\n",
      "Precision:  0.9573801970278845\n",
      "Confusion matrix: \n",
      " [[30743  1021]\n",
      " [  965 22935]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9678566931116988\n",
      "Sensitivity:  0.9596234309623431\n",
      "TP;  22935\n",
      "FP;  1021\n",
      "TN;  30743\n",
      "FN;  965\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9430691290600748\n",
      "F1 score score:  0.9342299151152896\n",
      "Recall:  0.9417154811715481\n",
      "Precision:  0.9268624140345098\n",
      "Confusion matrix: \n",
      " [[29988  1776]\n",
      " [ 1393 22507]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     31764\n",
      "         1.0       0.93      0.94      0.93     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.944087646392142\n",
      "Sensitivity:  0.9417154811715481\n",
      "TP;  22507\n",
      "FP;  1776\n",
      "TN;  29988\n",
      "FN;  1393\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9485125035929864\n",
      "F1 score score:  0.9405961115947437\n",
      "Recall:  0.9493723849372385\n",
      "Precision:  0.9319806128316767\n",
      "Confusion matrix: \n",
      " [[30108  1656]\n",
      " [ 1210 22690]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9478655081224027\n",
      "Sensitivity:  0.9493723849372385\n",
      "TP;  22690\n",
      "FP;  1656\n",
      "TN;  30108\n",
      "FN;  1210\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9479716862491466\n",
      "F1 score score:  0.9392821200939282\n",
      "Recall:  0.9372384937238494\n",
      "Precision:  0.9413346780971592\n",
      "Confusion matrix: \n",
      " [[30366  1396]\n",
      " [ 1500 22400]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.95     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9560481078017757\n",
      "Sensitivity:  0.9372384937238494\n",
      "TP;  22400\n",
      "FP;  1396\n",
      "TN;  30366\n",
      "FN;  1500\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9446859729807416\n",
      "F1 score score:  0.9369587027292643\n",
      "Recall:  0.9573640167364017\n",
      "Precision:  0.9174050759793112\n",
      "Confusion matrix: \n",
      " [[29704  2060]\n",
      " [ 1019 22881]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.94      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.95      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9351467069638585\n",
      "Sensitivity:  0.9573640167364017\n",
      "TP;  22881\n",
      "FP;  2060\n",
      "TN;  29704\n",
      "FN;  1019\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9427277953434895\n",
      "F1 score score:  0.9345299215509097\n",
      "Recall:  0.9520083682008368\n",
      "Precision:  0.9176816971848027\n",
      "Confusion matrix: \n",
      " [[29723  2041]\n",
      " [ 1147 22753]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     31764\n",
      "         1.0       0.92      0.95      0.93     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.935744868404483\n",
      "Sensitivity:  0.9520083682008368\n",
      "TP;  22753\n",
      "FP;  2041\n",
      "TN;  29723\n",
      "FN;  1147\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_5_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9588610437438246\n",
      "F1 score score:  0.9521321070234114\n",
      "Recall:  0.952928870292887\n",
      "Precision:  0.9513366750208856\n",
      "Confusion matrix: \n",
      " [[30600  1165]\n",
      " [ 1125 22775]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31765\n",
      "         1.0       0.95      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9633244136628365\n",
      "Sensitivity:  0.952928870292887\n",
      "TP;  22775\n",
      "FP;  1165\n",
      "TN;  30600\n",
      "FN;  1125\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9498401063562215\n",
      "F1 score score:  0.9410472972972973\n",
      "Recall:  0.9323849372384937\n",
      "Precision:  0.9498721227621484\n",
      "Confusion matrix: \n",
      " [[30586  1176]\n",
      " [ 1616 22284]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     31762\n",
      "         1.0       0.95      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9629746237642466\n",
      "Sensitivity:  0.9323849372384937\n",
      "TP;  22284\n",
      "FP;  1176\n",
      "TN;  30586\n",
      "FN;  1616\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_5_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9557890954819006\n",
      "F1 score score:  0.949388174807198\n",
      "Recall:  0.9657740585774058\n",
      "Precision:  0.9335490394337714\n",
      "Confusion matrix: \n",
      " [[30122  1643]\n",
      " [  818 23082]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31765\n",
      "         1.0       0.93      0.97      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9482764048481033\n",
      "Sensitivity:  0.9657740585774058\n",
      "TP;  23082\n",
      "FP;  1643\n",
      "TN;  30122\n",
      "FN;  818\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_3_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9683104284559418\n",
      "F1 score score:  0.9633660076424655\n",
      "Recall:  0.9704602510460251\n",
      "Precision:  0.9563747319808675\n",
      "Confusion matrix: \n",
      " [[30707  1058]\n",
      " [  706 23194]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9666929009916575\n",
      "Sensitivity:  0.9704602510460251\n",
      "TP;  23194\n",
      "FP;  1058\n",
      "TN;  30707\n",
      "FN;  706\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9482950666522942\n",
      "F1 score score:  0.9415634517766497\n",
      "Recall:  0.9701255230125523\n",
      "Precision:  0.9146351084812623\n",
      "Confusion matrix: \n",
      " [[29598  2164]\n",
      " [  714 23186]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.93      0.95     31762\n",
      "         1.0       0.91      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9318682702600591\n",
      "Sensitivity:  0.9701255230125523\n",
      "TP;  23186\n",
      "FP;  2164\n",
      "TN;  29598\n",
      "FN;  714\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_5_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9579089194287254\n",
      "F1 score score:  0.9512332188573211\n",
      "Recall:  0.9561087866108786\n",
      "Precision:  0.9464071236280803\n",
      "Confusion matrix: \n",
      " [[30471  1294]\n",
      " [ 1049 22851]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     31765\n",
      "         1.0       0.95      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9592633401542578\n",
      "Sensitivity:  0.9561087866108786\n",
      "TP;  22851\n",
      "FP;  1294\n",
      "TN;  30471\n",
      "FN;  1049\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.951169559124717\n",
      "F1 score score:  0.9428343078282084\n",
      "Recall:  0.9378242677824268\n",
      "Precision:  0.9478981645944345\n",
      "Confusion matrix: \n",
      " [[30530  1232]\n",
      " [ 1486 22414]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     31762\n",
      "         1.0       0.95      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9612115106101631\n",
      "Sensitivity:  0.9378242677824268\n",
      "TP;  22414\n",
      "FP;  1232\n",
      "TN;  30530\n",
      "FN;  1486\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9559328123596514\n",
      "F1 score score:  0.9491974733354044\n",
      "Recall:  0.9588284518828452\n",
      "Precision:  0.9397580479803158\n",
      "Confusion matrix: \n",
      " [[30296  1469]\n",
      " [  984 22916]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.95      0.96     31765\n",
      "         1.0       0.94      0.96      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.95      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9537541319061861\n",
      "Sensitivity:  0.9588284518828452\n",
      "TP;  22916\n",
      "FP;  1469\n",
      "TN;  30296\n",
      "FN;  984\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.943033199195171\n",
      "F1 score score:  0.9350750394136075\n",
      "Recall:  0.955439330543933\n",
      "Precision:  0.9155607233070046\n",
      "Confusion matrix: \n",
      " [[29658  2106]\n",
      " [ 1065 22835]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.94      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9336985266339252\n",
      "Sensitivity:  0.955439330543933\n",
      "TP;  22835\n",
      "FP;  2106\n",
      "TN;  29658\n",
      "FN;  1065\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.970609898499955\n",
      "F1 score score:  0.9658241069563401\n",
      "Recall:  0.9672384937238494\n",
      "Precision:  0.9644138506466416\n",
      "Confusion matrix: \n",
      " [[30912   853]\n",
      " [  783 23117]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.97     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9731465449393987\n",
      "Sensitivity:  0.9672384937238494\n",
      "TP;  23117\n",
      "FP;  853\n",
      "TN;  30912\n",
      "FN;  783\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9486903093672523\n",
      "F1 score score:  0.9400755350398656\n",
      "Recall:  0.9373221757322175\n",
      "Precision:  0.9428451178451178\n",
      "Confusion matrix: \n",
      " [[30404  1358]\n",
      " [ 1498 22402]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.96      0.96     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9572445060134752\n",
      "Sensitivity:  0.9373221757322175\n",
      "TP;  22402\n",
      "FP;  1358\n",
      "TN;  30404\n",
      "FN;  1498\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_4_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.963710836447255\n",
      "F1 score score:  0.9574342548887391\n",
      "Recall:  0.9505439330543933\n",
      "Precision:  0.9644251995245373\n",
      "Confusion matrix: \n",
      " [[30926   838]\n",
      " [ 1182 22718]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.97      0.97     31764\n",
      "         1.0       0.96      0.95      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9736179322503463\n",
      "Sensitivity:  0.9505439330543933\n",
      "TP;  22718\n",
      "FP;  838\n",
      "TN;  30926\n",
      "FN;  1182\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.946482466225927\n",
      "F1 score score:  0.9383344718375458\n",
      "Recall:  0.948326359832636\n",
      "Precision:  0.928550944323815\n",
      "Confusion matrix: \n",
      " [[30020  1744]\n",
      " [ 1235 22665]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.95      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.94      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9450950761868783\n",
      "Sensitivity:  0.948326359832636\n",
      "TP;  22665\n",
      "FP;  1744\n",
      "TN;  30020\n",
      "FN;  1235\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9659929938022096\n",
      "F1 score score:  0.9611779906072475\n",
      "Recall:  0.9805020920502092\n",
      "Precision:  0.9426008607859699\n",
      "Confusion matrix: \n",
      " [[30338  1427]\n",
      " [  466 23434]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.94      0.98      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.96      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9550763418857233\n",
      "Sensitivity:  0.9805020920502092\n",
      "TP;  23434\n",
      "FP;  1427\n",
      "TN;  30338\n",
      "FN;  466\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_4_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9622017821212993\n",
      "F1 score score:  0.9562759767248546\n",
      "Recall:  0.9626778242677825\n",
      "Precision:  0.9499587118084228\n",
      "Confusion matrix: \n",
      " [[30552  1212]\n",
      " [  892 23008]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97     31764\n",
      "         1.0       0.95      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9618435965243672\n",
      "Sensitivity:  0.9626778242677825\n",
      "TP;  23008\n",
      "FP;  1212\n",
      "TN;  30552\n",
      "FN;  892\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9505587294743272\n",
      "F1 score score:  0.9415363698164514\n",
      "Recall:  0.9271966527196652\n",
      "Precision:  0.9563266010702572\n",
      "Confusion matrix: \n",
      " [[30750  1012]\n",
      " [ 1740 22160]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9681380265726339\n",
      "Sensitivity:  0.9271966527196652\n",
      "TP;  22160\n",
      "FP;  1012\n",
      "TN;  30750\n",
      "FN;  1740\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_3_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9666756489715261\n",
      "F1 score score:  0.9616838452481771\n",
      "Recall:  0.9740167364016736\n",
      "Precision:  0.9496593644188798\n",
      "Confusion matrix: \n",
      " [[30531  1234]\n",
      " [  621 23279]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31765\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.96      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9611522115535968\n",
      "Sensitivity:  0.9740167364016736\n",
      "TP;  23279\n",
      "FP;  1234\n",
      "TN;  30531\n",
      "FN;  621\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.969765561843169\n",
      "F1 score score:  0.9649192287649817\n",
      "Recall:  0.9684518828451882\n",
      "Precision:  0.9614122533748702\n",
      "Confusion matrix: \n",
      " [[30836   929]\n",
      " [  754 23146]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9707539745002361\n",
      "Sensitivity:  0.9684518828451882\n",
      "TP;  23146\n",
      "FP;  929\n",
      "TN;  30836\n",
      "FN;  754\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_4_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.963207818338603\n",
      "F1 score score:  0.9571045576407508\n",
      "Recall:  0.9559832635983263\n",
      "Precision:  0.9582284851534978\n",
      "Confusion matrix: \n",
      " [[30768   996]\n",
      " [ 1052 22848]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9686437476388364\n",
      "Sensitivity:  0.9559832635983263\n",
      "TP;  22848\n",
      "FP;  996\n",
      "TN;  30768\n",
      "FN;  1052\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9426918654785859\n",
      "F1 score score:  0.9354721255765029\n",
      "Recall:  0.967489539748954\n",
      "Precision:  0.9055059523809523\n",
      "Confusion matrix: \n",
      " [[29351  2413]\n",
      " [  777 23123]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.92      0.95     31764\n",
      "         1.0       0.91      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.924033497040675\n",
      "Sensitivity:  0.967489539748954\n",
      "TP;  23123\n",
      "FP;  2413\n",
      "TN;  29351\n",
      "FN;  777\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_5_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9575855564537861\n",
      "F1 score score:  0.9505083324599098\n",
      "Recall:  0.9486192468619247\n",
      "Precision:  0.9524049569418189\n",
      "Confusion matrix: \n",
      " [[30632  1133]\n",
      " [ 1228 22672]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31765\n",
      "         1.0       0.95      0.95      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9643318117424838\n",
      "Sensitivity:  0.9486192468619247\n",
      "TP;  22672\n",
      "FP;  1133\n",
      "TN;  30632\n",
      "FN;  1228\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_4_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9653995400977292\n",
      "F1 score score:  0.9596158684894741\n",
      "Recall:  0.9574476987447699\n",
      "Precision:  0.9617938802958977\n",
      "Confusion matrix: \n",
      " [[30855   909]\n",
      " [ 1017 22883]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.97      0.97      0.97     55664\n",
      "\n",
      "Specificity:  0.9713826973932754\n",
      "Sensitivity:  0.9574476987447699\n",
      "TP;  22883\n",
      "FP;  909\n",
      "TN;  30855\n",
      "FN;  1017\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_3_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9532381209018234\n",
      "F1 score score:  0.9479992808198654\n",
      "Recall:  0.9927615062761507\n",
      "Precision:  0.907099438008946\n",
      "Confusion matrix: \n",
      " [[29335  2430]\n",
      " [  173 23727]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.92      0.96     31765\n",
      "         1.0       0.91      0.99      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55665\n",
      "   macro avg       0.95      0.96      0.95     55665\n",
      "weighted avg       0.96      0.95      0.95     55665\n",
      "\n",
      "Specificity:  0.9235007083267748\n",
      "Sensitivity:  0.9927615062761507\n",
      "TP;  23727\n",
      "FP;  2430\n",
      "TN;  29335\n",
      "FN;  173\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_4_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9604052888761139\n",
      "F1 score score:  0.9547321721984884\n",
      "Recall:  0.9724686192468619\n",
      "Precision:  0.937631111828304\n",
      "Confusion matrix: \n",
      " [[30218  1546]\n",
      " [  658 23242]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96     31764\n",
      "         1.0       0.94      0.97      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9513285480418083\n",
      "Sensitivity:  0.9724686192468619\n",
      "TP;  23242\n",
      "FP;  1546\n",
      "TN;  30218\n",
      "FN;  658\n",
      "\n",
      "        ############################################\n",
      "        uni_lstm_model_ws_4_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.961986202931877\n",
      "F1 score score:  0.9558982909545645\n",
      "Recall:  0.9594979079497908\n",
      "Precision:  0.9523255813953488\n",
      "Confusion matrix: \n",
      " [[30616  1148]\n",
      " [  968 22932]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.97     31764\n",
      "         1.0       0.95      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9638584561138396\n",
      "Sensitivity:  0.9594979079497908\n",
      "TP;  22932\n",
      "FP;  1148\n",
      "TN;  30616\n",
      "FN;  968\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9545470877798139\n",
      "F1 score score:  0.9464572928130027\n",
      "Recall:  0.9356066945606695\n",
      "Precision:  0.9575625214114423\n",
      "Confusion matrix: \n",
      " [[30771   991]\n",
      " [ 1539 22361]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.94      0.95     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9687991940054153\n",
      "Sensitivity:  0.9356066945606695\n",
      "TP;  22361\n",
      "FP;  991\n",
      "TN;  30771\n",
      "FN;  1539\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_3_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9688314021377885\n",
      "F1 score score:  0.9639750005190922\n",
      "Recall:  0.9712552301255231\n",
      "Precision:  0.9568030996249124\n",
      "Confusion matrix: \n",
      " [[30717  1048]\n",
      " [  687 23213]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9670077128915473\n",
      "Sensitivity:  0.9712552301255231\n",
      "TP;  23213\n",
      "FP;  1048\n",
      "TN;  30717\n",
      "FN;  687\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_6_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9523193561136861\n",
      "F1 score score:  0.943690061953662\n",
      "Recall:  0.9305020920502092\n",
      "Precision:  0.9572572314049587\n",
      "Confusion matrix: \n",
      " [[30769   993]\n",
      " [ 1661 22239]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9687362256784837\n",
      "Sensitivity:  0.9305020920502092\n",
      "TP;  22239\n",
      "FP;  993\n",
      "TN;  30769\n",
      "FN;  1661\n",
      "\n",
      "        ############################################\n",
      "        multi_cnn_model_ws_6_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9522474938018756\n",
      "F1 score score:  0.9437126762949473\n",
      "Recall:  0.9323012552301255\n",
      "Precision:  0.955406911928651\n",
      "Confusion matrix: \n",
      " [[30722  1040]\n",
      " [ 1618 22282]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.97      0.96     31762\n",
      "         1.0       0.96      0.93      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9672564699955922\n",
      "Sensitivity:  0.9323012552301255\n",
      "TP;  22282\n",
      "FP;  1040\n",
      "TN;  30722\n",
      "FN;  1618\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_bis_ws_3_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9653283032426121\n",
      "F1 score score:  0.9597581317764804\n",
      "Recall:  0.9629707112970711\n",
      "Precision:  0.9565669160432253\n",
      "Confusion matrix: \n",
      " [[30720  1045]\n",
      " [  885 23015]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31765\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.96      0.97      0.96     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.9671021564615142\n",
      "Sensitivity:  0.9629707112970711\n",
      "TP;  23015\n",
      "FP;  1045\n",
      "TN;  30720\n",
      "FN;  885\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_6_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9499838309798426\n",
      "F1 score score:  0.9416596814752725\n",
      "Recall:  0.9400836820083682\n",
      "Precision:  0.9432409739714526\n",
      "Confusion matrix: \n",
      " [[30410  1352]\n",
      " [ 1432 22468]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.96      0.96     31762\n",
      "         1.0       0.94      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55662\n",
      "   macro avg       0.95      0.95      0.95     55662\n",
      "weighted avg       0.95      0.95      0.95     55662\n",
      "\n",
      "Specificity:  0.9574334109942699\n",
      "Sensitivity:  0.9400836820083682\n",
      "TP;  22468\n",
      "FP;  1352\n",
      "TN;  30410\n",
      "FN;  1432\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_4_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9639982753664846\n",
      "F1 score score:  0.9581977471839799\n",
      "Recall:  0.9610041841004184\n",
      "Precision:  0.9554076539101497\n",
      "Confusion matrix: \n",
      " [[30692  1072]\n",
      " [  932 22968]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.966251101876338\n",
      "Sensitivity:  0.9610041841004184\n",
      "TP;  22968\n",
      "FP;  1072\n",
      "TN;  30692\n",
      "FN;  932\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_5_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9596335219617353\n",
      "F1 score score:  0.953693972179289\n",
      "Recall:  0.9681589958158996\n",
      "Precision:  0.9396548223350254\n",
      "Confusion matrix: \n",
      " [[30279  1486]\n",
      " [  761 23139]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.95      0.96     31765\n",
      "         1.0       0.94      0.97      0.95     23900\n",
      "\n",
      "    accuracy                           0.96     55665\n",
      "   macro avg       0.96      0.96      0.96     55665\n",
      "weighted avg       0.96      0.96      0.96     55665\n",
      "\n",
      "Specificity:  0.9532189516763734\n",
      "Sensitivity:  0.9681589958158996\n",
      "TP;  23139\n",
      "FP;  1486\n",
      "TN;  30279\n",
      "FN;  761\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_7_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9436080770336304\n",
      "F1 score score:  0.935803832545964\n",
      "Recall:  0.9572803347280334\n",
      "Precision:  0.9152698323798856\n",
      "Confusion matrix: \n",
      " [[29646  2118]\n",
      " [ 1021 22879]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.93      0.95     31764\n",
      "         1.0       0.92      0.96      0.94     23900\n",
      "\n",
      "    accuracy                           0.94     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.94      0.94      0.94     55664\n",
      "\n",
      "Specificity:  0.9333207404608991\n",
      "Sensitivity:  0.9572803347280334\n",
      "TP;  22879\n",
      "FP;  2118\n",
      "TN;  29646\n",
      "FN;  1021\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_7_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9450273066973268\n",
      "F1 score score:  0.9383809907370116\n",
      "Recall:  0.9748953974895398\n",
      "Precision:  0.9045031055900621\n",
      "Confusion matrix: \n",
      " [[29304  2460]\n",
      " [  600 23300]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.92      0.95     31764\n",
      "         1.0       0.90      0.97      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.94      0.95      0.94     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9225538345296562\n",
      "Sensitivity:  0.9748953974895398\n",
      "TP;  23300\n",
      "FP;  2460\n",
      "TN;  29304\n",
      "FN;  600\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_4_transform_None evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9658666283414774\n",
      "F1 score score:  0.960587454364421\n",
      "Recall:  0.9687866108786611\n",
      "Precision:  0.9525259173934507\n",
      "Confusion matrix: \n",
      " [[30610  1154]\n",
      " [  746 23154]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.96      0.97     31764\n",
      "         1.0       0.95      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55664\n",
      "   macro avg       0.96      0.97      0.97     55664\n",
      "weighted avg       0.97      0.97      0.97     55664\n",
      "\n",
      "Specificity:  0.9636695630273265\n",
      "Sensitivity:  0.9687866108786611\n",
      "TP;  23154\n",
      "FP;  1154\n",
      "TN;  30610\n",
      "FN;  746\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_comp_ws_4_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.964573153204944\n",
      "F1 score score:  0.9587344103122123\n",
      "Recall:  0.9584937238493724\n",
      "Precision:  0.9589752176825184\n",
      "Confusion matrix: \n",
      " [[30784   980]\n",
      " [  992 22908]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9691474625362045\n",
      "Sensitivity:  0.9584937238493724\n",
      "TP;  22908\n",
      "FP;  980\n",
      "TN;  30784\n",
      "FN;  992\n",
      "\n",
      "        ############################################\n",
      "        cnn_two_channels_model_ws_3_transform_fft evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9682385700170664\n",
      "F1 score score:  0.9631589914565535\n",
      "Recall:  0.9669874476987448\n",
      "Precision:  0.9593607305936073\n",
      "Confusion matrix: \n",
      " [[30786   979]\n",
      " [  789 23111]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97     31765\n",
      "         1.0       0.96      0.97      0.96     23900\n",
      "\n",
      "    accuracy                           0.97     55665\n",
      "   macro avg       0.97      0.97      0.97     55665\n",
      "weighted avg       0.97      0.97      0.97     55665\n",
      "\n",
      "Specificity:  0.969179915000787\n",
      "Sensitivity:  0.9669874476987448\n",
      "TP;  23111\n",
      "FP;  979\n",
      "TN;  30786\n",
      "FN;  789\n",
      "\n",
      "        ############################################\n",
      "        cnn_model_ws_7_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9466082207530899\n",
      "F1 score score:  0.938093651058157\n",
      "Recall:  0.9421757322175732\n",
      "Precision:  0.9340467894474863\n",
      "Confusion matrix: \n",
      " [[30174  1590]\n",
      " [ 1382 22518]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.95      0.95     31764\n",
      "         1.0       0.93      0.94      0.94     23900\n",
      "\n",
      "    accuracy                           0.95     55664\n",
      "   macro avg       0.95      0.95      0.95     55664\n",
      "weighted avg       0.95      0.95      0.95     55664\n",
      "\n",
      "Specificity:  0.9499433320740461\n",
      "Sensitivity:  0.9421757322175732\n",
      "TP;  22518\n",
      "FP;  1590\n",
      "TN;  30174\n",
      "FN;  1382\n",
      "\n",
      "        ############################################\n",
      "        multi_lstm_model_ws_4_transform_dct evaluation...\n",
      "        ############################################\n",
      "        \n",
      "########## All test data ##########\n",
      "Accuracy score:  0.9641419948260994\n",
      "F1 score score:  0.9581340716503062\n",
      "Recall:  0.9556485355648535\n",
      "Precision:  0.9606325706594886\n",
      "Confusion matrix: \n",
      " [[30828   936]\n",
      " [ 1060 22840]]\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.97      0.97     31764\n",
      "         1.0       0.96      0.96      0.96     23900\n",
      "\n",
      "    accuracy                           0.96     55664\n",
      "   macro avg       0.96      0.96      0.96     55664\n",
      "weighted avg       0.96      0.96      0.96     55664\n",
      "\n",
      "Specificity:  0.9705326785039667\n",
      "Sensitivity:  0.9556485355648535\n",
      "TP;  22840\n",
      "FP;  936\n",
      "TN;  30828\n",
      "FN;  1060\n"
     ]
    }
   ],
   "source": [
    "all_scores = [evaluate_models(test_df, model_preds, model_name) for model_name, model_preds in predictions.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77200974",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:15:54.507873Z",
     "start_time": "2021-10-15T06:15:54.407867Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>rec</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>sen</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_model_ws_5_transform_fft</td>\n",
       "      <td>0.956526</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.953565</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>30290</td>\n",
       "      <td>1475</td>\n",
       "      <td>945</td>\n",
       "      <td>22955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_model_ws_3_transform_dct</td>\n",
       "      <td>0.969640</td>\n",
       "      <td>0.964820</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>0.960063</td>\n",
       "      <td>0.969652</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>30801</td>\n",
       "      <td>964</td>\n",
       "      <td>726</td>\n",
       "      <td>23174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_dct</td>\n",
       "      <td>0.948403</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>30915</td>\n",
       "      <td>847</td>\n",
       "      <td>2025</td>\n",
       "      <td>21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_cnn_model_ws_5_transform_None</td>\n",
       "      <td>0.960496</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>0.949389</td>\n",
       "      <td>0.961530</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>30543</td>\n",
       "      <td>1222</td>\n",
       "      <td>977</td>\n",
       "      <td>22923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_model_comp_ws_3_transform_None</td>\n",
       "      <td>0.968795</td>\n",
       "      <td>0.964201</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>0.950083</td>\n",
       "      <td>0.961310</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>30536</td>\n",
       "      <td>1229</td>\n",
       "      <td>508</td>\n",
       "      <td>23392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>cnn_model_comp_ws_4_transform_None</td>\n",
       "      <td>0.965867</td>\n",
       "      <td>0.960587</td>\n",
       "      <td>0.968787</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>0.963670</td>\n",
       "      <td>0.968787</td>\n",
       "      <td>30610</td>\n",
       "      <td>1154</td>\n",
       "      <td>746</td>\n",
       "      <td>23154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>cnn_model_comp_ws_4_transform_dct</td>\n",
       "      <td>0.964573</td>\n",
       "      <td>0.958734</td>\n",
       "      <td>0.958494</td>\n",
       "      <td>0.958975</td>\n",
       "      <td>0.969147</td>\n",
       "      <td>0.958494</td>\n",
       "      <td>30784</td>\n",
       "      <td>980</td>\n",
       "      <td>992</td>\n",
       "      <td>22908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cnn_two_channels_model_ws_3_transform_fft</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.963159</td>\n",
       "      <td>0.966987</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.969180</td>\n",
       "      <td>0.966987</td>\n",
       "      <td>30786</td>\n",
       "      <td>979</td>\n",
       "      <td>789</td>\n",
       "      <td>23111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cnn_model_ws_7_transform_dct</td>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.949943</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>30174</td>\n",
       "      <td>1590</td>\n",
       "      <td>1382</td>\n",
       "      <td>22518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>multi_lstm_model_ws_4_transform_dct</td>\n",
       "      <td>0.964142</td>\n",
       "      <td>0.958134</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>0.960633</td>\n",
       "      <td>0.970533</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>30828</td>\n",
       "      <td>936</td>\n",
       "      <td>1060</td>\n",
       "      <td>22840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model_name       acc        f1       rec  \\\n",
       "0                cnn_model_ws_5_transform_fft  0.956526  0.949928  0.960460   \n",
       "1                cnn_model_ws_3_transform_dct  0.969640  0.964820  0.969623   \n",
       "2   cnn_two_channels_model_ws_6_transform_dct  0.948403  0.938398  0.915272   \n",
       "3         multi_cnn_model_ws_5_transform_None  0.960496  0.954230  0.959121   \n",
       "4          cnn_model_comp_ws_3_transform_None  0.968795  0.964201  0.978745   \n",
       "..                                        ...       ...       ...       ...   \n",
       "86         cnn_model_comp_ws_4_transform_None  0.965867  0.960587  0.968787   \n",
       "87          cnn_model_comp_ws_4_transform_dct  0.964573  0.958734  0.958494   \n",
       "88  cnn_two_channels_model_ws_3_transform_fft  0.968239  0.963159  0.966987   \n",
       "89               cnn_model_ws_7_transform_dct  0.946608  0.938094  0.942176   \n",
       "90        multi_lstm_model_ws_4_transform_dct  0.964142  0.958134  0.955649   \n",
       "\n",
       "         pre       spe       sen     tn    fp    fn     tp  \n",
       "0   0.939623  0.953565  0.960460  30290  1475   945  22955  \n",
       "1   0.960063  0.969652  0.969623  30801   964   726  23174  \n",
       "2   0.962723  0.973333  0.915272  30915   847  2025  21875  \n",
       "3   0.949389  0.961530  0.959121  30543  1222   977  22923  \n",
       "4   0.950083  0.961310  0.978745  30536  1229   508  23392  \n",
       "..       ...       ...       ...    ...   ...   ...    ...  \n",
       "86  0.952526  0.963670  0.968787  30610  1154   746  23154  \n",
       "87  0.958975  0.969147  0.958494  30784   980   992  22908  \n",
       "88  0.959361  0.969180  0.966987  30786   979   789  23111  \n",
       "89  0.934047  0.949943  0.942176  30174  1590  1382  22518  \n",
       "90  0.960633  0.970533  0.955649  30828   936  1060  22840  \n",
       "\n",
       "[91 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df = pd.DataFrame(all_scores, columns = [\"model_name\", \"acc\", \"f1\", \"rec\", \"pre\", \"spe\", \"sen\", \"tn\", \"fp\", \"fn\", \"tp\"])\n",
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d08a5b45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:20:32.190870Z",
     "start_time": "2021-10-15T06:20:32.167874Z"
    }
   },
   "outputs": [],
   "source": [
    "extract_ws = lambda x: re.search(r'_ws_(.*?)_transform', x).group(1)\n",
    "extract_transform = lambda x: re.search(r'transform_(.*)', x).group(1)\n",
    "extract_model = lambda x: re.search(r'(.*?)_ws', x).group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fba70b0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:20:32.777874Z",
     "start_time": "2021-10-15T06:20:32.757880Z"
    }
   },
   "outputs": [],
   "source": [
    "scores_df[\"window_size\"] = scores_df.model_name.apply(extract_ws)\n",
    "scores_df[\"transform\"] = scores_df.model_name.apply(extract_transform)\n",
    "scores_df[\"model\"] = scores_df.model_name.apply(extract_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8f49277",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:20:34.096866Z",
     "start_time": "2021-10-15T06:20:33.974876Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_name</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>rec</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>sen</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "      <th>window_size</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cnn_model_ws_5_transform_fft</td>\n",
       "      <td>0.956526</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.953565</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>30290</td>\n",
       "      <td>1475</td>\n",
       "      <td>945</td>\n",
       "      <td>22955</td>\n",
       "      <td>5</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cnn_model_ws_3_transform_dct</td>\n",
       "      <td>0.969640</td>\n",
       "      <td>0.964820</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>0.960063</td>\n",
       "      <td>0.969652</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>30801</td>\n",
       "      <td>964</td>\n",
       "      <td>726</td>\n",
       "      <td>23174</td>\n",
       "      <td>3</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cnn_two_channels_model_ws_6_transform_dct</td>\n",
       "      <td>0.948403</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>30915</td>\n",
       "      <td>847</td>\n",
       "      <td>2025</td>\n",
       "      <td>21875</td>\n",
       "      <td>6</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>multi_cnn_model_ws_5_transform_None</td>\n",
       "      <td>0.960496</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>0.949389</td>\n",
       "      <td>0.961530</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>30543</td>\n",
       "      <td>1222</td>\n",
       "      <td>977</td>\n",
       "      <td>22923</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>multi_cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cnn_model_comp_ws_3_transform_None</td>\n",
       "      <td>0.968795</td>\n",
       "      <td>0.964201</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>0.950083</td>\n",
       "      <td>0.961310</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>30536</td>\n",
       "      <td>1229</td>\n",
       "      <td>508</td>\n",
       "      <td>23392</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>cnn_model_comp_ws_4_transform_None</td>\n",
       "      <td>0.965867</td>\n",
       "      <td>0.960587</td>\n",
       "      <td>0.968787</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>0.963670</td>\n",
       "      <td>0.968787</td>\n",
       "      <td>30610</td>\n",
       "      <td>1154</td>\n",
       "      <td>746</td>\n",
       "      <td>23154</td>\n",
       "      <td>4</td>\n",
       "      <td>None</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>cnn_model_comp_ws_4_transform_dct</td>\n",
       "      <td>0.964573</td>\n",
       "      <td>0.958734</td>\n",
       "      <td>0.958494</td>\n",
       "      <td>0.958975</td>\n",
       "      <td>0.969147</td>\n",
       "      <td>0.958494</td>\n",
       "      <td>30784</td>\n",
       "      <td>980</td>\n",
       "      <td>992</td>\n",
       "      <td>22908</td>\n",
       "      <td>4</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model_comp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>cnn_two_channels_model_ws_3_transform_fft</td>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.963159</td>\n",
       "      <td>0.966987</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.969180</td>\n",
       "      <td>0.966987</td>\n",
       "      <td>30786</td>\n",
       "      <td>979</td>\n",
       "      <td>789</td>\n",
       "      <td>23111</td>\n",
       "      <td>3</td>\n",
       "      <td>fft</td>\n",
       "      <td>cnn_two_channels_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>cnn_model_ws_7_transform_dct</td>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.949943</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>30174</td>\n",
       "      <td>1590</td>\n",
       "      <td>1382</td>\n",
       "      <td>22518</td>\n",
       "      <td>7</td>\n",
       "      <td>dct</td>\n",
       "      <td>cnn_model</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>multi_lstm_model_ws_4_transform_dct</td>\n",
       "      <td>0.964142</td>\n",
       "      <td>0.958134</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>0.960633</td>\n",
       "      <td>0.970533</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>30828</td>\n",
       "      <td>936</td>\n",
       "      <td>1060</td>\n",
       "      <td>22840</td>\n",
       "      <td>4</td>\n",
       "      <td>dct</td>\n",
       "      <td>multi_lstm_model</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>91 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   model_name       acc        f1       rec  \\\n",
       "0                cnn_model_ws_5_transform_fft  0.956526  0.949928  0.960460   \n",
       "1                cnn_model_ws_3_transform_dct  0.969640  0.964820  0.969623   \n",
       "2   cnn_two_channels_model_ws_6_transform_dct  0.948403  0.938398  0.915272   \n",
       "3         multi_cnn_model_ws_5_transform_None  0.960496  0.954230  0.959121   \n",
       "4          cnn_model_comp_ws_3_transform_None  0.968795  0.964201  0.978745   \n",
       "..                                        ...       ...       ...       ...   \n",
       "86         cnn_model_comp_ws_4_transform_None  0.965867  0.960587  0.968787   \n",
       "87          cnn_model_comp_ws_4_transform_dct  0.964573  0.958734  0.958494   \n",
       "88  cnn_two_channels_model_ws_3_transform_fft  0.968239  0.963159  0.966987   \n",
       "89               cnn_model_ws_7_transform_dct  0.946608  0.938094  0.942176   \n",
       "90        multi_lstm_model_ws_4_transform_dct  0.964142  0.958134  0.955649   \n",
       "\n",
       "         pre       spe       sen     tn    fp    fn     tp window_size  \\\n",
       "0   0.939623  0.953565  0.960460  30290  1475   945  22955           5   \n",
       "1   0.960063  0.969652  0.969623  30801   964   726  23174           3   \n",
       "2   0.962723  0.973333  0.915272  30915   847  2025  21875           6   \n",
       "3   0.949389  0.961530  0.959121  30543  1222   977  22923           5   \n",
       "4   0.950083  0.961310  0.978745  30536  1229   508  23392           3   \n",
       "..       ...       ...       ...    ...   ...   ...    ...         ...   \n",
       "86  0.952526  0.963670  0.968787  30610  1154   746  23154           4   \n",
       "87  0.958975  0.969147  0.958494  30784   980   992  22908           4   \n",
       "88  0.959361  0.969180  0.966987  30786   979   789  23111           3   \n",
       "89  0.934047  0.949943  0.942176  30174  1590  1382  22518           7   \n",
       "90  0.960633  0.970533  0.955649  30828   936  1060  22840           4   \n",
       "\n",
       "   transform                   model  \n",
       "0        fft               cnn_model  \n",
       "1        dct               cnn_model  \n",
       "2        dct  cnn_two_channels_model  \n",
       "3       None         multi_cnn_model  \n",
       "4       None          cnn_model_comp  \n",
       "..       ...                     ...  \n",
       "86      None          cnn_model_comp  \n",
       "87       dct          cnn_model_comp  \n",
       "88       fft  cnn_two_channels_model  \n",
       "89       dct               cnn_model  \n",
       "90       dct        multi_lstm_model  \n",
       "\n",
       "[91 rows x 14 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "348c01d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:26:54.840876Z",
     "start_time": "2021-10-15T06:26:54.816866Z"
    }
   },
   "outputs": [],
   "source": [
    "del scores_df['model_name']\n",
    "\n",
    "scores_df = scores_df[scores_df.columns[-3:].tolist() + scores_df.columns[:-3].tolist()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ab0654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8424efee",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-10-15T06:27:20.069874Z",
     "start_time": "2021-10-15T06:27:19.956882Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "      <th>rec</th>\n",
       "      <th>pre</th>\n",
       "      <th>spe</th>\n",
       "      <th>sen</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tp</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>window_size</th>\n",
       "      <th>transform</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"19\" valign=\"top\">3</th>\n",
       "      <th rowspan=\"7\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.970610</td>\n",
       "      <td>0.965824</td>\n",
       "      <td>0.967238</td>\n",
       "      <td>0.964414</td>\n",
       "      <td>0.973147</td>\n",
       "      <td>0.967238</td>\n",
       "      <td>30912</td>\n",
       "      <td>853</td>\n",
       "      <td>783</td>\n",
       "      <td>23117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.968795</td>\n",
       "      <td>0.964201</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>0.950083</td>\n",
       "      <td>0.961310</td>\n",
       "      <td>0.978745</td>\n",
       "      <td>30536</td>\n",
       "      <td>1229</td>\n",
       "      <td>508</td>\n",
       "      <td>23392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.969173</td>\n",
       "      <td>0.964465</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>0.954777</td>\n",
       "      <td>0.965276</td>\n",
       "      <td>0.974351</td>\n",
       "      <td>30662</td>\n",
       "      <td>1103</td>\n",
       "      <td>613</td>\n",
       "      <td>23287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model_bis</th>\n",
       "      <td>0.965328</td>\n",
       "      <td>0.959758</td>\n",
       "      <td>0.962971</td>\n",
       "      <td>0.956567</td>\n",
       "      <td>0.967102</td>\n",
       "      <td>0.962971</td>\n",
       "      <td>30720</td>\n",
       "      <td>1045</td>\n",
       "      <td>885</td>\n",
       "      <td>23015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.969532</td>\n",
       "      <td>0.964646</td>\n",
       "      <td>0.968117</td>\n",
       "      <td>0.961200</td>\n",
       "      <td>0.970597</td>\n",
       "      <td>0.968117</td>\n",
       "      <td>30831</td>\n",
       "      <td>934</td>\n",
       "      <td>762</td>\n",
       "      <td>23138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.969766</td>\n",
       "      <td>0.964919</td>\n",
       "      <td>0.968452</td>\n",
       "      <td>0.961412</td>\n",
       "      <td>0.970754</td>\n",
       "      <td>0.968452</td>\n",
       "      <td>30836</td>\n",
       "      <td>929</td>\n",
       "      <td>754</td>\n",
       "      <td>23146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.966227</td>\n",
       "      <td>0.960840</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>0.956695</td>\n",
       "      <td>0.967134</td>\n",
       "      <td>0.965021</td>\n",
       "      <td>30721</td>\n",
       "      <td>1044</td>\n",
       "      <td>836</td>\n",
       "      <td>23064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.969640</td>\n",
       "      <td>0.964820</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>0.960063</td>\n",
       "      <td>0.969652</td>\n",
       "      <td>0.969623</td>\n",
       "      <td>30801</td>\n",
       "      <td>964</td>\n",
       "      <td>726</td>\n",
       "      <td>23174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.953238</td>\n",
       "      <td>0.947999</td>\n",
       "      <td>0.992762</td>\n",
       "      <td>0.907099</td>\n",
       "      <td>0.923501</td>\n",
       "      <td>0.992762</td>\n",
       "      <td>29335</td>\n",
       "      <td>2430</td>\n",
       "      <td>173</td>\n",
       "      <td>23727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.965993</td>\n",
       "      <td>0.961178</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>0.942601</td>\n",
       "      <td>0.955076</td>\n",
       "      <td>0.980502</td>\n",
       "      <td>30338</td>\n",
       "      <td>1427</td>\n",
       "      <td>466</td>\n",
       "      <td>23434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.968939</td>\n",
       "      <td>0.964077</td>\n",
       "      <td>0.970753</td>\n",
       "      <td>0.957492</td>\n",
       "      <td>0.967574</td>\n",
       "      <td>0.970753</td>\n",
       "      <td>30735</td>\n",
       "      <td>1030</td>\n",
       "      <td>699</td>\n",
       "      <td>23201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.970556</td>\n",
       "      <td>0.965734</td>\n",
       "      <td>0.966360</td>\n",
       "      <td>0.965108</td>\n",
       "      <td>0.973713</td>\n",
       "      <td>0.966360</td>\n",
       "      <td>30930</td>\n",
       "      <td>835</td>\n",
       "      <td>804</td>\n",
       "      <td>23096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.966748</td>\n",
       "      <td>0.961705</td>\n",
       "      <td>0.972469</td>\n",
       "      <td>0.951177</td>\n",
       "      <td>0.962443</td>\n",
       "      <td>0.972469</td>\n",
       "      <td>30572</td>\n",
       "      <td>1193</td>\n",
       "      <td>658</td>\n",
       "      <td>23242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.968310</td>\n",
       "      <td>0.963366</td>\n",
       "      <td>0.970460</td>\n",
       "      <td>0.956375</td>\n",
       "      <td>0.966693</td>\n",
       "      <td>0.970460</td>\n",
       "      <td>30707</td>\n",
       "      <td>1058</td>\n",
       "      <td>706</td>\n",
       "      <td>23194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.967358</td>\n",
       "      <td>0.962566</td>\n",
       "      <td>0.977448</td>\n",
       "      <td>0.948131</td>\n",
       "      <td>0.959767</td>\n",
       "      <td>0.977448</td>\n",
       "      <td>30487</td>\n",
       "      <td>1278</td>\n",
       "      <td>539</td>\n",
       "      <td>23361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.968239</td>\n",
       "      <td>0.963159</td>\n",
       "      <td>0.966987</td>\n",
       "      <td>0.959361</td>\n",
       "      <td>0.969180</td>\n",
       "      <td>0.966987</td>\n",
       "      <td>30786</td>\n",
       "      <td>979</td>\n",
       "      <td>789</td>\n",
       "      <td>23111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.967915</td>\n",
       "      <td>0.963052</td>\n",
       "      <td>0.973891</td>\n",
       "      <td>0.952451</td>\n",
       "      <td>0.963419</td>\n",
       "      <td>0.973891</td>\n",
       "      <td>30603</td>\n",
       "      <td>1162</td>\n",
       "      <td>624</td>\n",
       "      <td>23276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.963975</td>\n",
       "      <td>0.971255</td>\n",
       "      <td>0.956803</td>\n",
       "      <td>0.967008</td>\n",
       "      <td>0.971255</td>\n",
       "      <td>30717</td>\n",
       "      <td>1048</td>\n",
       "      <td>687</td>\n",
       "      <td>23213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.966676</td>\n",
       "      <td>0.961684</td>\n",
       "      <td>0.974017</td>\n",
       "      <td>0.949659</td>\n",
       "      <td>0.961152</td>\n",
       "      <td>0.974017</td>\n",
       "      <td>30531</td>\n",
       "      <td>1234</td>\n",
       "      <td>621</td>\n",
       "      <td>23279</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">4</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.964214</td>\n",
       "      <td>0.958141</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>0.962428</td>\n",
       "      <td>0.971981</td>\n",
       "      <td>0.953891</td>\n",
       "      <td>30874</td>\n",
       "      <td>890</td>\n",
       "      <td>1102</td>\n",
       "      <td>22798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.965867</td>\n",
       "      <td>0.960587</td>\n",
       "      <td>0.968787</td>\n",
       "      <td>0.952526</td>\n",
       "      <td>0.963670</td>\n",
       "      <td>0.968787</td>\n",
       "      <td>30610</td>\n",
       "      <td>1154</td>\n",
       "      <td>746</td>\n",
       "      <td>23154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.965400</td>\n",
       "      <td>0.959616</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>0.961794</td>\n",
       "      <td>0.971383</td>\n",
       "      <td>0.957448</td>\n",
       "      <td>30855</td>\n",
       "      <td>909</td>\n",
       "      <td>1017</td>\n",
       "      <td>22883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.965328</td>\n",
       "      <td>0.959392</td>\n",
       "      <td>0.953933</td>\n",
       "      <td>0.964915</td>\n",
       "      <td>0.973901</td>\n",
       "      <td>0.953933</td>\n",
       "      <td>30935</td>\n",
       "      <td>829</td>\n",
       "      <td>1101</td>\n",
       "      <td>22799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.964968</td>\n",
       "      <td>0.958627</td>\n",
       "      <td>0.945230</td>\n",
       "      <td>0.972409</td>\n",
       "      <td>0.979820</td>\n",
       "      <td>0.945230</td>\n",
       "      <td>31123</td>\n",
       "      <td>641</td>\n",
       "      <td>1309</td>\n",
       "      <td>22591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.962202</td>\n",
       "      <td>0.956276</td>\n",
       "      <td>0.962678</td>\n",
       "      <td>0.949959</td>\n",
       "      <td>0.961844</td>\n",
       "      <td>0.962678</td>\n",
       "      <td>30552</td>\n",
       "      <td>1212</td>\n",
       "      <td>892</td>\n",
       "      <td>23008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.964322</td>\n",
       "      <td>0.958501</td>\n",
       "      <td>0.959623</td>\n",
       "      <td>0.957380</td>\n",
       "      <td>0.967857</td>\n",
       "      <td>0.959623</td>\n",
       "      <td>30743</td>\n",
       "      <td>1021</td>\n",
       "      <td>965</td>\n",
       "      <td>22935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.964573</td>\n",
       "      <td>0.958734</td>\n",
       "      <td>0.958494</td>\n",
       "      <td>0.958975</td>\n",
       "      <td>0.969147</td>\n",
       "      <td>0.958494</td>\n",
       "      <td>30784</td>\n",
       "      <td>980</td>\n",
       "      <td>992</td>\n",
       "      <td>22908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.960405</td>\n",
       "      <td>0.954732</td>\n",
       "      <td>0.972469</td>\n",
       "      <td>0.937631</td>\n",
       "      <td>0.951329</td>\n",
       "      <td>0.972469</td>\n",
       "      <td>30218</td>\n",
       "      <td>1546</td>\n",
       "      <td>658</td>\n",
       "      <td>23242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.963711</td>\n",
       "      <td>0.957434</td>\n",
       "      <td>0.950544</td>\n",
       "      <td>0.964425</td>\n",
       "      <td>0.973618</td>\n",
       "      <td>0.950544</td>\n",
       "      <td>30926</td>\n",
       "      <td>838</td>\n",
       "      <td>1182</td>\n",
       "      <td>22718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.964142</td>\n",
       "      <td>0.958134</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>0.960633</td>\n",
       "      <td>0.970533</td>\n",
       "      <td>0.955649</td>\n",
       "      <td>30828</td>\n",
       "      <td>936</td>\n",
       "      <td>1060</td>\n",
       "      <td>22840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.961986</td>\n",
       "      <td>0.955898</td>\n",
       "      <td>0.959498</td>\n",
       "      <td>0.952326</td>\n",
       "      <td>0.963858</td>\n",
       "      <td>0.959498</td>\n",
       "      <td>30616</td>\n",
       "      <td>1148</td>\n",
       "      <td>968</td>\n",
       "      <td>22932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.963208</td>\n",
       "      <td>0.957105</td>\n",
       "      <td>0.955983</td>\n",
       "      <td>0.958228</td>\n",
       "      <td>0.968644</td>\n",
       "      <td>0.955983</td>\n",
       "      <td>30768</td>\n",
       "      <td>996</td>\n",
       "      <td>1052</td>\n",
       "      <td>22848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.963998</td>\n",
       "      <td>0.958212</td>\n",
       "      <td>0.961339</td>\n",
       "      <td>0.955105</td>\n",
       "      <td>0.965999</td>\n",
       "      <td>0.961339</td>\n",
       "      <td>30684</td>\n",
       "      <td>1080</td>\n",
       "      <td>924</td>\n",
       "      <td>22976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.963998</td>\n",
       "      <td>0.958198</td>\n",
       "      <td>0.961004</td>\n",
       "      <td>0.955408</td>\n",
       "      <td>0.966251</td>\n",
       "      <td>0.961004</td>\n",
       "      <td>30692</td>\n",
       "      <td>1072</td>\n",
       "      <td>932</td>\n",
       "      <td>22968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.963962</td>\n",
       "      <td>0.958247</td>\n",
       "      <td>0.963138</td>\n",
       "      <td>0.953405</td>\n",
       "      <td>0.964583</td>\n",
       "      <td>0.963138</td>\n",
       "      <td>30639</td>\n",
       "      <td>1125</td>\n",
       "      <td>881</td>\n",
       "      <td>23019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.962920</td>\n",
       "      <td>0.956459</td>\n",
       "      <td>0.948536</td>\n",
       "      <td>0.964517</td>\n",
       "      <td>0.973744</td>\n",
       "      <td>0.948536</td>\n",
       "      <td>30930</td>\n",
       "      <td>834</td>\n",
       "      <td>1230</td>\n",
       "      <td>22670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.961160</td>\n",
       "      <td>0.954770</td>\n",
       "      <td>0.954770</td>\n",
       "      <td>0.954770</td>\n",
       "      <td>0.965968</td>\n",
       "      <td>0.954770</td>\n",
       "      <td>30683</td>\n",
       "      <td>1081</td>\n",
       "      <td>1081</td>\n",
       "      <td>22819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">5</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.959508</td>\n",
       "      <td>0.953012</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>0.949647</td>\n",
       "      <td>0.961845</td>\n",
       "      <td>0.956402</td>\n",
       "      <td>30553</td>\n",
       "      <td>1212</td>\n",
       "      <td>1042</td>\n",
       "      <td>22858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.959634</td>\n",
       "      <td>0.953694</td>\n",
       "      <td>0.968159</td>\n",
       "      <td>0.939655</td>\n",
       "      <td>0.953219</td>\n",
       "      <td>0.968159</td>\n",
       "      <td>30279</td>\n",
       "      <td>1486</td>\n",
       "      <td>761</td>\n",
       "      <td>23139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.958969</td>\n",
       "      <td>0.952496</td>\n",
       "      <td>0.958075</td>\n",
       "      <td>0.946981</td>\n",
       "      <td>0.959641</td>\n",
       "      <td>0.958075</td>\n",
       "      <td>30483</td>\n",
       "      <td>1282</td>\n",
       "      <td>1002</td>\n",
       "      <td>22898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.960496</td>\n",
       "      <td>0.954230</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>0.949389</td>\n",
       "      <td>0.961530</td>\n",
       "      <td>0.959121</td>\n",
       "      <td>30543</td>\n",
       "      <td>1222</td>\n",
       "      <td>977</td>\n",
       "      <td>22923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.958681</td>\n",
       "      <td>0.952193</td>\n",
       "      <td>0.958368</td>\n",
       "      <td>0.946097</td>\n",
       "      <td>0.958917</td>\n",
       "      <td>0.958368</td>\n",
       "      <td>30460</td>\n",
       "      <td>1305</td>\n",
       "      <td>995</td>\n",
       "      <td>22905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.955933</td>\n",
       "      <td>0.949197</td>\n",
       "      <td>0.958828</td>\n",
       "      <td>0.939758</td>\n",
       "      <td>0.953754</td>\n",
       "      <td>0.958828</td>\n",
       "      <td>30296</td>\n",
       "      <td>1469</td>\n",
       "      <td>984</td>\n",
       "      <td>22916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.958861</td>\n",
       "      <td>0.952132</td>\n",
       "      <td>0.952929</td>\n",
       "      <td>0.951337</td>\n",
       "      <td>0.963324</td>\n",
       "      <td>0.952929</td>\n",
       "      <td>30600</td>\n",
       "      <td>1165</td>\n",
       "      <td>1125</td>\n",
       "      <td>22775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.957586</td>\n",
       "      <td>0.950508</td>\n",
       "      <td>0.948619</td>\n",
       "      <td>0.952405</td>\n",
       "      <td>0.964332</td>\n",
       "      <td>0.948619</td>\n",
       "      <td>30632</td>\n",
       "      <td>1133</td>\n",
       "      <td>1228</td>\n",
       "      <td>22672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.957909</td>\n",
       "      <td>0.951233</td>\n",
       "      <td>0.956109</td>\n",
       "      <td>0.946407</td>\n",
       "      <td>0.959263</td>\n",
       "      <td>0.956109</td>\n",
       "      <td>30471</td>\n",
       "      <td>1294</td>\n",
       "      <td>1049</td>\n",
       "      <td>22851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.958556</td>\n",
       "      <td>0.951872</td>\n",
       "      <td>0.954561</td>\n",
       "      <td>0.949199</td>\n",
       "      <td>0.961561</td>\n",
       "      <td>0.954561</td>\n",
       "      <td>30544</td>\n",
       "      <td>1221</td>\n",
       "      <td>1086</td>\n",
       "      <td>22814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.959346</td>\n",
       "      <td>0.953123</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>0.943836</td>\n",
       "      <td>0.956902</td>\n",
       "      <td>0.962594</td>\n",
       "      <td>30396</td>\n",
       "      <td>1369</td>\n",
       "      <td>894</td>\n",
       "      <td>23006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.954657</td>\n",
       "      <td>0.947937</td>\n",
       "      <td>0.961423</td>\n",
       "      <td>0.934825</td>\n",
       "      <td>0.949567</td>\n",
       "      <td>0.961423</td>\n",
       "      <td>30163</td>\n",
       "      <td>1602</td>\n",
       "      <td>922</td>\n",
       "      <td>22978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.956526</td>\n",
       "      <td>0.949928</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>0.939623</td>\n",
       "      <td>0.953565</td>\n",
       "      <td>0.960460</td>\n",
       "      <td>30290</td>\n",
       "      <td>1475</td>\n",
       "      <td>945</td>\n",
       "      <td>22955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.956580</td>\n",
       "      <td>0.950129</td>\n",
       "      <td>0.963347</td>\n",
       "      <td>0.937268</td>\n",
       "      <td>0.951487</td>\n",
       "      <td>0.963347</td>\n",
       "      <td>30224</td>\n",
       "      <td>1541</td>\n",
       "      <td>876</td>\n",
       "      <td>23024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.955843</td>\n",
       "      <td>0.948983</td>\n",
       "      <td>0.956527</td>\n",
       "      <td>0.941557</td>\n",
       "      <td>0.955328</td>\n",
       "      <td>0.956527</td>\n",
       "      <td>30346</td>\n",
       "      <td>1419</td>\n",
       "      <td>1039</td>\n",
       "      <td>22861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.956544</td>\n",
       "      <td>0.949933</td>\n",
       "      <td>0.960167</td>\n",
       "      <td>0.939914</td>\n",
       "      <td>0.953817</td>\n",
       "      <td>0.960167</td>\n",
       "      <td>30298</td>\n",
       "      <td>1467</td>\n",
       "      <td>952</td>\n",
       "      <td>22948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.955789</td>\n",
       "      <td>0.949388</td>\n",
       "      <td>0.965774</td>\n",
       "      <td>0.933549</td>\n",
       "      <td>0.948276</td>\n",
       "      <td>0.965774</td>\n",
       "      <td>30122</td>\n",
       "      <td>1643</td>\n",
       "      <td>818</td>\n",
       "      <td>23082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.955178</td>\n",
       "      <td>0.947972</td>\n",
       "      <td>0.951046</td>\n",
       "      <td>0.944918</td>\n",
       "      <td>0.958287</td>\n",
       "      <td>0.951046</td>\n",
       "      <td>30440</td>\n",
       "      <td>1325</td>\n",
       "      <td>1170</td>\n",
       "      <td>22730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">6</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.952319</td>\n",
       "      <td>0.943690</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>0.957257</td>\n",
       "      <td>0.968736</td>\n",
       "      <td>0.930502</td>\n",
       "      <td>30769</td>\n",
       "      <td>993</td>\n",
       "      <td>1661</td>\n",
       "      <td>22239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.947361</td>\n",
       "      <td>0.940832</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>0.909251</td>\n",
       "      <td>0.926799</td>\n",
       "      <td>0.974686</td>\n",
       "      <td>29437</td>\n",
       "      <td>2325</td>\n",
       "      <td>605</td>\n",
       "      <td>23295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.952499</td>\n",
       "      <td>0.945606</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>0.930144</td>\n",
       "      <td>0.945658</td>\n",
       "      <td>0.961590</td>\n",
       "      <td>30036</td>\n",
       "      <td>1726</td>\n",
       "      <td>918</td>\n",
       "      <td>22982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.954547</td>\n",
       "      <td>0.946457</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>0.957563</td>\n",
       "      <td>0.968799</td>\n",
       "      <td>0.935607</td>\n",
       "      <td>30771</td>\n",
       "      <td>991</td>\n",
       "      <td>1539</td>\n",
       "      <td>22361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.954044</td>\n",
       "      <td>0.946843</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>0.940550</td>\n",
       "      <td>0.954663</td>\n",
       "      <td>0.953222</td>\n",
       "      <td>30322</td>\n",
       "      <td>1440</td>\n",
       "      <td>1118</td>\n",
       "      <td>22782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.950451</td>\n",
       "      <td>0.942342</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>0.941673</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.943013</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1362</td>\n",
       "      <td>22538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.953613</td>\n",
       "      <td>0.945913</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.947143</td>\n",
       "      <td>0.960330</td>\n",
       "      <td>0.944686</td>\n",
       "      <td>30502</td>\n",
       "      <td>1260</td>\n",
       "      <td>1322</td>\n",
       "      <td>22578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.948295</td>\n",
       "      <td>0.941563</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>0.914635</td>\n",
       "      <td>0.931868</td>\n",
       "      <td>0.970126</td>\n",
       "      <td>29598</td>\n",
       "      <td>2164</td>\n",
       "      <td>714</td>\n",
       "      <td>23186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.948403</td>\n",
       "      <td>0.938398</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>0.962723</td>\n",
       "      <td>0.973333</td>\n",
       "      <td>0.915272</td>\n",
       "      <td>30915</td>\n",
       "      <td>847</td>\n",
       "      <td>2025</td>\n",
       "      <td>21875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.952247</td>\n",
       "      <td>0.943713</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>0.955407</td>\n",
       "      <td>0.967256</td>\n",
       "      <td>0.932301</td>\n",
       "      <td>30722</td>\n",
       "      <td>1040</td>\n",
       "      <td>1618</td>\n",
       "      <td>22282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.953972</td>\n",
       "      <td>0.946346</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>0.947338</td>\n",
       "      <td>0.960456</td>\n",
       "      <td>0.945356</td>\n",
       "      <td>30506</td>\n",
       "      <td>1256</td>\n",
       "      <td>1306</td>\n",
       "      <td>22594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.947972</td>\n",
       "      <td>0.939282</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>0.941335</td>\n",
       "      <td>0.956048</td>\n",
       "      <td>0.937238</td>\n",
       "      <td>30366</td>\n",
       "      <td>1396</td>\n",
       "      <td>1500</td>\n",
       "      <td>22400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.949840</td>\n",
       "      <td>0.941047</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>0.949872</td>\n",
       "      <td>0.962975</td>\n",
       "      <td>0.932385</td>\n",
       "      <td>30586</td>\n",
       "      <td>1176</td>\n",
       "      <td>1616</td>\n",
       "      <td>22284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.949337</td>\n",
       "      <td>0.942178</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>0.923804</td>\n",
       "      <td>0.940338</td>\n",
       "      <td>0.961297</td>\n",
       "      <td>29867</td>\n",
       "      <td>1895</td>\n",
       "      <td>925</td>\n",
       "      <td>22975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.950559</td>\n",
       "      <td>0.941536</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>0.956327</td>\n",
       "      <td>0.968138</td>\n",
       "      <td>0.927197</td>\n",
       "      <td>30750</td>\n",
       "      <td>1012</td>\n",
       "      <td>1740</td>\n",
       "      <td>22160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.951170</td>\n",
       "      <td>0.942834</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>0.947898</td>\n",
       "      <td>0.961212</td>\n",
       "      <td>0.937824</td>\n",
       "      <td>30530</td>\n",
       "      <td>1232</td>\n",
       "      <td>1486</td>\n",
       "      <td>22414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.949984</td>\n",
       "      <td>0.941660</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>0.943241</td>\n",
       "      <td>0.957433</td>\n",
       "      <td>0.940084</td>\n",
       "      <td>30410</td>\n",
       "      <td>1352</td>\n",
       "      <td>1432</td>\n",
       "      <td>22468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.948690</td>\n",
       "      <td>0.940076</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>0.942845</td>\n",
       "      <td>0.957245</td>\n",
       "      <td>0.937322</td>\n",
       "      <td>30404</td>\n",
       "      <td>1358</td>\n",
       "      <td>1498</td>\n",
       "      <td>22402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"18\" valign=\"top\">7</th>\n",
       "      <th rowspan=\"6\" valign=\"top\">None</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.948117</td>\n",
       "      <td>0.939133</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>0.946153</td>\n",
       "      <td>0.960081</td>\n",
       "      <td>0.932218</td>\n",
       "      <td>30496</td>\n",
       "      <td>1268</td>\n",
       "      <td>1620</td>\n",
       "      <td>22280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.945027</td>\n",
       "      <td>0.938381</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>0.904503</td>\n",
       "      <td>0.922554</td>\n",
       "      <td>0.974895</td>\n",
       "      <td>29304</td>\n",
       "      <td>2460</td>\n",
       "      <td>600</td>\n",
       "      <td>23300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.946482</td>\n",
       "      <td>0.938334</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>0.928551</td>\n",
       "      <td>0.945095</td>\n",
       "      <td>0.948326</td>\n",
       "      <td>30020</td>\n",
       "      <td>1744</td>\n",
       "      <td>1235</td>\n",
       "      <td>22665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.948513</td>\n",
       "      <td>0.940596</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>0.931981</td>\n",
       "      <td>0.947866</td>\n",
       "      <td>0.949372</td>\n",
       "      <td>30108</td>\n",
       "      <td>1656</td>\n",
       "      <td>1210</td>\n",
       "      <td>22690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.947578</td>\n",
       "      <td>0.940126</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>0.922411</td>\n",
       "      <td>0.939334</td>\n",
       "      <td>0.958536</td>\n",
       "      <td>29837</td>\n",
       "      <td>1927</td>\n",
       "      <td>991</td>\n",
       "      <td>22909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.943033</td>\n",
       "      <td>0.935075</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>0.915561</td>\n",
       "      <td>0.933699</td>\n",
       "      <td>0.955439</td>\n",
       "      <td>29658</td>\n",
       "      <td>2106</td>\n",
       "      <td>1065</td>\n",
       "      <td>22835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">dct</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.946608</td>\n",
       "      <td>0.938094</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>0.934047</td>\n",
       "      <td>0.949943</td>\n",
       "      <td>0.942176</td>\n",
       "      <td>30174</td>\n",
       "      <td>1590</td>\n",
       "      <td>1382</td>\n",
       "      <td>22518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.933781</td>\n",
       "      <td>0.927232</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>0.877775</td>\n",
       "      <td>0.897053</td>\n",
       "      <td>0.982594</td>\n",
       "      <td>28494</td>\n",
       "      <td>3270</td>\n",
       "      <td>416</td>\n",
       "      <td>23484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.944686</td>\n",
       "      <td>0.936959</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>0.917405</td>\n",
       "      <td>0.935147</td>\n",
       "      <td>0.957364</td>\n",
       "      <td>29704</td>\n",
       "      <td>2060</td>\n",
       "      <td>1019</td>\n",
       "      <td>22881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.947129</td>\n",
       "      <td>0.939009</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>0.930276</td>\n",
       "      <td>0.946543</td>\n",
       "      <td>0.947908</td>\n",
       "      <td>30066</td>\n",
       "      <td>1698</td>\n",
       "      <td>1245</td>\n",
       "      <td>22655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.948099</td>\n",
       "      <td>0.940645</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>0.924071</td>\n",
       "      <td>0.940782</td>\n",
       "      <td>0.957824</td>\n",
       "      <td>29883</td>\n",
       "      <td>1881</td>\n",
       "      <td>1008</td>\n",
       "      <td>22892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.942728</td>\n",
       "      <td>0.934530</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>0.917682</td>\n",
       "      <td>0.935745</td>\n",
       "      <td>0.952008</td>\n",
       "      <td>29723</td>\n",
       "      <td>2041</td>\n",
       "      <td>1147</td>\n",
       "      <td>22753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">fft</th>\n",
       "      <th>cnn_model</th>\n",
       "      <td>0.944524</td>\n",
       "      <td>0.935902</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>0.928654</td>\n",
       "      <td>0.945473</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>30032</td>\n",
       "      <td>1732</td>\n",
       "      <td>1356</td>\n",
       "      <td>22544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_model_comp</th>\n",
       "      <td>0.933835</td>\n",
       "      <td>0.927361</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>0.877141</td>\n",
       "      <td>0.896329</td>\n",
       "      <td>0.983682</td>\n",
       "      <td>28471</td>\n",
       "      <td>3293</td>\n",
       "      <td>390</td>\n",
       "      <td>23510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cnn_two_channels_model</th>\n",
       "      <td>0.942692</td>\n",
       "      <td>0.935472</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>0.905506</td>\n",
       "      <td>0.924033</td>\n",
       "      <td>0.967490</td>\n",
       "      <td>29351</td>\n",
       "      <td>2413</td>\n",
       "      <td>777</td>\n",
       "      <td>23123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_cnn_model</th>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.936713</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>0.924982</td>\n",
       "      <td>0.942104</td>\n",
       "      <td>0.948745</td>\n",
       "      <td>29925</td>\n",
       "      <td>1839</td>\n",
       "      <td>1225</td>\n",
       "      <td>22675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multi_lstm_model</th>\n",
       "      <td>0.943608</td>\n",
       "      <td>0.935804</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>0.915270</td>\n",
       "      <td>0.933321</td>\n",
       "      <td>0.957280</td>\n",
       "      <td>29646</td>\n",
       "      <td>2118</td>\n",
       "      <td>1021</td>\n",
       "      <td>22879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>uni_lstm_model</th>\n",
       "      <td>0.943069</td>\n",
       "      <td>0.934230</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>0.926862</td>\n",
       "      <td>0.944088</td>\n",
       "      <td>0.941715</td>\n",
       "      <td>29988</td>\n",
       "      <td>1776</td>\n",
       "      <td>1393</td>\n",
       "      <td>22507</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       acc        f1  \\\n",
       "window_size transform model                                            \n",
       "3           None      cnn_model                   0.970610  0.965824   \n",
       "                      cnn_model_comp              0.968795  0.964201   \n",
       "                      cnn_two_channels_model      0.969173  0.964465   \n",
       "                      cnn_two_channels_model_bis  0.965328  0.959758   \n",
       "                      multi_cnn_model             0.969532  0.964646   \n",
       "                      multi_lstm_model            0.969766  0.964919   \n",
       "                      uni_lstm_model              0.966227  0.960840   \n",
       "            dct       cnn_model                   0.969640  0.964820   \n",
       "                      cnn_model_comp              0.953238  0.947999   \n",
       "                      cnn_two_channels_model      0.965993  0.961178   \n",
       "                      multi_cnn_model             0.968939  0.964077   \n",
       "                      multi_lstm_model            0.970556  0.965734   \n",
       "                      uni_lstm_model              0.966748  0.961705   \n",
       "            fft       cnn_model                   0.968310  0.963366   \n",
       "                      cnn_model_comp              0.967358  0.962566   \n",
       "                      cnn_two_channels_model      0.968239  0.963159   \n",
       "                      multi_cnn_model             0.967915  0.963052   \n",
       "                      multi_lstm_model            0.968831  0.963975   \n",
       "                      uni_lstm_model              0.966676  0.961684   \n",
       "4           None      cnn_model                   0.964214  0.958141   \n",
       "                      cnn_model_comp              0.965867  0.960587   \n",
       "                      cnn_two_channels_model      0.965400  0.959616   \n",
       "                      multi_cnn_model             0.965328  0.959392   \n",
       "                      multi_lstm_model            0.964968  0.958627   \n",
       "                      uni_lstm_model              0.962202  0.956276   \n",
       "            dct       cnn_model                   0.964322  0.958501   \n",
       "                      cnn_model_comp              0.964573  0.958734   \n",
       "                      cnn_two_channels_model      0.960405  0.954732   \n",
       "                      multi_cnn_model             0.963711  0.957434   \n",
       "                      multi_lstm_model            0.964142  0.958134   \n",
       "                      uni_lstm_model              0.961986  0.955898   \n",
       "            fft       cnn_model                   0.963208  0.957105   \n",
       "                      cnn_model_comp              0.963998  0.958212   \n",
       "                      cnn_two_channels_model      0.963998  0.958198   \n",
       "                      multi_cnn_model             0.963962  0.958247   \n",
       "                      multi_lstm_model            0.962920  0.956459   \n",
       "                      uni_lstm_model              0.961160  0.954770   \n",
       "5           None      cnn_model                   0.959508  0.953012   \n",
       "                      cnn_model_comp              0.959634  0.953694   \n",
       "                      cnn_two_channels_model      0.958969  0.952496   \n",
       "                      multi_cnn_model             0.960496  0.954230   \n",
       "                      multi_lstm_model            0.958681  0.952193   \n",
       "                      uni_lstm_model              0.955933  0.949197   \n",
       "            dct       cnn_model                   0.958861  0.952132   \n",
       "                      cnn_model_comp              0.957586  0.950508   \n",
       "                      cnn_two_channels_model      0.957909  0.951233   \n",
       "                      multi_cnn_model             0.958556  0.951872   \n",
       "                      multi_lstm_model            0.959346  0.953123   \n",
       "                      uni_lstm_model              0.954657  0.947937   \n",
       "            fft       cnn_model                   0.956526  0.949928   \n",
       "                      cnn_model_comp              0.956580  0.950129   \n",
       "                      cnn_two_channels_model      0.955843  0.948983   \n",
       "                      multi_cnn_model             0.956544  0.949933   \n",
       "                      multi_lstm_model            0.955789  0.949388   \n",
       "                      uni_lstm_model              0.955178  0.947972   \n",
       "6           None      cnn_model                   0.952319  0.943690   \n",
       "                      cnn_model_comp              0.947361  0.940832   \n",
       "                      cnn_two_channels_model      0.952499  0.945606   \n",
       "                      multi_cnn_model             0.954547  0.946457   \n",
       "                      multi_lstm_model            0.954044  0.946843   \n",
       "                      uni_lstm_model              0.950451  0.942342   \n",
       "            dct       cnn_model                   0.953613  0.945913   \n",
       "                      cnn_model_comp              0.948295  0.941563   \n",
       "                      cnn_two_channels_model      0.948403  0.938398   \n",
       "                      multi_cnn_model             0.952247  0.943713   \n",
       "                      multi_lstm_model            0.953972  0.946346   \n",
       "                      uni_lstm_model              0.947972  0.939282   \n",
       "            fft       cnn_model                   0.949840  0.941047   \n",
       "                      cnn_model_comp              0.949337  0.942178   \n",
       "                      cnn_two_channels_model      0.950559  0.941536   \n",
       "                      multi_cnn_model             0.951170  0.942834   \n",
       "                      multi_lstm_model            0.949984  0.941660   \n",
       "                      uni_lstm_model              0.948690  0.940076   \n",
       "7           None      cnn_model                   0.948117  0.939133   \n",
       "                      cnn_model_comp              0.945027  0.938381   \n",
       "                      cnn_two_channels_model      0.946482  0.938334   \n",
       "                      multi_cnn_model             0.948513  0.940596   \n",
       "                      multi_lstm_model            0.947578  0.940126   \n",
       "                      uni_lstm_model              0.943033  0.935075   \n",
       "            dct       cnn_model                   0.946608  0.938094   \n",
       "                      cnn_model_comp              0.933781  0.927232   \n",
       "                      cnn_two_channels_model      0.944686  0.936959   \n",
       "                      multi_cnn_model             0.947129  0.939009   \n",
       "                      multi_lstm_model            0.948099  0.940645   \n",
       "                      uni_lstm_model              0.942728  0.934530   \n",
       "            fft       cnn_model                   0.944524  0.935902   \n",
       "                      cnn_model_comp              0.933835  0.927361   \n",
       "                      cnn_two_channels_model      0.942692  0.935472   \n",
       "                      multi_cnn_model             0.944955  0.936713   \n",
       "                      multi_lstm_model            0.943608  0.935804   \n",
       "                      uni_lstm_model              0.943069  0.934230   \n",
       "\n",
       "                                                       rec       pre  \\\n",
       "window_size transform model                                            \n",
       "3           None      cnn_model                   0.967238  0.964414   \n",
       "                      cnn_model_comp              0.978745  0.950083   \n",
       "                      cnn_two_channels_model      0.974351  0.954777   \n",
       "                      cnn_two_channels_model_bis  0.962971  0.956567   \n",
       "                      multi_cnn_model             0.968117  0.961200   \n",
       "                      multi_lstm_model            0.968452  0.961412   \n",
       "                      uni_lstm_model              0.965021  0.956695   \n",
       "            dct       cnn_model                   0.969623  0.960063   \n",
       "                      cnn_model_comp              0.992762  0.907099   \n",
       "                      cnn_two_channels_model      0.980502  0.942601   \n",
       "                      multi_cnn_model             0.970753  0.957492   \n",
       "                      multi_lstm_model            0.966360  0.965108   \n",
       "                      uni_lstm_model              0.972469  0.951177   \n",
       "            fft       cnn_model                   0.970460  0.956375   \n",
       "                      cnn_model_comp              0.977448  0.948131   \n",
       "                      cnn_two_channels_model      0.966987  0.959361   \n",
       "                      multi_cnn_model             0.973891  0.952451   \n",
       "                      multi_lstm_model            0.971255  0.956803   \n",
       "                      uni_lstm_model              0.974017  0.949659   \n",
       "4           None      cnn_model                   0.953891  0.962428   \n",
       "                      cnn_model_comp              0.968787  0.952526   \n",
       "                      cnn_two_channels_model      0.957448  0.961794   \n",
       "                      multi_cnn_model             0.953933  0.964915   \n",
       "                      multi_lstm_model            0.945230  0.972409   \n",
       "                      uni_lstm_model              0.962678  0.949959   \n",
       "            dct       cnn_model                   0.959623  0.957380   \n",
       "                      cnn_model_comp              0.958494  0.958975   \n",
       "                      cnn_two_channels_model      0.972469  0.937631   \n",
       "                      multi_cnn_model             0.950544  0.964425   \n",
       "                      multi_lstm_model            0.955649  0.960633   \n",
       "                      uni_lstm_model              0.959498  0.952326   \n",
       "            fft       cnn_model                   0.955983  0.958228   \n",
       "                      cnn_model_comp              0.961339  0.955105   \n",
       "                      cnn_two_channels_model      0.961004  0.955408   \n",
       "                      multi_cnn_model             0.963138  0.953405   \n",
       "                      multi_lstm_model            0.948536  0.964517   \n",
       "                      uni_lstm_model              0.954770  0.954770   \n",
       "5           None      cnn_model                   0.956402  0.949647   \n",
       "                      cnn_model_comp              0.968159  0.939655   \n",
       "                      cnn_two_channels_model      0.958075  0.946981   \n",
       "                      multi_cnn_model             0.959121  0.949389   \n",
       "                      multi_lstm_model            0.958368  0.946097   \n",
       "                      uni_lstm_model              0.958828  0.939758   \n",
       "            dct       cnn_model                   0.952929  0.951337   \n",
       "                      cnn_model_comp              0.948619  0.952405   \n",
       "                      cnn_two_channels_model      0.956109  0.946407   \n",
       "                      multi_cnn_model             0.954561  0.949199   \n",
       "                      multi_lstm_model            0.962594  0.943836   \n",
       "                      uni_lstm_model              0.961423  0.934825   \n",
       "            fft       cnn_model                   0.960460  0.939623   \n",
       "                      cnn_model_comp              0.963347  0.937268   \n",
       "                      cnn_two_channels_model      0.956527  0.941557   \n",
       "                      multi_cnn_model             0.960167  0.939914   \n",
       "                      multi_lstm_model            0.965774  0.933549   \n",
       "                      uni_lstm_model              0.951046  0.944918   \n",
       "6           None      cnn_model                   0.930502  0.957257   \n",
       "                      cnn_model_comp              0.974686  0.909251   \n",
       "                      cnn_two_channels_model      0.961590  0.930144   \n",
       "                      multi_cnn_model             0.935607  0.957563   \n",
       "                      multi_lstm_model            0.953222  0.940550   \n",
       "                      uni_lstm_model              0.943013  0.941673   \n",
       "            dct       cnn_model                   0.944686  0.947143   \n",
       "                      cnn_model_comp              0.970126  0.914635   \n",
       "                      cnn_two_channels_model      0.915272  0.962723   \n",
       "                      multi_cnn_model             0.932301  0.955407   \n",
       "                      multi_lstm_model            0.945356  0.947338   \n",
       "                      uni_lstm_model              0.937238  0.941335   \n",
       "            fft       cnn_model                   0.932385  0.949872   \n",
       "                      cnn_model_comp              0.961297  0.923804   \n",
       "                      cnn_two_channels_model      0.927197  0.956327   \n",
       "                      multi_cnn_model             0.937824  0.947898   \n",
       "                      multi_lstm_model            0.940084  0.943241   \n",
       "                      uni_lstm_model              0.937322  0.942845   \n",
       "7           None      cnn_model                   0.932218  0.946153   \n",
       "                      cnn_model_comp              0.974895  0.904503   \n",
       "                      cnn_two_channels_model      0.948326  0.928551   \n",
       "                      multi_cnn_model             0.949372  0.931981   \n",
       "                      multi_lstm_model            0.958536  0.922411   \n",
       "                      uni_lstm_model              0.955439  0.915561   \n",
       "            dct       cnn_model                   0.942176  0.934047   \n",
       "                      cnn_model_comp              0.982594  0.877775   \n",
       "                      cnn_two_channels_model      0.957364  0.917405   \n",
       "                      multi_cnn_model             0.947908  0.930276   \n",
       "                      multi_lstm_model            0.957824  0.924071   \n",
       "                      uni_lstm_model              0.952008  0.917682   \n",
       "            fft       cnn_model                   0.943264  0.928654   \n",
       "                      cnn_model_comp              0.983682  0.877141   \n",
       "                      cnn_two_channels_model      0.967490  0.905506   \n",
       "                      multi_cnn_model             0.948745  0.924982   \n",
       "                      multi_lstm_model            0.957280  0.915270   \n",
       "                      uni_lstm_model              0.941715  0.926862   \n",
       "\n",
       "                                                       spe       sen     tn  \\\n",
       "window_size transform model                                                   \n",
       "3           None      cnn_model                   0.973147  0.967238  30912   \n",
       "                      cnn_model_comp              0.961310  0.978745  30536   \n",
       "                      cnn_two_channels_model      0.965276  0.974351  30662   \n",
       "                      cnn_two_channels_model_bis  0.967102  0.962971  30720   \n",
       "                      multi_cnn_model             0.970597  0.968117  30831   \n",
       "                      multi_lstm_model            0.970754  0.968452  30836   \n",
       "                      uni_lstm_model              0.967134  0.965021  30721   \n",
       "            dct       cnn_model                   0.969652  0.969623  30801   \n",
       "                      cnn_model_comp              0.923501  0.992762  29335   \n",
       "                      cnn_two_channels_model      0.955076  0.980502  30338   \n",
       "                      multi_cnn_model             0.967574  0.970753  30735   \n",
       "                      multi_lstm_model            0.973713  0.966360  30930   \n",
       "                      uni_lstm_model              0.962443  0.972469  30572   \n",
       "            fft       cnn_model                   0.966693  0.970460  30707   \n",
       "                      cnn_model_comp              0.959767  0.977448  30487   \n",
       "                      cnn_two_channels_model      0.969180  0.966987  30786   \n",
       "                      multi_cnn_model             0.963419  0.973891  30603   \n",
       "                      multi_lstm_model            0.967008  0.971255  30717   \n",
       "                      uni_lstm_model              0.961152  0.974017  30531   \n",
       "4           None      cnn_model                   0.971981  0.953891  30874   \n",
       "                      cnn_model_comp              0.963670  0.968787  30610   \n",
       "                      cnn_two_channels_model      0.971383  0.957448  30855   \n",
       "                      multi_cnn_model             0.973901  0.953933  30935   \n",
       "                      multi_lstm_model            0.979820  0.945230  31123   \n",
       "                      uni_lstm_model              0.961844  0.962678  30552   \n",
       "            dct       cnn_model                   0.967857  0.959623  30743   \n",
       "                      cnn_model_comp              0.969147  0.958494  30784   \n",
       "                      cnn_two_channels_model      0.951329  0.972469  30218   \n",
       "                      multi_cnn_model             0.973618  0.950544  30926   \n",
       "                      multi_lstm_model            0.970533  0.955649  30828   \n",
       "                      uni_lstm_model              0.963858  0.959498  30616   \n",
       "            fft       cnn_model                   0.968644  0.955983  30768   \n",
       "                      cnn_model_comp              0.965999  0.961339  30684   \n",
       "                      cnn_two_channels_model      0.966251  0.961004  30692   \n",
       "                      multi_cnn_model             0.964583  0.963138  30639   \n",
       "                      multi_lstm_model            0.973744  0.948536  30930   \n",
       "                      uni_lstm_model              0.965968  0.954770  30683   \n",
       "5           None      cnn_model                   0.961845  0.956402  30553   \n",
       "                      cnn_model_comp              0.953219  0.968159  30279   \n",
       "                      cnn_two_channels_model      0.959641  0.958075  30483   \n",
       "                      multi_cnn_model             0.961530  0.959121  30543   \n",
       "                      multi_lstm_model            0.958917  0.958368  30460   \n",
       "                      uni_lstm_model              0.953754  0.958828  30296   \n",
       "            dct       cnn_model                   0.963324  0.952929  30600   \n",
       "                      cnn_model_comp              0.964332  0.948619  30632   \n",
       "                      cnn_two_channels_model      0.959263  0.956109  30471   \n",
       "                      multi_cnn_model             0.961561  0.954561  30544   \n",
       "                      multi_lstm_model            0.956902  0.962594  30396   \n",
       "                      uni_lstm_model              0.949567  0.961423  30163   \n",
       "            fft       cnn_model                   0.953565  0.960460  30290   \n",
       "                      cnn_model_comp              0.951487  0.963347  30224   \n",
       "                      cnn_two_channels_model      0.955328  0.956527  30346   \n",
       "                      multi_cnn_model             0.953817  0.960167  30298   \n",
       "                      multi_lstm_model            0.948276  0.965774  30122   \n",
       "                      uni_lstm_model              0.958287  0.951046  30440   \n",
       "6           None      cnn_model                   0.968736  0.930502  30769   \n",
       "                      cnn_model_comp              0.926799  0.974686  29437   \n",
       "                      cnn_two_channels_model      0.945658  0.961590  30036   \n",
       "                      multi_cnn_model             0.968799  0.935607  30771   \n",
       "                      multi_lstm_model            0.954663  0.953222  30322   \n",
       "                      uni_lstm_model              0.956048  0.943013  30366   \n",
       "            dct       cnn_model                   0.960330  0.944686  30502   \n",
       "                      cnn_model_comp              0.931868  0.970126  29598   \n",
       "                      cnn_two_channels_model      0.973333  0.915272  30915   \n",
       "                      multi_cnn_model             0.967256  0.932301  30722   \n",
       "                      multi_lstm_model            0.960456  0.945356  30506   \n",
       "                      uni_lstm_model              0.956048  0.937238  30366   \n",
       "            fft       cnn_model                   0.962975  0.932385  30586   \n",
       "                      cnn_model_comp              0.940338  0.961297  29867   \n",
       "                      cnn_two_channels_model      0.968138  0.927197  30750   \n",
       "                      multi_cnn_model             0.961212  0.937824  30530   \n",
       "                      multi_lstm_model            0.957433  0.940084  30410   \n",
       "                      uni_lstm_model              0.957245  0.937322  30404   \n",
       "7           None      cnn_model                   0.960081  0.932218  30496   \n",
       "                      cnn_model_comp              0.922554  0.974895  29304   \n",
       "                      cnn_two_channels_model      0.945095  0.948326  30020   \n",
       "                      multi_cnn_model             0.947866  0.949372  30108   \n",
       "                      multi_lstm_model            0.939334  0.958536  29837   \n",
       "                      uni_lstm_model              0.933699  0.955439  29658   \n",
       "            dct       cnn_model                   0.949943  0.942176  30174   \n",
       "                      cnn_model_comp              0.897053  0.982594  28494   \n",
       "                      cnn_two_channels_model      0.935147  0.957364  29704   \n",
       "                      multi_cnn_model             0.946543  0.947908  30066   \n",
       "                      multi_lstm_model            0.940782  0.957824  29883   \n",
       "                      uni_lstm_model              0.935745  0.952008  29723   \n",
       "            fft       cnn_model                   0.945473  0.943264  30032   \n",
       "                      cnn_model_comp              0.896329  0.983682  28471   \n",
       "                      cnn_two_channels_model      0.924033  0.967490  29351   \n",
       "                      multi_cnn_model             0.942104  0.948745  29925   \n",
       "                      multi_lstm_model            0.933321  0.957280  29646   \n",
       "                      uni_lstm_model              0.944088  0.941715  29988   \n",
       "\n",
       "                                                    fp    fn     tp  \n",
       "window_size transform model                                          \n",
       "3           None      cnn_model                    853   783  23117  \n",
       "                      cnn_model_comp              1229   508  23392  \n",
       "                      cnn_two_channels_model      1103   613  23287  \n",
       "                      cnn_two_channels_model_bis  1045   885  23015  \n",
       "                      multi_cnn_model              934   762  23138  \n",
       "                      multi_lstm_model             929   754  23146  \n",
       "                      uni_lstm_model              1044   836  23064  \n",
       "            dct       cnn_model                    964   726  23174  \n",
       "                      cnn_model_comp              2430   173  23727  \n",
       "                      cnn_two_channels_model      1427   466  23434  \n",
       "                      multi_cnn_model             1030   699  23201  \n",
       "                      multi_lstm_model             835   804  23096  \n",
       "                      uni_lstm_model              1193   658  23242  \n",
       "            fft       cnn_model                   1058   706  23194  \n",
       "                      cnn_model_comp              1278   539  23361  \n",
       "                      cnn_two_channels_model       979   789  23111  \n",
       "                      multi_cnn_model             1162   624  23276  \n",
       "                      multi_lstm_model            1048   687  23213  \n",
       "                      uni_lstm_model              1234   621  23279  \n",
       "4           None      cnn_model                    890  1102  22798  \n",
       "                      cnn_model_comp              1154   746  23154  \n",
       "                      cnn_two_channels_model       909  1017  22883  \n",
       "                      multi_cnn_model              829  1101  22799  \n",
       "                      multi_lstm_model             641  1309  22591  \n",
       "                      uni_lstm_model              1212   892  23008  \n",
       "            dct       cnn_model                   1021   965  22935  \n",
       "                      cnn_model_comp               980   992  22908  \n",
       "                      cnn_two_channels_model      1546   658  23242  \n",
       "                      multi_cnn_model              838  1182  22718  \n",
       "                      multi_lstm_model             936  1060  22840  \n",
       "                      uni_lstm_model              1148   968  22932  \n",
       "            fft       cnn_model                    996  1052  22848  \n",
       "                      cnn_model_comp              1080   924  22976  \n",
       "                      cnn_two_channels_model      1072   932  22968  \n",
       "                      multi_cnn_model             1125   881  23019  \n",
       "                      multi_lstm_model             834  1230  22670  \n",
       "                      uni_lstm_model              1081  1081  22819  \n",
       "5           None      cnn_model                   1212  1042  22858  \n",
       "                      cnn_model_comp              1486   761  23139  \n",
       "                      cnn_two_channels_model      1282  1002  22898  \n",
       "                      multi_cnn_model             1222   977  22923  \n",
       "                      multi_lstm_model            1305   995  22905  \n",
       "                      uni_lstm_model              1469   984  22916  \n",
       "            dct       cnn_model                   1165  1125  22775  \n",
       "                      cnn_model_comp              1133  1228  22672  \n",
       "                      cnn_two_channels_model      1294  1049  22851  \n",
       "                      multi_cnn_model             1221  1086  22814  \n",
       "                      multi_lstm_model            1369   894  23006  \n",
       "                      uni_lstm_model              1602   922  22978  \n",
       "            fft       cnn_model                   1475   945  22955  \n",
       "                      cnn_model_comp              1541   876  23024  \n",
       "                      cnn_two_channels_model      1419  1039  22861  \n",
       "                      multi_cnn_model             1467   952  22948  \n",
       "                      multi_lstm_model            1643   818  23082  \n",
       "                      uni_lstm_model              1325  1170  22730  \n",
       "6           None      cnn_model                    993  1661  22239  \n",
       "                      cnn_model_comp              2325   605  23295  \n",
       "                      cnn_two_channels_model      1726   918  22982  \n",
       "                      multi_cnn_model              991  1539  22361  \n",
       "                      multi_lstm_model            1440  1118  22782  \n",
       "                      uni_lstm_model              1396  1362  22538  \n",
       "            dct       cnn_model                   1260  1322  22578  \n",
       "                      cnn_model_comp              2164   714  23186  \n",
       "                      cnn_two_channels_model       847  2025  21875  \n",
       "                      multi_cnn_model             1040  1618  22282  \n",
       "                      multi_lstm_model            1256  1306  22594  \n",
       "                      uni_lstm_model              1396  1500  22400  \n",
       "            fft       cnn_model                   1176  1616  22284  \n",
       "                      cnn_model_comp              1895   925  22975  \n",
       "                      cnn_two_channels_model      1012  1740  22160  \n",
       "                      multi_cnn_model             1232  1486  22414  \n",
       "                      multi_lstm_model            1352  1432  22468  \n",
       "                      uni_lstm_model              1358  1498  22402  \n",
       "7           None      cnn_model                   1268  1620  22280  \n",
       "                      cnn_model_comp              2460   600  23300  \n",
       "                      cnn_two_channels_model      1744  1235  22665  \n",
       "                      multi_cnn_model             1656  1210  22690  \n",
       "                      multi_lstm_model            1927   991  22909  \n",
       "                      uni_lstm_model              2106  1065  22835  \n",
       "            dct       cnn_model                   1590  1382  22518  \n",
       "                      cnn_model_comp              3270   416  23484  \n",
       "                      cnn_two_channels_model      2060  1019  22881  \n",
       "                      multi_cnn_model             1698  1245  22655  \n",
       "                      multi_lstm_model            1881  1008  22892  \n",
       "                      uni_lstm_model              2041  1147  22753  \n",
       "            fft       cnn_model                   1732  1356  22544  \n",
       "                      cnn_model_comp              3293   390  23510  \n",
       "                      cnn_two_channels_model      2413   777  23123  \n",
       "                      multi_cnn_model             1839  1225  22675  \n",
       "                      multi_lstm_model            2118  1021  22879  \n",
       "                      uni_lstm_model              1776  1393  22507  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_df.sort_values(by=['window_size', 'transform', 'model']).set_index(['window_size', 'transform', 'model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0781ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
